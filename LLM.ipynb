{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "LLM.ipynb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "536bbd4f9d9a4dae84f4cd117507ef8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_827048c2f2ea453a86e0a1457e3ab98b",
              "IPY_MODEL_6c230d8949374ecdba5cabcf58653a20",
              "IPY_MODEL_a606d875b90f41b2bc4c315910da8501"
            ],
            "layout": "IPY_MODEL_0d50b193594d408c8c035b81d565484d"
          }
        },
        "827048c2f2ea453a86e0a1457e3ab98b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c485fbd3d0d54c0698d16766a4543742",
            "placeholder": "​",
            "style": "IPY_MODEL_774ae5fb84114ee3bf8735e0e11c23e4",
            "value": "README.md: 100%"
          }
        },
        "6c230d8949374ecdba5cabcf58653a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f907fa7065b46dd96864df818087336",
            "max": 10464,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d6a07bac37e435cb312418413ac2d47",
            "value": 10464
          }
        },
        "a606d875b90f41b2bc4c315910da8501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8f07bde87574731903a06630f15470a",
            "placeholder": "​",
            "style": "IPY_MODEL_6e38b8ac0860400797d2b9495ee9a0f5",
            "value": " 10.5k/10.5k [00:00&lt;00:00, 1.13MB/s]"
          }
        },
        "0d50b193594d408c8c035b81d565484d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c485fbd3d0d54c0698d16766a4543742": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "774ae5fb84114ee3bf8735e0e11c23e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f907fa7065b46dd96864df818087336": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d6a07bac37e435cb312418413ac2d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8f07bde87574731903a06630f15470a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e38b8ac0860400797d2b9495ee9a0f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b8a9207b1d9419ebe7e5e3060ea8aa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75f3865a0f1e4d98baf9c3bcc3949f99",
              "IPY_MODEL_7b6425481eef4af6badb191c15682b0e",
              "IPY_MODEL_1a122848ca5448e1a16574e73367366a"
            ],
            "layout": "IPY_MODEL_5fb59fe14ec44f2ea6738e9b47438ebb"
          }
        },
        "75f3865a0f1e4d98baf9c3bcc3949f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63753fe89da44919b74febd863535679",
            "placeholder": "​",
            "style": "IPY_MODEL_189f0d3062c24d6fa7f8d64261520d12",
            "value": "test-00000-of-00001.parquet: 100%"
          }
        },
        "7b6425481eef4af6badb191c15682b0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9876244a5f3403b8e3530555de584aa",
            "max": 732610,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57029ed61e77438c9ed90d8218d5fb34",
            "value": 732610
          }
        },
        "1a122848ca5448e1a16574e73367366a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d232dafab814c2497796713987acac7",
            "placeholder": "​",
            "style": "IPY_MODEL_620276cff6e1481da44ca422459f8dc6",
            "value": " 733k/733k [00:00&lt;00:00, 4.57MB/s]"
          }
        },
        "5fb59fe14ec44f2ea6738e9b47438ebb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63753fe89da44919b74febd863535679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "189f0d3062c24d6fa7f8d64261520d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9876244a5f3403b8e3530555de584aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57029ed61e77438c9ed90d8218d5fb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d232dafab814c2497796713987acac7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "620276cff6e1481da44ca422459f8dc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebe1b765189b4a0d86bb43bf898fb92b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be8cf3f1c4ec456f8f89709baed70a57",
              "IPY_MODEL_9683ea64da0943838e7282a47aedc978",
              "IPY_MODEL_fba5467fb87e4d64ab733d67000c96c0"
            ],
            "layout": "IPY_MODEL_0f97c3ac8f194414b6256669b046a1cc"
          }
        },
        "be8cf3f1c4ec456f8f89709baed70a57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c976351aed424abb8db1e44ec8c7c714",
            "placeholder": "​",
            "style": "IPY_MODEL_90d22cd398ad4431a35a223aa657f624",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "9683ea64da0943838e7282a47aedc978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a18834ca90c1404cafd15a66742882bc",
            "max": 6357543,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7c216e11a544d57b74b37e9faaf9aaa",
            "value": 6357543
          }
        },
        "fba5467fb87e4d64ab733d67000c96c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccf9d8759c794eeea73a4f51c0b72900",
            "placeholder": "​",
            "style": "IPY_MODEL_7391b82a402240fa9d26025dc6dc63f9",
            "value": " 6.36M/6.36M [00:00&lt;00:00, 33.7MB/s]"
          }
        },
        "0f97c3ac8f194414b6256669b046a1cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c976351aed424abb8db1e44ec8c7c714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90d22cd398ad4431a35a223aa657f624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a18834ca90c1404cafd15a66742882bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7c216e11a544d57b74b37e9faaf9aaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccf9d8759c794eeea73a4f51c0b72900": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7391b82a402240fa9d26025dc6dc63f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73fef4b00a8c4dac8dc70c203dc64b92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9395ca6c3084d8f9c4ac76c8a325a02",
              "IPY_MODEL_b14cff3dbda04ee98d3b9aea508b664a",
              "IPY_MODEL_64a415e282a14e6f83f69a41ab90e279"
            ],
            "layout": "IPY_MODEL_b8a92af712634b43a4ff9d104db05976"
          }
        },
        "f9395ca6c3084d8f9c4ac76c8a325a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_295eb816a3ec4184b6070454bd5d282d",
            "placeholder": "​",
            "style": "IPY_MODEL_030080d788d3482cb5e402a41a00e87d",
            "value": "validation-00000-of-00001.parquet: 100%"
          }
        },
        "b14cff3dbda04ee98d3b9aea508b664a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c035a2e225cb45e29fec3f9350252122",
            "max": 657209,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8322480b6c794c23bd7411938feb66f2",
            "value": 657209
          }
        },
        "64a415e282a14e6f83f69a41ab90e279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5311f45ad4e640a19d329a3975d7563a",
            "placeholder": "​",
            "style": "IPY_MODEL_23d4bf5d7a09483f8737244105601a21",
            "value": " 657k/657k [00:00&lt;00:00, 23.5MB/s]"
          }
        },
        "b8a92af712634b43a4ff9d104db05976": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "295eb816a3ec4184b6070454bd5d282d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "030080d788d3482cb5e402a41a00e87d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c035a2e225cb45e29fec3f9350252122": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8322480b6c794c23bd7411938feb66f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5311f45ad4e640a19d329a3975d7563a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23d4bf5d7a09483f8737244105601a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b9b9d68f43c4abb8a10010da5e96eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01ebffd4084740e988790caccb3b998d",
              "IPY_MODEL_ecb558ff6abf4f91aacf226188cf1101",
              "IPY_MODEL_66ee1da365474fc993caa1f75712a3df"
            ],
            "layout": "IPY_MODEL_c60cfcc00a5b4c7cbb5872175e4c5f53"
          }
        },
        "01ebffd4084740e988790caccb3b998d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66cb2114fbc84d6a90f12f63befcc861",
            "placeholder": "​",
            "style": "IPY_MODEL_de90c22a6b0e4e4ba41ea8d793e3eb4b",
            "value": "Generating test split: 100%"
          }
        },
        "ecb558ff6abf4f91aacf226188cf1101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08d2a3c20252467c9fa82535a5bd1e08",
            "max": 4358,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4659665e029a45d9b7fa177831df323b",
            "value": 4358
          }
        },
        "66ee1da365474fc993caa1f75712a3df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fcbe876ec3944a9956c8cdd2110f064",
            "placeholder": "​",
            "style": "IPY_MODEL_b442131657294e37b22e06e2261ab074",
            "value": " 4358/4358 [00:00&lt;00:00, 61101.56 examples/s]"
          }
        },
        "c60cfcc00a5b4c7cbb5872175e4c5f53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66cb2114fbc84d6a90f12f63befcc861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de90c22a6b0e4e4ba41ea8d793e3eb4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08d2a3c20252467c9fa82535a5bd1e08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4659665e029a45d9b7fa177831df323b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fcbe876ec3944a9956c8cdd2110f064": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b442131657294e37b22e06e2261ab074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbc55dc5fef04c6ca20196a13317088f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74defcf547384e04a9727e16e64bd522",
              "IPY_MODEL_4e59af71b85649a09f4101a4fb6e61f2",
              "IPY_MODEL_acc276708088402eb94d332eb3bceaf3"
            ],
            "layout": "IPY_MODEL_b86f8740ddc54c3bac6a14c7ac496104"
          }
        },
        "74defcf547384e04a9727e16e64bd522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb62f4c2298b4b9692e802adf126f293",
            "placeholder": "​",
            "style": "IPY_MODEL_f38b5ddf625049248276204f01aaaf2a",
            "value": "Generating train split: 100%"
          }
        },
        "4e59af71b85649a09f4101a4fb6e61f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8e0cb17545d4a45bc1ef2ccb1cba5ba",
            "max": 36718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3aa4f36da0a6434da75563755762fd07",
            "value": 36718
          }
        },
        "acc276708088402eb94d332eb3bceaf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e6c95d5a95d44f599563fb780869309",
            "placeholder": "​",
            "style": "IPY_MODEL_0bf5252545ac47a68afe8c5e6f5c8818",
            "value": " 36718/36718 [00:00&lt;00:00, 168944.35 examples/s]"
          }
        },
        "b86f8740ddc54c3bac6a14c7ac496104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb62f4c2298b4b9692e802adf126f293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f38b5ddf625049248276204f01aaaf2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8e0cb17545d4a45bc1ef2ccb1cba5ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa4f36da0a6434da75563755762fd07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e6c95d5a95d44f599563fb780869309": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bf5252545ac47a68afe8c5e6f5c8818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d31c16fe66b4752846f2ca410670e51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_716194d342ae4f11894525c469e452da",
              "IPY_MODEL_bc9c6afde29b4009b98210ce0326574a",
              "IPY_MODEL_4ab511d0ac4b4b55ae6d04657c0cfae8"
            ],
            "layout": "IPY_MODEL_f7149e15972a43a18e819b8ecba52edf"
          }
        },
        "716194d342ae4f11894525c469e452da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40b3f408fe454a1a907f36d23469a251",
            "placeholder": "​",
            "style": "IPY_MODEL_16f3286c4f76431ab10aa441786eab8d",
            "value": "Generating validation split: 100%"
          }
        },
        "bc9c6afde29b4009b98210ce0326574a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ebddcae99444efd898722ff7ee617f0",
            "max": 3760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f7b6cb614974caa950ce816ed7ecd97",
            "value": 3760
          }
        },
        "4ab511d0ac4b4b55ae6d04657c0cfae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d4bb0556d9545f2a62bc1c08845975b",
            "placeholder": "​",
            "style": "IPY_MODEL_65f670306e664758b956f6ba42759670",
            "value": " 3760/3760 [00:00&lt;00:00, 87510.80 examples/s]"
          }
        },
        "f7149e15972a43a18e819b8ecba52edf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40b3f408fe454a1a907f36d23469a251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16f3286c4f76431ab10aa441786eab8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ebddcae99444efd898722ff7ee617f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f7b6cb614974caa950ce816ed7ecd97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d4bb0556d9545f2a62bc1c08845975b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65f670306e664758b956f6ba42759670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1a0e34d71014ac4ae36c3b817a634a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba774e82f7904b04aee1b1a72591905c",
              "IPY_MODEL_c2e3a74bac95475287f9b0d78d5e7d3f",
              "IPY_MODEL_3a1771d51cd84676be26696cdfa3ebe2"
            ],
            "layout": "IPY_MODEL_ed76d5f54f81494ab10acded85170071"
          }
        },
        "ba774e82f7904b04aee1b1a72591905c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c74a0f176464190952e0072fb03cc87",
            "placeholder": "​",
            "style": "IPY_MODEL_f67790fc39304678beebe927ec23fe12",
            "value": "Tokenizing dataset: 100%"
          }
        },
        "c2e3a74bac95475287f9b0d78d5e7d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96ae4d470b3042788fe45b05c7fd0396",
            "max": 4358,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fcb0afe9dac54e09b7d6332022b45e82",
            "value": 4358
          }
        },
        "3a1771d51cd84676be26696cdfa3ebe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37f8c95e98e24c3ea34501209d7b40dd",
            "placeholder": "​",
            "style": "IPY_MODEL_dfbf1f1ba2c24373ae1dccc0af138e1d",
            "value": " 4358/4358 [00:01&lt;00:00, 3772.49 examples/s]"
          }
        },
        "ed76d5f54f81494ab10acded85170071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c74a0f176464190952e0072fb03cc87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f67790fc39304678beebe927ec23fe12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96ae4d470b3042788fe45b05c7fd0396": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcb0afe9dac54e09b7d6332022b45e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37f8c95e98e24c3ea34501209d7b40dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfbf1f1ba2c24373ae1dccc0af138e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b064ebaf32e445b290583af749bdcdd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1fbbb3b6a6a4387b29192d5d8a5cd68",
              "IPY_MODEL_23c933031faa4b979a9d6c931de726fd",
              "IPY_MODEL_285b37ff2c7a4128a039160eb07d0daa"
            ],
            "layout": "IPY_MODEL_63936513fd744fe9a03712d6ee25c80a"
          }
        },
        "f1fbbb3b6a6a4387b29192d5d8a5cd68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3505a1db03c7474f87268a0d761aeb14",
            "placeholder": "​",
            "style": "IPY_MODEL_63895d357a8646af98e74673b967db25",
            "value": "Tokenizing dataset: 100%"
          }
        },
        "23c933031faa4b979a9d6c931de726fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb4acf90f2f54f3abe2000719d71abd4",
            "max": 36718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56397e1d2b244612bf16211ab92fb791",
            "value": 36718
          }
        },
        "285b37ff2c7a4128a039160eb07d0daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a70b2cb1e474f9ca9715053d040757f",
            "placeholder": "​",
            "style": "IPY_MODEL_0754632694f14643a75d8d7b2278fd8f",
            "value": " 36718/36718 [00:12&lt;00:00, 2356.22 examples/s]"
          }
        },
        "63936513fd744fe9a03712d6ee25c80a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3505a1db03c7474f87268a0d761aeb14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63895d357a8646af98e74673b967db25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb4acf90f2f54f3abe2000719d71abd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56397e1d2b244612bf16211ab92fb791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a70b2cb1e474f9ca9715053d040757f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0754632694f14643a75d8d7b2278fd8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14decca3db5d4b5e89e6d0485131c794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6b59725c711451bbfe15979f7f9b945",
              "IPY_MODEL_b8bfaedbaed7492fb2798d5afbf7301a",
              "IPY_MODEL_6a044d1224ad40c280a10aebf82e102c"
            ],
            "layout": "IPY_MODEL_48a2f57e4ebf416c873d81acb4067b03"
          }
        },
        "f6b59725c711451bbfe15979f7f9b945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bb7b359ed1c4fac9efaefde0b00d20c",
            "placeholder": "​",
            "style": "IPY_MODEL_4a86cbf4a2d34690b94ac8f8034d398b",
            "value": "Tokenizing dataset: 100%"
          }
        },
        "b8bfaedbaed7492fb2798d5afbf7301a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2381755cc7ae4399a60fa86586fc5844",
            "max": 3760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d613c953b514230b26fcb4a24d9a48b",
            "value": 3760
          }
        },
        "6a044d1224ad40c280a10aebf82e102c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38ed302edc59435b911e46a552c90c50",
            "placeholder": "​",
            "style": "IPY_MODEL_0493c4908c634c238c49bdc7cddde28d",
            "value": " 3760/3760 [00:01&lt;00:00, 3273.99 examples/s]"
          }
        },
        "48a2f57e4ebf416c873d81acb4067b03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bb7b359ed1c4fac9efaefde0b00d20c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a86cbf4a2d34690b94ac8f8034d398b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2381755cc7ae4399a60fa86586fc5844": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d613c953b514230b26fcb4a24d9a48b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38ed302edc59435b911e46a552c90c50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0493c4908c634c238c49bdc7cddde28d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3cb8fdd22a14ad698234ffafb0927c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93b147b8d3ec4433b8024430d267600a",
              "IPY_MODEL_cdf708a423284bb9adaf0923f2c4ff37",
              "IPY_MODEL_2e35a52749194040aa04da3aa48ab429"
            ],
            "layout": "IPY_MODEL_8201bbe3ff7a4023bc6ce7198c47729b"
          }
        },
        "93b147b8d3ec4433b8024430d267600a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feb4f89fe6564c10b02e310c75d5cf85",
            "placeholder": "​",
            "style": "IPY_MODEL_a9ec911a9b8c4a32ab1d585f9b5ba383",
            "value": "Filtering empty examples: 100%"
          }
        },
        "cdf708a423284bb9adaf0923f2c4ff37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb4de201419c4246876073b43f3c6557",
            "max": 4358,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_205a1f6d5eaa4150bc14a132847936b7",
            "value": 4358
          }
        },
        "2e35a52749194040aa04da3aa48ab429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2cdb111319b4312a5eaf65781626332",
            "placeholder": "​",
            "style": "IPY_MODEL_3298509c78104d61a71762443a010fe6",
            "value": " 4358/4358 [00:00&lt;00:00, 28613.65 examples/s]"
          }
        },
        "8201bbe3ff7a4023bc6ce7198c47729b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feb4f89fe6564c10b02e310c75d5cf85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9ec911a9b8c4a32ab1d585f9b5ba383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb4de201419c4246876073b43f3c6557": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "205a1f6d5eaa4150bc14a132847936b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2cdb111319b4312a5eaf65781626332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3298509c78104d61a71762443a010fe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4862ff4488be4019b30a42dd35f24469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8494633f990a49d4a03c83885686403f",
              "IPY_MODEL_7a4362ac58b34eefa5adbc16bbbd5526",
              "IPY_MODEL_63dbdfb932ae47c2b605ddb7dc575403"
            ],
            "layout": "IPY_MODEL_5712f16f2d6340968ad3145f6d4f6e59"
          }
        },
        "8494633f990a49d4a03c83885686403f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12e69714b0104b51a7ba54eb6a543980",
            "placeholder": "​",
            "style": "IPY_MODEL_e3fb2328b22c4602ba98212ed2a30255",
            "value": "Filtering empty examples: 100%"
          }
        },
        "7a4362ac58b34eefa5adbc16bbbd5526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c799189e98e94dd0a8466dec3aa5bb1e",
            "max": 36718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72a0e5ca017046d79e5d0480a7831fe9",
            "value": 36718
          }
        },
        "63dbdfb932ae47c2b605ddb7dc575403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b1fa170c7d0494ea94f24d13b3c3ae5",
            "placeholder": "​",
            "style": "IPY_MODEL_688e30f4c11e4674a4beb1e14790c3db",
            "value": " 36718/36718 [00:01&lt;00:00, 33511.70 examples/s]"
          }
        },
        "5712f16f2d6340968ad3145f6d4f6e59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12e69714b0104b51a7ba54eb6a543980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3fb2328b22c4602ba98212ed2a30255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c799189e98e94dd0a8466dec3aa5bb1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72a0e5ca017046d79e5d0480a7831fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b1fa170c7d0494ea94f24d13b3c3ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "688e30f4c11e4674a4beb1e14790c3db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "764544c792034bf7b48a49d80e999d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ecc751648004284b27d77ae33700315",
              "IPY_MODEL_f481a209c86b459e83c83de0a921c7e5",
              "IPY_MODEL_ec95ade0677343429d9594dcbacb7492"
            ],
            "layout": "IPY_MODEL_081a796bde454ec784ac62f7c24381dc"
          }
        },
        "9ecc751648004284b27d77ae33700315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d0916bdaa3344168f832b39f2da9749",
            "placeholder": "​",
            "style": "IPY_MODEL_3232ef5d70824852ab90a535dfa3ecdb",
            "value": "Filtering empty examples: 100%"
          }
        },
        "f481a209c86b459e83c83de0a921c7e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81855616304f466ebe1f516afd8a8599",
            "max": 3760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fc9fbccdff54dcdbbcb8eda65950724",
            "value": 3760
          }
        },
        "ec95ade0677343429d9594dcbacb7492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52c816d244234877b975382661a73068",
            "placeholder": "​",
            "style": "IPY_MODEL_d411b414cca042ea8eec81af1b07e7fd",
            "value": " 3760/3760 [00:00&lt;00:00, 28293.17 examples/s]"
          }
        },
        "081a796bde454ec784ac62f7c24381dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d0916bdaa3344168f832b39f2da9749": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3232ef5d70824852ab90a535dfa3ecdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81855616304f466ebe1f516afd8a8599": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fc9fbccdff54dcdbbcb8eda65950724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52c816d244234877b975382661a73068": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d411b414cca042ea8eec81af1b07e7fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42f83158948f413192905cd5fe431e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f16002efbb8478bbf8e15aa11036bca",
              "IPY_MODEL_20de2a1b869144888c9fa7f7ae6d103a",
              "IPY_MODEL_fa51b611a92c4f4ba92da915a268e865"
            ],
            "layout": "IPY_MODEL_9eccf4ecef374e4b92166b704234a4da"
          }
        },
        "7f16002efbb8478bbf8e15aa11036bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_288f4cd5e0cc4d338ea468d335498f3f",
            "placeholder": "​",
            "style": "IPY_MODEL_9fdbdc4591f24e439e2853b01fcda60f",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "20de2a1b869144888c9fa7f7ae6d103a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cb66fa466c54ed3a744216f351aff8b",
            "max": 2891,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82da42920adb4a7394df504936b95b82",
            "value": 2891
          }
        },
        "fa51b611a92c4f4ba92da915a268e865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24ed3c66180946e08fa830fdbb67da32",
            "placeholder": "​",
            "style": "IPY_MODEL_c592eb227e4e4fec9eaf5019f0378ef9",
            "value": " 2891/2891 [00:00&lt;00:00, 75710.59 examples/s]"
          }
        },
        "9eccf4ecef374e4b92166b704234a4da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "288f4cd5e0cc4d338ea468d335498f3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fdbdc4591f24e439e2853b01fcda60f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cb66fa466c54ed3a744216f351aff8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82da42920adb4a7394df504936b95b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24ed3c66180946e08fa830fdbb67da32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c592eb227e4e4fec9eaf5019f0378ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bad0f76d32de4cb78101dc2cfa511df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c15231678b6b4e0ab6b67e0d1de36915",
              "IPY_MODEL_a1b757abb1f94734abc568f2c0ab447b",
              "IPY_MODEL_5546e29df09440e790796a5d9d48bf3f"
            ],
            "layout": "IPY_MODEL_a9446b48b9a44fd2aa4cfb1b21ffe96d"
          }
        },
        "c15231678b6b4e0ab6b67e0d1de36915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0dfac3561884c99ab4cac1bf66ed45c",
            "placeholder": "​",
            "style": "IPY_MODEL_effef65dffb246a89be7fd4d29b0799d",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "a1b757abb1f94734abc568f2c0ab447b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2db4fc6e568b4799bb8aefffd498594e",
            "max": 23767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5837210b97be4e20a492ad7bdc83e5cc",
            "value": 23767
          }
        },
        "5546e29df09440e790796a5d9d48bf3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_922ab780037e4b7da19d74b69bb4a86f",
            "placeholder": "​",
            "style": "IPY_MODEL_5b43dfe3e4c547a9ad2845aac03f54dc",
            "value": " 23767/23767 [00:00&lt;00:00, 198860.58 examples/s]"
          }
        },
        "a9446b48b9a44fd2aa4cfb1b21ffe96d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0dfac3561884c99ab4cac1bf66ed45c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "effef65dffb246a89be7fd4d29b0799d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2db4fc6e568b4799bb8aefffd498594e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5837210b97be4e20a492ad7bdc83e5cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "922ab780037e4b7da19d74b69bb4a86f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b43dfe3e4c547a9ad2845aac03f54dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e82ea79dffe472e8d592141c7b80626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_621b4f7f4bb8449793c96e064eb30d3c",
              "IPY_MODEL_b8fe3f43cecc4c15b88a6dd4382316ce",
              "IPY_MODEL_1df4c9855c464c1b92d60314a1d95d46"
            ],
            "layout": "IPY_MODEL_6a4fc30c902248f8b8db2a3e872e5074"
          }
        },
        "621b4f7f4bb8449793c96e064eb30d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05dda977ec75464abcb74c89ba67f8a7",
            "placeholder": "​",
            "style": "IPY_MODEL_64ca6d8f4a1e4fd88bcede93eecb7257",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "b8fe3f43cecc4c15b88a6dd4382316ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90ad64fad7e74f2bb0fd8935bc70118c",
            "max": 2461,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df4bd850f4284c33af619a06da796814",
            "value": 2461
          }
        },
        "1df4c9855c464c1b92d60314a1d95d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38cee70ebeca44478a512224d833a442",
            "placeholder": "​",
            "style": "IPY_MODEL_6c2f437e58be45cabf6a6cb68e7d5075",
            "value": " 2461/2461 [00:00&lt;00:00, 63216.90 examples/s]"
          }
        },
        "6a4fc30c902248f8b8db2a3e872e5074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05dda977ec75464abcb74c89ba67f8a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64ca6d8f4a1e4fd88bcede93eecb7257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90ad64fad7e74f2bb0fd8935bc70118c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df4bd850f4284c33af619a06da796814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38cee70ebeca44478a512224d833a442": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c2f437e58be45cabf6a6cb68e7d5075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95bee252432a4df182459da33924f31e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba1ae8ba04fd4a368b5145b90d832913",
              "IPY_MODEL_a7ce23d3939e4095b7562beed5f0fdcd",
              "IPY_MODEL_a313d48c80c64527a392b30822e34d6e"
            ],
            "layout": "IPY_MODEL_74e390573ea242749a7bcaac164970e6"
          }
        },
        "ba1ae8ba04fd4a368b5145b90d832913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8dcaaf0546a43d0a4f559909c654bbf",
            "placeholder": "​",
            "style": "IPY_MODEL_be4886ab77d342de8a8999d199b0009e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a7ce23d3939e4095b7562beed5f0fdcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f34ec067e7d2461c8f0fdb086cdf7b50",
            "max": 1289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f3b203d2ac14705a740262c4d092754",
            "value": 1289
          }
        },
        "a313d48c80c64527a392b30822e34d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e4ee69491dd47e4857fdd032fd54365",
            "placeholder": "​",
            "style": "IPY_MODEL_46be26a3050f4d28b1348f40db9f7a05",
            "value": " 1.29k/1.29k [00:00&lt;00:00, 87.2kB/s]"
          }
        },
        "74e390573ea242749a7bcaac164970e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8dcaaf0546a43d0a4f559909c654bbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be4886ab77d342de8a8999d199b0009e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f34ec067e7d2461c8f0fdb086cdf7b50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f3b203d2ac14705a740262c4d092754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e4ee69491dd47e4857fdd032fd54365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46be26a3050f4d28b1348f40db9f7a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61b992d7bf9d48e392aee26f9aa03105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2bd7195f1124c4b945c723fcbcbbcb5",
              "IPY_MODEL_409ac01dc52e44808358cb780d4c34f9",
              "IPY_MODEL_19954f3d09b44fb882f86849fd69f690"
            ],
            "layout": "IPY_MODEL_ece64d6c4b8f4066b62fd99e320bcbd3"
          }
        },
        "a2bd7195f1124c4b945c723fcbcbbcb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7177422c703145bc88a7164b8bb27515",
            "placeholder": "​",
            "style": "IPY_MODEL_00451771cf89495b8b97c3453dfab792",
            "value": "tokenizer.model: 100%"
          }
        },
        "409ac01dc52e44808358cb780d4c34f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c2c1f9506bb440d9f83eb663822cf20",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f7e84f8eb284b929955ed2ef2a5570d",
            "value": 499723
          }
        },
        "19954f3d09b44fb882f86849fd69f690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24e0d3acfb5c4e9ebddd183f0664b24d",
            "placeholder": "​",
            "style": "IPY_MODEL_3e79fdd3092646d3ac6acb6e909a8535",
            "value": " 500k/500k [00:00&lt;00:00, 6.24MB/s]"
          }
        },
        "ece64d6c4b8f4066b62fd99e320bcbd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7177422c703145bc88a7164b8bb27515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00451771cf89495b8b97c3453dfab792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c2c1f9506bb440d9f83eb663822cf20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f7e84f8eb284b929955ed2ef2a5570d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24e0d3acfb5c4e9ebddd183f0664b24d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e79fdd3092646d3ac6acb6e909a8535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd204d38ff314bd2a607474fb1b207db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4d3925266a94772b688cf65821794c9",
              "IPY_MODEL_5cfd86e6800c42e3b3864d313c97b498",
              "IPY_MODEL_4745fc0b121e40b0a6d65fc16c1f03db"
            ],
            "layout": "IPY_MODEL_4bf054390f284e079afc75dc0affdfd3"
          }
        },
        "f4d3925266a94772b688cf65821794c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b380a4366450409787ca7a57f1d18862",
            "placeholder": "​",
            "style": "IPY_MODEL_239e1737a85b49d9825211c35c85767e",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "5cfd86e6800c42e3b3864d313c97b498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa746a7fad784f1fae0acf789e70d424",
            "max": 551,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d251e2765314ab48496da58dd6a3ad8",
            "value": 551
          }
        },
        "4745fc0b121e40b0a6d65fc16c1f03db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e34e106347004fd5aa7ea4b53b0c42ea",
            "placeholder": "​",
            "style": "IPY_MODEL_18c4af60f2b94dadacff2e8a877e3ddd",
            "value": " 551/551 [00:00&lt;00:00, 56.0kB/s]"
          }
        },
        "4bf054390f284e079afc75dc0affdfd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b380a4366450409787ca7a57f1d18862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "239e1737a85b49d9825211c35c85767e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa746a7fad784f1fae0acf789e70d424": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d251e2765314ab48496da58dd6a3ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e34e106347004fd5aa7ea4b53b0c42ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18c4af60f2b94dadacff2e8a877e3ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2c13d296f784cb2a91b44346e276985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3097ee6d1585414db1d6708c442d287a",
              "IPY_MODEL_8441c42e32a44e50a1b2a469a4e187cd",
              "IPY_MODEL_75e6339057d94874a8255788cac53983"
            ],
            "layout": "IPY_MODEL_d5541991dea549ad9060e10129c8172b"
          }
        },
        "3097ee6d1585414db1d6708c442d287a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ac275c336454566b011911f919b8b01",
            "placeholder": "​",
            "style": "IPY_MODEL_e5e296dcf859428d82e68d820ff88a0d",
            "value": "tokenizer.json: 100%"
          }
        },
        "8441c42e32a44e50a1b2a469a4e187cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9852fdd66b0455b8c7c28d947fe05ff",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92ef27ff960840a9b84d6c9c47516bae",
            "value": 1842767
          }
        },
        "75e6339057d94874a8255788cac53983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c0375fa74f646ddb4c9d32373df23e6",
            "placeholder": "​",
            "style": "IPY_MODEL_1021ee65e4e345e3971aa5efff1aa0a9",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 8.22MB/s]"
          }
        },
        "d5541991dea549ad9060e10129c8172b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ac275c336454566b011911f919b8b01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5e296dcf859428d82e68d820ff88a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9852fdd66b0455b8c7c28d947fe05ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92ef27ff960840a9b84d6c9c47516bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c0375fa74f646ddb4c9d32373df23e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1021ee65e4e345e3971aa5efff1aa0a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "feb3b8913f244be5bd9e3c2828aa40f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6c2bf78a7e64505aa2d419864cacea8",
              "IPY_MODEL_2ef38bbda0c743f6ae59f70a2bae3a53",
              "IPY_MODEL_e527cd3bbda4408a8d6807e729ffeaf5"
            ],
            "layout": "IPY_MODEL_cb8bc619bf29406893903d7b42e615a0"
          }
        },
        "a6c2bf78a7e64505aa2d419864cacea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1f5a1a0357244c4b8a0152279ab5b5c",
            "placeholder": "​",
            "style": "IPY_MODEL_7923ebaa7f0c466a88e88a6cc44dc961",
            "value": "config.json: 100%"
          }
        },
        "2ef38bbda0c743f6ae59f70a2bae3a53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9adfd19453804f0883c2955cc0be9f6c",
            "max": 608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_689a6d3ba8384cb087c95eb604d3abfe",
            "value": 608
          }
        },
        "e527cd3bbda4408a8d6807e729ffeaf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa4b9a508b674e6683f21afec5ff4c7d",
            "placeholder": "​",
            "style": "IPY_MODEL_92978d07db014c869babbfbc2452ae61",
            "value": " 608/608 [00:00&lt;00:00, 34.5kB/s]"
          }
        },
        "cb8bc619bf29406893903d7b42e615a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1f5a1a0357244c4b8a0152279ab5b5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7923ebaa7f0c466a88e88a6cc44dc961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9adfd19453804f0883c2955cc0be9f6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "689a6d3ba8384cb087c95eb604d3abfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa4b9a508b674e6683f21afec5ff4c7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92978d07db014c869babbfbc2452ae61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2de8beb5f3f24a4ba7a90490ea61551f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a5ffdfd9bd948259a4ed1b4ebb0969c",
              "IPY_MODEL_69a2662320ff4ea8a76c856e4cdab3e3",
              "IPY_MODEL_f50d73de4e6b4364a08aa178c1dd2248"
            ],
            "layout": "IPY_MODEL_e924c918453d4d8cac0fadbed031bb38"
          }
        },
        "6a5ffdfd9bd948259a4ed1b4ebb0969c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bfae5b88e3a432387a47a85ed486884",
            "placeholder": "​",
            "style": "IPY_MODEL_e18c54eb6cb24c4394249459779c2d7d",
            "value": "model.safetensors: 100%"
          }
        },
        "69a2662320ff4ea8a76c856e4cdab3e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43be75df609c4b778d7d80732ffa1609",
            "max": 2200119864,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a38bfdf30ee74cfbbb7ccf4c774875e2",
            "value": 2200119864
          }
        },
        "f50d73de4e6b4364a08aa178c1dd2248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9997ae011fa64793b7d55ee91030a020",
            "placeholder": "​",
            "style": "IPY_MODEL_1ff26ab8d19046ba93dd6f4b3444482e",
            "value": " 2.20G/2.20G [00:18&lt;00:00, 203MB/s]"
          }
        },
        "e924c918453d4d8cac0fadbed031bb38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bfae5b88e3a432387a47a85ed486884": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e18c54eb6cb24c4394249459779c2d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43be75df609c4b778d7d80732ffa1609": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a38bfdf30ee74cfbbb7ccf4c774875e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9997ae011fa64793b7d55ee91030a020": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ff26ab8d19046ba93dd6f4b3444482e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fb745766b4640e5a80142c2f730ee3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e395cb1b63c0457eabdc8f0f19da63e0",
              "IPY_MODEL_b01fc93999b944a088d3d2a9559b5643",
              "IPY_MODEL_92d7e700d715475588d44efad420ccf6"
            ],
            "layout": "IPY_MODEL_9ad768b54ed949bba83bca5904374514"
          }
        },
        "e395cb1b63c0457eabdc8f0f19da63e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62817b806c9d4caa8e4d8f83a156c519",
            "placeholder": "​",
            "style": "IPY_MODEL_61bf0e49bd1a4df482b6cabb00a5c1e3",
            "value": "generation_config.json: 100%"
          }
        },
        "b01fc93999b944a088d3d2a9559b5643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df691eaded384c6c943d6ef882b8cad6",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b30afc0f4034e8d882000507f4ac277",
            "value": 124
          }
        },
        "92d7e700d715475588d44efad420ccf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a365d42dbdf04909a853fa41d28c5804",
            "placeholder": "​",
            "style": "IPY_MODEL_07f2ca0f6fcd40d58e0e7b8f1f7e8780",
            "value": " 124/124 [00:00&lt;00:00, 9.34kB/s]"
          }
        },
        "9ad768b54ed949bba83bca5904374514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62817b806c9d4caa8e4d8f83a156c519": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61bf0e49bd1a4df482b6cabb00a5c1e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df691eaded384c6c943d6ef882b8cad6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b30afc0f4034e8d882000507f4ac277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a365d42dbdf04909a853fa41d28c5804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07f2ca0f6fcd40d58e0e7b8f1f7e8780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvlymo1QH8kX",
        "outputId": "81231eba-e486-4db5-8bfb-19f77bc78b70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers datasets sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"GPU Available:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k18FBoKKILp1",
        "outputId": "9f5d0303-7ac7-41c0-8ad0-2b534361ca58"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CustomLLM(nn.Module):\n",
        "    def __init__(self, vocab_size=32000, d_model=768, num_heads=8, num_layers=8, ff_dim=3072):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "        # ✅ Fix: Use batch_first=True\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=ff_dim,\n",
        "            batch_first=True  # ✅ Fix: Better inference performance\n",
        "        )\n",
        "\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
        "        self.fc = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.transformer(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "# ✅ Instantiate model and move to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CustomLLM().to(device)\n",
        "\n",
        "# ✅ Check parameter count\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total Parameters: {total_params / 1e6:.2f}M\")  # Convert to million\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6K5FSuPIQ9i",
        "outputId": "4a297fa2-856d-47df-abff-c90c085e6fc7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Parameters: 105.89M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")  # Wikipedia dataset\n",
        "print(dataset[\"train\"][0][\"text\"])  # Sample text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363,
          "referenced_widgets": [
            "536bbd4f9d9a4dae84f4cd117507ef8f",
            "827048c2f2ea453a86e0a1457e3ab98b",
            "6c230d8949374ecdba5cabcf58653a20",
            "a606d875b90f41b2bc4c315910da8501",
            "0d50b193594d408c8c035b81d565484d",
            "c485fbd3d0d54c0698d16766a4543742",
            "774ae5fb84114ee3bf8735e0e11c23e4",
            "3f907fa7065b46dd96864df818087336",
            "3d6a07bac37e435cb312418413ac2d47",
            "b8f07bde87574731903a06630f15470a",
            "6e38b8ac0860400797d2b9495ee9a0f5",
            "5b8a9207b1d9419ebe7e5e3060ea8aa0",
            "75f3865a0f1e4d98baf9c3bcc3949f99",
            "7b6425481eef4af6badb191c15682b0e",
            "1a122848ca5448e1a16574e73367366a",
            "5fb59fe14ec44f2ea6738e9b47438ebb",
            "63753fe89da44919b74febd863535679",
            "189f0d3062c24d6fa7f8d64261520d12",
            "e9876244a5f3403b8e3530555de584aa",
            "57029ed61e77438c9ed90d8218d5fb34",
            "1d232dafab814c2497796713987acac7",
            "620276cff6e1481da44ca422459f8dc6",
            "ebe1b765189b4a0d86bb43bf898fb92b",
            "be8cf3f1c4ec456f8f89709baed70a57",
            "9683ea64da0943838e7282a47aedc978",
            "fba5467fb87e4d64ab733d67000c96c0",
            "0f97c3ac8f194414b6256669b046a1cc",
            "c976351aed424abb8db1e44ec8c7c714",
            "90d22cd398ad4431a35a223aa657f624",
            "a18834ca90c1404cafd15a66742882bc",
            "d7c216e11a544d57b74b37e9faaf9aaa",
            "ccf9d8759c794eeea73a4f51c0b72900",
            "7391b82a402240fa9d26025dc6dc63f9",
            "73fef4b00a8c4dac8dc70c203dc64b92",
            "f9395ca6c3084d8f9c4ac76c8a325a02",
            "b14cff3dbda04ee98d3b9aea508b664a",
            "64a415e282a14e6f83f69a41ab90e279",
            "b8a92af712634b43a4ff9d104db05976",
            "295eb816a3ec4184b6070454bd5d282d",
            "030080d788d3482cb5e402a41a00e87d",
            "c035a2e225cb45e29fec3f9350252122",
            "8322480b6c794c23bd7411938feb66f2",
            "5311f45ad4e640a19d329a3975d7563a",
            "23d4bf5d7a09483f8737244105601a21",
            "9b9b9d68f43c4abb8a10010da5e96eb3",
            "01ebffd4084740e988790caccb3b998d",
            "ecb558ff6abf4f91aacf226188cf1101",
            "66ee1da365474fc993caa1f75712a3df",
            "c60cfcc00a5b4c7cbb5872175e4c5f53",
            "66cb2114fbc84d6a90f12f63befcc861",
            "de90c22a6b0e4e4ba41ea8d793e3eb4b",
            "08d2a3c20252467c9fa82535a5bd1e08",
            "4659665e029a45d9b7fa177831df323b",
            "3fcbe876ec3944a9956c8cdd2110f064",
            "b442131657294e37b22e06e2261ab074",
            "dbc55dc5fef04c6ca20196a13317088f",
            "74defcf547384e04a9727e16e64bd522",
            "4e59af71b85649a09f4101a4fb6e61f2",
            "acc276708088402eb94d332eb3bceaf3",
            "b86f8740ddc54c3bac6a14c7ac496104",
            "cb62f4c2298b4b9692e802adf126f293",
            "f38b5ddf625049248276204f01aaaf2a",
            "b8e0cb17545d4a45bc1ef2ccb1cba5ba",
            "3aa4f36da0a6434da75563755762fd07",
            "5e6c95d5a95d44f599563fb780869309",
            "0bf5252545ac47a68afe8c5e6f5c8818",
            "4d31c16fe66b4752846f2ca410670e51",
            "716194d342ae4f11894525c469e452da",
            "bc9c6afde29b4009b98210ce0326574a",
            "4ab511d0ac4b4b55ae6d04657c0cfae8",
            "f7149e15972a43a18e819b8ecba52edf",
            "40b3f408fe454a1a907f36d23469a251",
            "16f3286c4f76431ab10aa441786eab8d",
            "6ebddcae99444efd898722ff7ee617f0",
            "6f7b6cb614974caa950ce816ed7ecd97",
            "1d4bb0556d9545f2a62bc1c08845975b",
            "65f670306e664758b956f6ba42759670"
          ]
        },
        "id": "hhmFwgUpIWq1",
        "outputId": "13de9f7d-4aa1-4020-d1ec-c626ba420778"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "536bbd4f9d9a4dae84f4cd117507ef8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/733k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b8a9207b1d9419ebe7e5e3060ea8aa0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/6.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebe1b765189b4a0d86bb43bf898fb92b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/657k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73fef4b00a8c4dac8dc70c203dc64b92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b9b9d68f43c4abb8a10010da5e96eb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbc55dc5fef04c6ca20196a13317088f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d31c16fe66b4752846f2ca410670e51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save model\n",
        "model_path = \"/content/drive/MyDrive/LLM/custom_llm.pth\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(\"Model saved to Google Drive!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWgEIiHKIYeR",
        "outputId": "f138fcb3-9315-40b7-85cf-cfadf56d20b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Model saved to Google Drive!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Day-2**"
      ],
      "metadata": {
        "id": "lDTsVc5ZNNKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Day-2\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
        "\n",
        "train_text_file = \"/content/wikitext_train.txt\"\n",
        "with open(train_text_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    for example in dataset[\"train\"]:\n",
        "        f.write(example[\"text\"] + \"\\n\")\n",
        "\n",
        "print(f\"Training text saved to {train_text_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnKaFO_FK2mw",
        "outputId": "17f6d98a-d57c-482e-a2db-77f2f7ca1866"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training text saved to /content/wikitext_train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "spm.SentencePieceTrainer.train(\n",
        "    input=train_text_file,\n",
        "    model_prefix=\"mytokenizer\",\n",
        "    vocab_size=32000,\n",
        "    model_type=\"bpe\",\n",
        "    character_coverage=1.0,\n",
        "    max_sentence_length=10000\n",
        ")\n",
        "\n",
        "print(\"Tokenizer training complete!\")"
      ],
      "metadata": {
        "id": "IFBeaHRyK9yp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c0509f-7855-44ff-9166-f9137ed7e58d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sp = spm.SentencePieceProcessor(model_file=\"mytokenizer.model\")\n",
        "\n",
        "# Test it\n",
        "sample_text = \"Hello, I am building an LLM from scratch!\"\n",
        "tokens = sp.encode(sample_text, out_type=str)\n",
        "token_ids = sp.encode(sample_text, out_type=int)\n",
        "\n",
        "print(\"Tokens:\", tokens)\n",
        "print(\"Token IDs:\", token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_L_O1zcLZvQ",
        "outputId": "28a14ef7-1251-4f52-aaa4-dd21bf37e850"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['▁Hell', 'o', ',', '▁I', '▁am', '▁building', '▁an', '▁L', 'L', 'M', '▁from', '▁scratch', '!']\n",
            "Token IDs: [6064, 31014, 31029, 74, 586, 1830, 134, 125, 31057, 31042, 148, 19500, 31091]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tokenize_function(examples):\n",
        "\n",
        "    if examples[\"text\"].strip():\n",
        "        return {\"input_ids\": sp.encode(examples[\"text\"], out_type=int)}\n",
        "    else:\n",
        "        return {\"input_ids\": []}\n",
        "\n",
        "\n",
        "tokenized_dataset = dataset.map(\n",
        "    tokenize_function,\n",
        "    remove_columns=[\"text\"],\n",
        "    desc=\"Tokenizing dataset\"\n",
        ")\n",
        "\n",
        "\n",
        "tokenized_dataset = tokenized_dataset.filter(\n",
        "    lambda example: len(example[\"input_ids\"]) > 0,\n",
        "    desc=\"Filtering empty examples\"\n",
        ")\n",
        "\n",
        "print(\"Dataset tokenized and filtered!\")\n",
        "print(\"First example:\", tokenized_dataset[\"train\"][0])\n",
        "\n",
        "\n",
        "original_count = len(dataset[\"train\"])\n",
        "filtered_count = len(tokenized_dataset[\"train\"])\n",
        "print(f\"Original rows: {original_count}, Filtered rows: {filtered_count}, Empty rows removed: {original_count - filtered_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261,
          "referenced_widgets": [
            "b1a0e34d71014ac4ae36c3b817a634a5",
            "ba774e82f7904b04aee1b1a72591905c",
            "c2e3a74bac95475287f9b0d78d5e7d3f",
            "3a1771d51cd84676be26696cdfa3ebe2",
            "ed76d5f54f81494ab10acded85170071",
            "9c74a0f176464190952e0072fb03cc87",
            "f67790fc39304678beebe927ec23fe12",
            "96ae4d470b3042788fe45b05c7fd0396",
            "fcb0afe9dac54e09b7d6332022b45e82",
            "37f8c95e98e24c3ea34501209d7b40dd",
            "dfbf1f1ba2c24373ae1dccc0af138e1d",
            "b064ebaf32e445b290583af749bdcdd6",
            "f1fbbb3b6a6a4387b29192d5d8a5cd68",
            "23c933031faa4b979a9d6c931de726fd",
            "285b37ff2c7a4128a039160eb07d0daa",
            "63936513fd744fe9a03712d6ee25c80a",
            "3505a1db03c7474f87268a0d761aeb14",
            "63895d357a8646af98e74673b967db25",
            "bb4acf90f2f54f3abe2000719d71abd4",
            "56397e1d2b244612bf16211ab92fb791",
            "4a70b2cb1e474f9ca9715053d040757f",
            "0754632694f14643a75d8d7b2278fd8f",
            "14decca3db5d4b5e89e6d0485131c794",
            "f6b59725c711451bbfe15979f7f9b945",
            "b8bfaedbaed7492fb2798d5afbf7301a",
            "6a044d1224ad40c280a10aebf82e102c",
            "48a2f57e4ebf416c873d81acb4067b03",
            "2bb7b359ed1c4fac9efaefde0b00d20c",
            "4a86cbf4a2d34690b94ac8f8034d398b",
            "2381755cc7ae4399a60fa86586fc5844",
            "3d613c953b514230b26fcb4a24d9a48b",
            "38ed302edc59435b911e46a552c90c50",
            "0493c4908c634c238c49bdc7cddde28d",
            "c3cb8fdd22a14ad698234ffafb0927c4",
            "93b147b8d3ec4433b8024430d267600a",
            "cdf708a423284bb9adaf0923f2c4ff37",
            "2e35a52749194040aa04da3aa48ab429",
            "8201bbe3ff7a4023bc6ce7198c47729b",
            "feb4f89fe6564c10b02e310c75d5cf85",
            "a9ec911a9b8c4a32ab1d585f9b5ba383",
            "fb4de201419c4246876073b43f3c6557",
            "205a1f6d5eaa4150bc14a132847936b7",
            "a2cdb111319b4312a5eaf65781626332",
            "3298509c78104d61a71762443a010fe6",
            "4862ff4488be4019b30a42dd35f24469",
            "8494633f990a49d4a03c83885686403f",
            "7a4362ac58b34eefa5adbc16bbbd5526",
            "63dbdfb932ae47c2b605ddb7dc575403",
            "5712f16f2d6340968ad3145f6d4f6e59",
            "12e69714b0104b51a7ba54eb6a543980",
            "e3fb2328b22c4602ba98212ed2a30255",
            "c799189e98e94dd0a8466dec3aa5bb1e",
            "72a0e5ca017046d79e5d0480a7831fe9",
            "9b1fa170c7d0494ea94f24d13b3c3ae5",
            "688e30f4c11e4674a4beb1e14790c3db",
            "764544c792034bf7b48a49d80e999d85",
            "9ecc751648004284b27d77ae33700315",
            "f481a209c86b459e83c83de0a921c7e5",
            "ec95ade0677343429d9594dcbacb7492",
            "081a796bde454ec784ac62f7c24381dc",
            "7d0916bdaa3344168f832b39f2da9749",
            "3232ef5d70824852ab90a535dfa3ecdb",
            "81855616304f466ebe1f516afd8a8599",
            "6fc9fbccdff54dcdbbcb8eda65950724",
            "52c816d244234877b975382661a73068",
            "d411b414cca042ea8eec81af1b07e7fd"
          ]
        },
        "id": "zsxZqIKoLbGS",
        "outputId": "e72cda0a-fd4e-4f02-a969-0f2cff6c3da9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing dataset:   0%|          | 0/4358 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1a0e34d71014ac4ae36c3b817a634a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing dataset:   0%|          | 0/36718 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b064ebaf32e445b290583af749bdcdd6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing dataset:   0%|          | 0/3760 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14decca3db5d4b5e89e6d0485131c794"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filtering empty examples:   0%|          | 0/4358 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3cb8fdd22a14ad698234ffafb0927c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filtering empty examples:   0%|          | 0/36718 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4862ff4488be4019b30a42dd35f24469"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filtering empty examples:   0%|          | 0/3760 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "764544c792034bf7b48a49d80e999d85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset tokenized and filtered!\n",
            "First example: {'input_ids': [47, 8330, 9206, 2779, 47]}\n",
            "Original rows: 36718, Filtered rows: 23767, Empty rows removed: 12951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "tokenized_dataset.save_to_disk(\"/content/drive/MyDrive/LLM/tokenized_wikitext\")\n",
        "\n",
        "import shutil\n",
        "shutil.copy(\"mytokenizer.model\", \"/content/drive/MyDrive/LLM/mytokenizer.model\")\n",
        "shutil.copy(\"mytokenizer.vocab\", \"/content/drive/MyDrive/LLM/mytokenizer.vocab\")\n",
        "\n",
        "print(\"Tokenized dataset and tokenizer saved to Google Drive!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148,
          "referenced_widgets": [
            "42f83158948f413192905cd5fe431e92",
            "7f16002efbb8478bbf8e15aa11036bca",
            "20de2a1b869144888c9fa7f7ae6d103a",
            "fa51b611a92c4f4ba92da915a268e865",
            "9eccf4ecef374e4b92166b704234a4da",
            "288f4cd5e0cc4d338ea468d335498f3f",
            "9fdbdc4591f24e439e2853b01fcda60f",
            "1cb66fa466c54ed3a744216f351aff8b",
            "82da42920adb4a7394df504936b95b82",
            "24ed3c66180946e08fa830fdbb67da32",
            "c592eb227e4e4fec9eaf5019f0378ef9",
            "bad0f76d32de4cb78101dc2cfa511df9",
            "c15231678b6b4e0ab6b67e0d1de36915",
            "a1b757abb1f94734abc568f2c0ab447b",
            "5546e29df09440e790796a5d9d48bf3f",
            "a9446b48b9a44fd2aa4cfb1b21ffe96d",
            "d0dfac3561884c99ab4cac1bf66ed45c",
            "effef65dffb246a89be7fd4d29b0799d",
            "2db4fc6e568b4799bb8aefffd498594e",
            "5837210b97be4e20a492ad7bdc83e5cc",
            "922ab780037e4b7da19d74b69bb4a86f",
            "5b43dfe3e4c547a9ad2845aac03f54dc",
            "2e82ea79dffe472e8d592141c7b80626",
            "621b4f7f4bb8449793c96e064eb30d3c",
            "b8fe3f43cecc4c15b88a6dd4382316ce",
            "1df4c9855c464c1b92d60314a1d95d46",
            "6a4fc30c902248f8b8db2a3e872e5074",
            "05dda977ec75464abcb74c89ba67f8a7",
            "64ca6d8f4a1e4fd88bcede93eecb7257",
            "90ad64fad7e74f2bb0fd8935bc70118c",
            "df4bd850f4284c33af619a06da796814",
            "38cee70ebeca44478a512224d833a442",
            "6c2f437e58be45cabf6a6cb68e7d5075"
          ]
        },
        "id": "YE5TAPw7Lgp0",
        "outputId": "b266843f-18f3-435d-b485-27405cc0e9ce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/2891 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42f83158948f413192905cd5fe431e92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/23767 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bad0f76d32de4cb78101dc2cfa511df9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/2461 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e82ea79dffe472e8d592141c7b80626"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized dataset and tokenizer saved to Google Drive!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Day 3: Data Pipeline & Preprocessing Starts Here\n",
        "from datasets import load_from_disk\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "QDGErx20M535"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = load_from_disk(\"/content/drive/MyDrive/LLM/tokenized_wikitext\")\n",
        "print(\"Tokenized dataset loaded from Google Drive!\")\n",
        "print(\"First example:\", tokenized_dataset[\"train\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpJ1qVpvOXNk",
        "outputId": "c99edcf4-523d-4335-8d76-7b8691ed8841"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized dataset loaded from Google Drive!\n",
            "First example: {'input_ids': [47, 8330, 9206, 2779, 47]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LLMDataset(Dataset):\n",
        "    def __init__(self, tokenized_data, max_length=128):\n",
        "        self.data = tokenized_data\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_ids = self.data[idx][\"input_ids\"]\n",
        "\n",
        "        if len(input_ids) > self.max_length:\n",
        "            input_ids = input_ids[:self.max_length]\n",
        "        else:\n",
        "            input_ids = input_ids + [0] * (self.max_length - len(input_ids))\n",
        "\n",
        "\n",
        "        input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
        "\n",
        "        return input_ids"
      ],
      "metadata": {
        "id": "aNPvzgQVOb06"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = LLMDataset(tokenized_dataset[\"train\"], max_length=128)\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "\n",
        "for batch in train_dataloader:\n",
        "    print(\"Batch shape:\", batch.shape)\n",
        "    print(\"First batch example:\", batch[0])\n",
        "    break\n",
        "\n",
        "print(\"DataLoader ready for training!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWmDoMSrOepW",
        "outputId": "49753269-bbbd-4582-9557-9b5c8014db97"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shape: torch.Size([16, 128])\n",
            "First batch example: tensor([ 4820,  1751,    34, 19636,    48, 11067,    10,    48,     7,  1504,\n",
            "          204,  2742,  1422,   619,  1388,    82,     7,   607,    18,  2389,\n",
            "           89,   349,  1699,   130,    66,  1835,  1085,    82,     7,   453,\n",
            "           76, 31016,  9200,    30,     7,   607,    10,  1016,    49, 12707,\n",
            "         4105,  7633,  1802,    69,  5359,    66, 29365,  6925,    10,   349,\n",
            "         1358,     5, 14288,    34,  7722,   130,   104,   354, 18927,  3722,\n",
            "           10,  4685,    32,   130,    48,  5475,    82,  5557,   234,   246,\n",
            "           48,     7,  1504, 13432,   828,  3722,    82,  1047,   408,   101,\n",
            "          250,  1174,   607,    18,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "DataLoader ready for training!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Train the Model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import time\n",
        "from google.colab import drive\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CustomLLM().to(device)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/LLM/custom_llm.pth\", map_location=device))\n",
        "print(\"Model loaded from Google Drive!\")\n",
        "\n",
        "\n",
        "from datasets import load_from_disk\n",
        "tokenized_dataset = load_from_disk(\"/content/drive/MyDrive/LLM/tokenized_wikitext\")\n",
        "\n",
        "\n",
        "train_subset = Subset(LLMDataset(tokenized_dataset[\"train\"], max_length=128), indices=range(1000))\n",
        "train_dataloader = DataLoader(train_subset, batch_size=16, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "num_epochs = 2\n",
        "model.train()\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_start_time = time.time()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        inputs = batch[:, :-1]\n",
        "        targets = batch[:, 1:]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "\n",
        "        loss = criterion(outputs.view(-1, 32000), targets.reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "        memory_used = torch.cuda.memory_allocated(device) / 1e6\n",
        "        print(f\"Batch {num_batches}, Loss: {loss.item():.4f}, Memory Used: {memory_used:.2f} MB\")\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    epoch_time = time.time() - epoch_start_time\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Avg Loss: {avg_loss:.4f}, Time: {epoch_time:.2f}s, Speed: {len(train_subset)/epoch_time:.2f} examples/s\")\n",
        "\n",
        "    # checkpoint\n",
        "    checkpoint_path = f\"/content/drive/MyDrive/LLM/custom_llm_epoch_{epoch+1}.pth\"\n",
        "    torch.save(model.state_dict(), checkpoint_path)\n",
        "    print(f\"Checkpoint saved to {checkpoint_path}\")\n",
        "\n",
        "print(\"Initial training phase complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2rbVAVtOsv7",
        "outputId": "20cb8fda-bba7-4c59-94fe-abc85c87e1db"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from Google Drive!\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Batch 1, Loss: 10.5174, Memory Used: 1977.98 MB\n",
            "Batch 2, Loss: 10.1157, Memory Used: 1978.13 MB\n",
            "Batch 3, Loss: 9.8719, Memory Used: 1978.13 MB\n",
            "Batch 4, Loss: 9.7171, Memory Used: 1978.13 MB\n",
            "Batch 5, Loss: 9.5270, Memory Used: 1978.13 MB\n",
            "Batch 6, Loss: 9.4329, Memory Used: 1978.13 MB\n",
            "Batch 7, Loss: 9.3925, Memory Used: 1978.13 MB\n",
            "Batch 8, Loss: 9.2014, Memory Used: 1978.13 MB\n",
            "Batch 9, Loss: 9.0870, Memory Used: 1978.13 MB\n",
            "Batch 10, Loss: 9.1303, Memory Used: 1978.13 MB\n",
            "Batch 11, Loss: 8.9499, Memory Used: 1978.13 MB\n",
            "Batch 12, Loss: 8.8763, Memory Used: 1978.13 MB\n",
            "Batch 13, Loss: 9.1004, Memory Used: 1978.13 MB\n",
            "Batch 14, Loss: 8.8827, Memory Used: 1978.13 MB\n",
            "Batch 15, Loss: 8.7009, Memory Used: 1978.13 MB\n",
            "Batch 16, Loss: 8.7116, Memory Used: 1978.13 MB\n",
            "Batch 17, Loss: 8.7041, Memory Used: 1978.13 MB\n",
            "Batch 18, Loss: 8.7847, Memory Used: 1978.13 MB\n",
            "Batch 19, Loss: 8.7335, Memory Used: 1978.13 MB\n",
            "Batch 20, Loss: 8.7126, Memory Used: 1978.13 MB\n",
            "Batch 21, Loss: 8.7586, Memory Used: 1978.13 MB\n",
            "Batch 22, Loss: 8.7258, Memory Used: 1978.13 MB\n",
            "Batch 23, Loss: 8.6531, Memory Used: 1978.13 MB\n",
            "Batch 24, Loss: 8.5580, Memory Used: 1978.13 MB\n",
            "Batch 25, Loss: 8.6449, Memory Used: 1978.13 MB\n",
            "Batch 26, Loss: 8.2833, Memory Used: 1978.13 MB\n",
            "Batch 27, Loss: 8.5453, Memory Used: 1978.13 MB\n",
            "Batch 28, Loss: 8.3599, Memory Used: 1978.13 MB\n",
            "Batch 29, Loss: 8.5486, Memory Used: 1978.13 MB\n",
            "Batch 30, Loss: 8.4511, Memory Used: 1978.13 MB\n",
            "Batch 31, Loss: 8.5015, Memory Used: 1978.13 MB\n",
            "Batch 32, Loss: 8.2189, Memory Used: 1978.13 MB\n",
            "Batch 33, Loss: 8.3864, Memory Used: 1978.13 MB\n",
            "Batch 34, Loss: 8.0698, Memory Used: 1978.13 MB\n",
            "Batch 35, Loss: 8.2487, Memory Used: 1978.13 MB\n",
            "Batch 36, Loss: 8.3265, Memory Used: 1978.13 MB\n",
            "Batch 37, Loss: 8.2292, Memory Used: 1978.13 MB\n",
            "Batch 38, Loss: 8.4400, Memory Used: 1978.13 MB\n",
            "Batch 39, Loss: 7.9675, Memory Used: 1978.13 MB\n",
            "Batch 40, Loss: 8.1884, Memory Used: 1978.13 MB\n",
            "Batch 41, Loss: 8.2444, Memory Used: 1978.13 MB\n",
            "Batch 42, Loss: 8.1637, Memory Used: 1978.13 MB\n",
            "Batch 43, Loss: 8.0469, Memory Used: 1978.13 MB\n",
            "Batch 44, Loss: 8.0796, Memory Used: 1978.13 MB\n",
            "Batch 45, Loss: 7.8252, Memory Used: 1978.13 MB\n",
            "Batch 46, Loss: 8.1274, Memory Used: 1978.13 MB\n",
            "Batch 47, Loss: 8.1569, Memory Used: 1978.13 MB\n",
            "Batch 48, Loss: 7.9640, Memory Used: 1978.13 MB\n",
            "Batch 49, Loss: 7.9213, Memory Used: 1978.13 MB\n",
            "Batch 50, Loss: 7.8633, Memory Used: 1978.13 MB\n",
            "Batch 51, Loss: 8.0400, Memory Used: 1978.13 MB\n",
            "Batch 52, Loss: 7.9872, Memory Used: 1978.13 MB\n",
            "Batch 53, Loss: 7.9100, Memory Used: 1978.13 MB\n",
            "Batch 54, Loss: 7.6873, Memory Used: 1978.13 MB\n",
            "Batch 55, Loss: 7.7691, Memory Used: 1978.13 MB\n",
            "Batch 56, Loss: 7.9554, Memory Used: 1978.13 MB\n",
            "Batch 57, Loss: 7.7159, Memory Used: 1978.13 MB\n",
            "Batch 58, Loss: 7.8334, Memory Used: 1978.13 MB\n",
            "Batch 59, Loss: 7.5533, Memory Used: 1978.13 MB\n",
            "Batch 60, Loss: 7.7563, Memory Used: 1978.13 MB\n",
            "Batch 61, Loss: 7.7973, Memory Used: 1978.13 MB\n",
            "Batch 62, Loss: 7.7743, Memory Used: 1978.13 MB\n",
            "Batch 63, Loss: 7.4888, Memory Used: 1850.69 MB\n",
            "Epoch 1/2, Avg Loss: 8.4749, Time: 20.73s, Speed: 48.24 examples/s\n",
            "Checkpoint saved to /content/drive/MyDrive/LLM/custom_llm_epoch_1.pth\n",
            "Batch 1, Loss: 7.6429, Memory Used: 1978.81 MB\n",
            "Batch 2, Loss: 7.6245, Memory Used: 1978.13 MB\n",
            "Batch 3, Loss: 7.4402, Memory Used: 1978.13 MB\n",
            "Batch 4, Loss: 7.4714, Memory Used: 1978.13 MB\n",
            "Batch 5, Loss: 7.5819, Memory Used: 1978.13 MB\n",
            "Batch 6, Loss: 7.3773, Memory Used: 1978.13 MB\n",
            "Batch 7, Loss: 7.6013, Memory Used: 1978.13 MB\n",
            "Batch 8, Loss: 7.3667, Memory Used: 1978.13 MB\n",
            "Batch 9, Loss: 7.4975, Memory Used: 1978.13 MB\n",
            "Batch 10, Loss: 7.4642, Memory Used: 1978.13 MB\n",
            "Batch 11, Loss: 7.4571, Memory Used: 1978.13 MB\n",
            "Batch 12, Loss: 7.3295, Memory Used: 1978.13 MB\n",
            "Batch 13, Loss: 7.2222, Memory Used: 1978.13 MB\n",
            "Batch 14, Loss: 7.4164, Memory Used: 1978.13 MB\n",
            "Batch 15, Loss: 7.2550, Memory Used: 1978.13 MB\n",
            "Batch 16, Loss: 7.3290, Memory Used: 1978.13 MB\n",
            "Batch 17, Loss: 7.3820, Memory Used: 1978.13 MB\n",
            "Batch 18, Loss: 7.1140, Memory Used: 1978.13 MB\n",
            "Batch 19, Loss: 7.3119, Memory Used: 1978.13 MB\n",
            "Batch 20, Loss: 7.3629, Memory Used: 1978.13 MB\n",
            "Batch 21, Loss: 7.1624, Memory Used: 1978.13 MB\n",
            "Batch 22, Loss: 7.2637, Memory Used: 1978.13 MB\n",
            "Batch 23, Loss: 7.0867, Memory Used: 1978.13 MB\n",
            "Batch 24, Loss: 7.1137, Memory Used: 1978.13 MB\n",
            "Batch 25, Loss: 7.2767, Memory Used: 1978.13 MB\n",
            "Batch 26, Loss: 7.3016, Memory Used: 1978.13 MB\n",
            "Batch 27, Loss: 7.0170, Memory Used: 1978.13 MB\n",
            "Batch 28, Loss: 7.2058, Memory Used: 1978.13 MB\n",
            "Batch 29, Loss: 7.3020, Memory Used: 1978.13 MB\n",
            "Batch 30, Loss: 7.1871, Memory Used: 1978.13 MB\n",
            "Batch 31, Loss: 7.0778, Memory Used: 1978.13 MB\n",
            "Batch 32, Loss: 7.1237, Memory Used: 1978.13 MB\n",
            "Batch 33, Loss: 7.2098, Memory Used: 1978.13 MB\n",
            "Batch 34, Loss: 7.1620, Memory Used: 1978.13 MB\n",
            "Batch 35, Loss: 7.3980, Memory Used: 1978.13 MB\n",
            "Batch 36, Loss: 7.0974, Memory Used: 1978.13 MB\n",
            "Batch 37, Loss: 7.0522, Memory Used: 1978.13 MB\n",
            "Batch 38, Loss: 7.1666, Memory Used: 1978.13 MB\n",
            "Batch 39, Loss: 7.1035, Memory Used: 1978.13 MB\n",
            "Batch 40, Loss: 6.9474, Memory Used: 1978.13 MB\n",
            "Batch 41, Loss: 6.9150, Memory Used: 1978.13 MB\n",
            "Batch 42, Loss: 7.0656, Memory Used: 1978.13 MB\n",
            "Batch 43, Loss: 7.1851, Memory Used: 1978.13 MB\n",
            "Batch 44, Loss: 7.2361, Memory Used: 1978.13 MB\n",
            "Batch 45, Loss: 7.0789, Memory Used: 1978.13 MB\n",
            "Batch 46, Loss: 7.0097, Memory Used: 1978.13 MB\n",
            "Batch 47, Loss: 7.0797, Memory Used: 1978.13 MB\n",
            "Batch 48, Loss: 6.9305, Memory Used: 1978.13 MB\n",
            "Batch 49, Loss: 6.9501, Memory Used: 1978.13 MB\n",
            "Batch 50, Loss: 7.3431, Memory Used: 1978.13 MB\n",
            "Batch 51, Loss: 6.9443, Memory Used: 1978.13 MB\n",
            "Batch 52, Loss: 6.9429, Memory Used: 1978.13 MB\n",
            "Batch 53, Loss: 6.9603, Memory Used: 1978.13 MB\n",
            "Batch 54, Loss: 7.1077, Memory Used: 1978.13 MB\n",
            "Batch 55, Loss: 6.8963, Memory Used: 1978.13 MB\n",
            "Batch 56, Loss: 7.1461, Memory Used: 1978.13 MB\n",
            "Batch 57, Loss: 6.6815, Memory Used: 1978.13 MB\n",
            "Batch 58, Loss: 6.9268, Memory Used: 1978.13 MB\n",
            "Batch 59, Loss: 6.9865, Memory Used: 1978.13 MB\n",
            "Batch 60, Loss: 7.0936, Memory Used: 1978.13 MB\n",
            "Batch 61, Loss: 7.0300, Memory Used: 1978.13 MB\n",
            "Batch 62, Loss: 6.9000, Memory Used: 1978.13 MB\n",
            "Batch 63, Loss: 7.3177, Memory Used: 1850.69 MB\n",
            "Epoch 2/2, Avg Loss: 7.1941, Time: 20.81s, Speed: 48.04 examples/s\n",
            "Checkpoint saved to /content/drive/MyDrive/LLM/custom_llm_epoch_2.pth\n",
            "Initial training phase complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Day-5"
      ],
      "metadata": {
        "id": "WiWgffYJPJcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Day 4: Continue Training (Scaling Up)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from datasets import load_from_disk\n",
        "from google.colab import drive\n",
        "import time\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CustomLLM().to(device)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/LLM/custom_llm_epoch_2.pth\", map_location=device))\n",
        "print(\"Model loaded from last checkpoint!\")\n",
        "\n",
        "tokenized_wikitext = load_from_disk(\"/content/drive/MyDrive/LLM/tokenized_wikitext\")\n",
        "train_dataset = LLMDataset(tokenized_wikitext[\"train\"], max_length=128)\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "\n",
        "accumulation_steps = 4\n",
        "effective_batch_size = 16\n",
        "\n",
        "\n",
        "num_epochs = 5\n",
        "total_steps = len(train_dataloader) * num_epochs // accumulation_steps\n",
        "warmup_steps = int(0.1 * total_steps)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=total_steps - warmup_steps, eta_min=1e-6)\n",
        "\n",
        "\n",
        "model.train()\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_start_time = time.time()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        batch = batch.to(device)\n",
        "        inputs = batch[:, :-1]\n",
        "        targets = batch[:, 1:]\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs.view(-1, 32000), targets.reshape(-1))\n",
        "        loss = loss / accumulation_steps\n",
        "        loss.backward()\n",
        "\n",
        "        total_loss += loss.item() * accumulation_steps\n",
        "\n",
        "        if (i + 1) % accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "            if num_batches < warmup_steps:\n",
        "                lr = 1e-5 + (5e-5 - 1e-5) * num_batches / warmup_steps\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = lr\n",
        "            else:\n",
        "                scheduler.step()\n",
        "\n",
        "            num_batches += 1\n",
        "            memory_used = torch.cuda.memory_allocated(device) / 1e6\n",
        "            print(f\"Step {num_batches}, Loss: {loss.item() * accumulation_steps:.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}, Memory: {memory_used:.2f} MB\")\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    epoch_time = time.time() - epoch_start_time\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Avg Loss: {avg_loss:.4f}, Time: {epoch_time:.2f}s, Speed: {len(train_dataset)/epoch_time:.2f} examples/s\")\n",
        "\n",
        "\n",
        "    checkpoint_path = f\"/content/drive/MyDrive/LLM/custom_llm_epoch_{epoch+3}.pth\"\n",
        "    torch.save(model.state_dict(), checkpoint_path)\n",
        "    print(f\"Model weights saved to {checkpoint_path}\")\n",
        "\n",
        "print(\"Scaled training phase complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx4bAYvAPLPZ",
        "outputId": "9567b0ad-4709-4c88-94e6-59578252439a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Step 950, Loss: 5.2103, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 951, Loss: 5.7046, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 952, Loss: 5.7154, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 953, Loss: 6.5561, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 954, Loss: 6.2218, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 955, Loss: 5.7063, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 956, Loss: 5.0465, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 957, Loss: 6.0546, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 958, Loss: 5.7800, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 959, Loss: 5.3047, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 960, Loss: 4.8480, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 961, Loss: 6.4239, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 962, Loss: 6.0752, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 963, Loss: 5.6873, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 964, Loss: 5.8344, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 965, Loss: 5.8425, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 966, Loss: 5.9652, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 967, Loss: 5.8169, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 968, Loss: 6.0288, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 969, Loss: 5.9142, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 970, Loss: 5.8099, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 971, Loss: 5.8449, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 972, Loss: 3.5066, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 973, Loss: 5.4910, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 974, Loss: 5.8114, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 975, Loss: 6.4070, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 976, Loss: 5.9214, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 977, Loss: 6.1313, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 978, Loss: 6.1953, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 979, Loss: 6.1220, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 980, Loss: 6.0900, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 981, Loss: 6.6873, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 982, Loss: 5.8692, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 983, Loss: 5.4896, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 984, Loss: 5.7560, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 985, Loss: 5.5455, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 986, Loss: 5.9264, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 987, Loss: 5.3510, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 988, Loss: 6.4155, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 989, Loss: 6.3016, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 990, Loss: 5.9678, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 991, Loss: 6.1249, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 992, Loss: 5.8735, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 993, Loss: 6.3614, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 994, Loss: 5.3777, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 995, Loss: 5.8731, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 996, Loss: 5.8613, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 997, Loss: 5.9618, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 998, Loss: 4.7967, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 999, Loss: 5.6922, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1000, Loss: 5.5187, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1001, Loss: 5.4355, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1002, Loss: 5.5709, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 1003, Loss: 5.5988, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 1004, Loss: 6.0475, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1005, Loss: 5.5228, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1006, Loss: 5.7677, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1007, Loss: 6.1816, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1008, Loss: 6.0791, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 1009, Loss: 5.7359, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 1010, Loss: 5.8522, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1011, Loss: 6.4767, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1012, Loss: 6.5886, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 1013, Loss: 5.4943, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 1014, Loss: 5.7590, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1015, Loss: 6.0843, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1016, Loss: 5.9372, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1017, Loss: 5.5458, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1018, Loss: 5.8826, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 1019, Loss: 4.5873, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1020, Loss: 6.1626, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1021, Loss: 5.9449, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1022, Loss: 5.7128, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 1023, Loss: 5.5699, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 1024, Loss: 6.1827, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1025, Loss: 6.2015, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1026, Loss: 6.2100, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1027, Loss: 6.4648, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 1028, Loss: 6.3432, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 1029, Loss: 6.2555, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1030, Loss: 5.9445, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1031, Loss: 5.2617, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1032, Loss: 6.0167, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 1033, Loss: 6.3513, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 1034, Loss: 6.2832, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1035, Loss: 6.2887, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1036, Loss: 6.7015, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1037, Loss: 5.7286, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 1038, Loss: 5.6593, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 1039, Loss: 5.5733, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1040, Loss: 5.9763, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1041, Loss: 5.8075, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 1042, Loss: 6.1939, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1043, Loss: 6.1999, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1044, Loss: 5.9289, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1045, Loss: 6.1975, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1046, Loss: 6.0244, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1047, Loss: 5.7897, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1048, Loss: 5.6558, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1049, Loss: 6.0921, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1050, Loss: 6.1409, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1051, Loss: 5.4855, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1052, Loss: 6.0785, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1053, Loss: 5.3069, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1054, Loss: 5.8605, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1055, Loss: 5.5652, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1056, Loss: 6.1424, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1057, Loss: 6.1685, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1058, Loss: 5.9729, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1059, Loss: 6.3241, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1060, Loss: 5.7852, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1061, Loss: 5.3349, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1062, Loss: 5.8294, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1063, Loss: 5.8743, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1064, Loss: 6.5422, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1065, Loss: 5.7303, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1066, Loss: 6.4331, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1067, Loss: 5.4536, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1068, Loss: 6.2308, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1069, Loss: 6.2965, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1070, Loss: 4.6625, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1071, Loss: 6.0646, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1072, Loss: 5.9189, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1073, Loss: 6.1348, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1074, Loss: 5.7377, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1075, Loss: 5.7175, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1076, Loss: 5.5525, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1077, Loss: 5.7329, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1078, Loss: 6.2151, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1079, Loss: 5.5298, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1080, Loss: 6.3124, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1081, Loss: 6.0331, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1082, Loss: 6.2809, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1083, Loss: 6.2225, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1084, Loss: 5.3227, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1085, Loss: 5.9481, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1086, Loss: 5.9438, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1087, Loss: 6.4886, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1088, Loss: 6.0639, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1089, Loss: 6.0551, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1090, Loss: 6.0579, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1091, Loss: 5.7670, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1092, Loss: 6.2748, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1093, Loss: 5.4113, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1094, Loss: 6.1901, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1095, Loss: 5.1910, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1096, Loss: 6.1376, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1097, Loss: 5.8656, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1098, Loss: 5.9120, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1099, Loss: 5.4767, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1100, Loss: 5.8096, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1101, Loss: 5.6637, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1102, Loss: 5.9391, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1103, Loss: 5.9840, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1104, Loss: 6.3682, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1105, Loss: 5.6908, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1106, Loss: 5.0804, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1107, Loss: 6.0520, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1108, Loss: 5.9172, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1109, Loss: 5.8486, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1110, Loss: 6.1833, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1111, Loss: 6.1662, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1112, Loss: 4.2903, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1113, Loss: 6.0762, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1114, Loss: 6.7762, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1115, Loss: 6.3410, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1116, Loss: 5.7003, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1117, Loss: 5.4956, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1118, Loss: 5.5157, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1119, Loss: 5.6820, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1120, Loss: 6.0457, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1121, Loss: 5.6202, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1122, Loss: 6.1457, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1123, Loss: 6.3953, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1124, Loss: 6.0410, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1125, Loss: 6.1060, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1126, Loss: 5.6508, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1127, Loss: 6.1227, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1128, Loss: 5.8456, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1129, Loss: 5.1598, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1130, Loss: 5.7742, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1131, Loss: 6.0168, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1132, Loss: 5.6387, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1133, Loss: 5.6090, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1134, Loss: 5.7939, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1135, Loss: 6.0976, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1136, Loss: 5.8448, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1137, Loss: 5.9403, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1138, Loss: 6.4583, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1139, Loss: 5.7593, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1140, Loss: 6.0546, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1141, Loss: 6.0983, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1142, Loss: 5.5044, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1143, Loss: 6.2198, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1144, Loss: 5.6266, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1145, Loss: 5.6499, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1146, Loss: 6.2927, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1147, Loss: 6.1461, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1148, Loss: 5.8555, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1149, Loss: 5.4339, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1150, Loss: 5.8976, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1151, Loss: 5.8980, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1152, Loss: 6.1022, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1153, Loss: 5.7644, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1154, Loss: 6.1375, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1155, Loss: 6.2197, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1156, Loss: 5.0702, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1157, Loss: 4.9286, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1158, Loss: 5.7711, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1159, Loss: 5.9068, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1160, Loss: 6.0263, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1161, Loss: 5.8651, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1162, Loss: 5.5960, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1163, Loss: 5.4639, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1164, Loss: 5.7312, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1165, Loss: 5.2497, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1166, Loss: 5.5118, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1167, Loss: 6.2732, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1168, Loss: 5.9163, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1169, Loss: 6.1635, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1170, Loss: 6.3925, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1171, Loss: 5.5184, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1172, Loss: 5.9616, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1173, Loss: 6.2079, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1174, Loss: 5.5660, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1175, Loss: 5.7981, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1176, Loss: 6.5049, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1177, Loss: 5.7541, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1178, Loss: 5.7729, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1179, Loss: 5.6624, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1180, Loss: 5.6047, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1181, Loss: 5.5899, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1182, Loss: 5.9281, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1183, Loss: 5.1874, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1184, Loss: 5.6075, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1185, Loss: 5.9333, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1186, Loss: 6.1840, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1187, Loss: 5.5575, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1188, Loss: 6.0479, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1189, Loss: 5.4113, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1190, Loss: 6.1704, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1191, Loss: 6.0250, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1192, Loss: 5.6740, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1193, Loss: 6.1828, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1194, Loss: 5.7103, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1195, Loss: 6.2199, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1196, Loss: 5.3053, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1197, Loss: 5.8264, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1198, Loss: 5.8935, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1199, Loss: 5.2522, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1200, Loss: 5.6420, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1201, Loss: 5.8359, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1202, Loss: 6.1878, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1203, Loss: 5.0128, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1204, Loss: 6.4515, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1205, Loss: 6.0178, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1206, Loss: 5.5922, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1207, Loss: 5.5675, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1208, Loss: 6.2311, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1209, Loss: 5.3735, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1210, Loss: 6.3764, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1211, Loss: 6.0124, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1212, Loss: 6.0632, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1213, Loss: 5.6600, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1214, Loss: 6.0990, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1215, Loss: 5.8326, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1216, Loss: 5.8527, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1217, Loss: 3.7936, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1218, Loss: 6.3299, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1219, Loss: 5.9406, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1220, Loss: 6.0344, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1221, Loss: 5.8284, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1222, Loss: 6.1598, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1223, Loss: 5.1111, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1224, Loss: 5.7905, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1225, Loss: 6.5033, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1226, Loss: 6.0172, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1227, Loss: 6.0116, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1228, Loss: 6.4293, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1229, Loss: 5.8974, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1230, Loss: 6.2049, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1231, Loss: 5.6932, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1232, Loss: 5.9149, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1233, Loss: 5.9568, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1234, Loss: 5.5745, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1235, Loss: 5.6980, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1236, Loss: 5.9184, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1237, Loss: 5.9205, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1238, Loss: 5.6598, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1239, Loss: 5.1767, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1240, Loss: 5.3397, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1241, Loss: 5.3676, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1242, Loss: 6.2255, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1243, Loss: 5.7872, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1244, Loss: 5.6808, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1245, Loss: 6.0043, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1246, Loss: 5.4844, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1247, Loss: 5.6827, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1248, Loss: 6.2766, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1249, Loss: 5.0425, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1250, Loss: 6.0678, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1251, Loss: 6.0331, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1252, Loss: 6.1948, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1253, Loss: 6.1541, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1254, Loss: 5.3381, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1255, Loss: 5.3210, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1256, Loss: 6.2171, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1257, Loss: 6.3733, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1258, Loss: 5.9995, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1259, Loss: 6.1580, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1260, Loss: 5.9467, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1261, Loss: 6.1229, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1262, Loss: 6.2251, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1263, Loss: 6.0925, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1264, Loss: 6.2288, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1265, Loss: 5.9612, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1266, Loss: 5.2812, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1267, Loss: 5.9964, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1268, Loss: 6.3913, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1269, Loss: 6.1906, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1270, Loss: 5.5405, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1271, Loss: 5.5032, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1272, Loss: 6.2743, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1273, Loss: 5.8584, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1274, Loss: 5.9188, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1275, Loss: 5.6504, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1276, Loss: 5.9514, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1277, Loss: 6.0311, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1278, Loss: 5.8729, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1279, Loss: 5.4792, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1280, Loss: 5.7625, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1281, Loss: 5.9115, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1282, Loss: 5.9634, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1283, Loss: 5.6235, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1284, Loss: 5.6189, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1285, Loss: 6.0043, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1286, Loss: 5.7268, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1287, Loss: 5.8208, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1288, Loss: 6.6461, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1289, Loss: 6.1057, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1290, Loss: 5.7384, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1291, Loss: 6.3116, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1292, Loss: 5.9309, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1293, Loss: 5.6093, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1294, Loss: 5.4952, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1295, Loss: 6.1558, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1296, Loss: 6.3455, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1297, Loss: 5.7624, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1298, Loss: 5.7079, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1299, Loss: 5.5894, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1300, Loss: 6.6058, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1301, Loss: 6.0035, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1302, Loss: 5.4839, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1303, Loss: 5.2877, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1304, Loss: 5.7193, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1305, Loss: 5.9427, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1306, Loss: 5.8712, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1307, Loss: 6.0806, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1308, Loss: 5.4394, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1309, Loss: 6.1371, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1310, Loss: 6.2857, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1311, Loss: 5.9103, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1312, Loss: 6.1557, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1313, Loss: 5.9800, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1314, Loss: 5.5015, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1315, Loss: 5.8133, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1316, Loss: 2.9136, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1317, Loss: 5.4576, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1318, Loss: 6.0117, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1319, Loss: 6.1710, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1320, Loss: 5.0710, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1321, Loss: 6.5331, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1322, Loss: 5.0315, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1323, Loss: 5.9929, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1324, Loss: 4.9263, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1325, Loss: 4.2378, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1326, Loss: 6.3060, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1327, Loss: 6.2010, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1328, Loss: 6.1223, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1329, Loss: 4.9284, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1330, Loss: 5.8661, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1331, Loss: 6.3836, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1332, Loss: 5.6880, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1333, Loss: 5.6879, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1334, Loss: 5.9950, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1335, Loss: 6.2398, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1336, Loss: 5.5353, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1337, Loss: 6.0010, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1338, Loss: 5.4805, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1339, Loss: 5.9162, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1340, Loss: 5.8571, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1341, Loss: 5.9170, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1342, Loss: 5.6012, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1343, Loss: 5.8342, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1344, Loss: 4.5086, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1345, Loss: 5.9441, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1346, Loss: 5.9666, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1347, Loss: 6.3328, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1348, Loss: 2.9499, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1349, Loss: 5.2094, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1350, Loss: 6.4824, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1351, Loss: 5.4319, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1352, Loss: 5.5597, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1353, Loss: 6.0289, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1354, Loss: 5.5239, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1355, Loss: 5.9836, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1356, Loss: 5.6780, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1357, Loss: 6.0183, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1358, Loss: 6.0248, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1359, Loss: 6.1182, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1360, Loss: 5.1894, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1361, Loss: 5.9501, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1362, Loss: 5.8481, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1363, Loss: 5.9564, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1364, Loss: 6.0117, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1365, Loss: 6.7343, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1366, Loss: 5.7664, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1367, Loss: 5.8176, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1368, Loss: 5.9108, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1369, Loss: 5.8964, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1370, Loss: 5.8250, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1371, Loss: 5.9396, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1372, Loss: 6.0121, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1373, Loss: 6.3778, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1374, Loss: 6.1671, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1375, Loss: 5.8003, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1376, Loss: 5.2064, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1377, Loss: 5.8707, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1378, Loss: 6.1015, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1379, Loss: 6.1435, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1380, Loss: 5.2893, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1381, Loss: 6.2677, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1382, Loss: 5.9943, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1383, Loss: 6.1434, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1384, Loss: 5.9380, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1385, Loss: 5.9282, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1386, Loss: 6.0149, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1387, Loss: 5.5376, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1388, Loss: 6.0461, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1389, Loss: 5.8806, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1390, Loss: 5.9315, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1391, Loss: 6.3824, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1392, Loss: 5.1359, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1393, Loss: 5.9677, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1394, Loss: 5.6665, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1395, Loss: 5.7852, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1396, Loss: 5.3072, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1397, Loss: 5.6230, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1398, Loss: 5.7535, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1399, Loss: 6.2609, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1400, Loss: 5.5427, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1401, Loss: 5.9860, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1402, Loss: 5.7252, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1403, Loss: 5.6361, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1404, Loss: 6.0188, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1405, Loss: 5.7409, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1406, Loss: 5.3757, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1407, Loss: 5.9517, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1408, Loss: 6.0696, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1409, Loss: 6.1700, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1410, Loss: 5.9172, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1411, Loss: 6.3968, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1412, Loss: 5.8910, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1413, Loss: 5.9863, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1414, Loss: 5.7628, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1415, Loss: 6.2079, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1416, Loss: 6.1050, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1417, Loss: 5.8494, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1418, Loss: 6.1685, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1419, Loss: 5.9605, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1420, Loss: 6.1038, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1421, Loss: 5.8921, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1422, Loss: 6.5771, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1423, Loss: 5.8062, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1424, Loss: 6.1122, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1425, Loss: 5.8508, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1426, Loss: 5.5320, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1427, Loss: 6.0530, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1428, Loss: 6.0745, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1429, Loss: 5.5404, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1430, Loss: 6.3177, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1431, Loss: 5.8773, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1432, Loss: 5.9752, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1433, Loss: 5.5485, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1434, Loss: 6.0753, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1435, Loss: 5.9432, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1436, Loss: 6.3408, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1437, Loss: 6.0071, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1438, Loss: 5.7577, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1439, Loss: 5.4159, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1440, Loss: 5.5882, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1441, Loss: 5.5978, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1442, Loss: 5.5651, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1443, Loss: 5.8438, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1444, Loss: 5.4849, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1445, Loss: 5.4886, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1446, Loss: 6.0797, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1447, Loss: 5.3008, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1448, Loss: 5.9121, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1449, Loss: 5.9502, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1450, Loss: 4.3814, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1451, Loss: 6.0881, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1452, Loss: 5.4817, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1453, Loss: 5.2724, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1454, Loss: 5.4917, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1455, Loss: 5.5001, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1456, Loss: 5.8631, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1457, Loss: 5.6251, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1458, Loss: 3.6771, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1459, Loss: 5.3760, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1460, Loss: 5.7501, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1461, Loss: 6.2639, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1462, Loss: 5.9873, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1463, Loss: 5.9253, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1464, Loss: 5.6499, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1465, Loss: 5.8416, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1466, Loss: 5.8099, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1467, Loss: 5.8569, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1468, Loss: 6.3126, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1469, Loss: 6.2030, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1470, Loss: 5.6289, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1471, Loss: 6.0247, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1472, Loss: 5.4180, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1473, Loss: 5.4332, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1474, Loss: 6.0953, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1475, Loss: 6.2287, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1476, Loss: 5.2690, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1477, Loss: 5.4836, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1478, Loss: 6.6602, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1479, Loss: 5.9996, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1480, Loss: 5.7311, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1481, Loss: 5.7586, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1482, Loss: 6.1825, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1483, Loss: 5.2247, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1484, Loss: 6.2075, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1485, Loss: 5.9480, LR: 0.000046, Memory: 1421.12 MB\n",
            "Epoch 2/5, Avg Loss: 23.7665, Time: 536.14s, Speed: 44.33 examples/s\n",
            "Model weights saved to /content/drive/MyDrive/LLM/custom_llm_epoch_4.pth\n",
            "Step 1, Loss: 4.7919, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 2, Loss: 5.3278, LR: 0.000010, Memory: 1356.09 MB\n",
            "Step 3, Loss: 5.5075, LR: 0.000010, Memory: 1356.09 MB\n",
            "Step 4, Loss: 6.0797, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 5, Loss: 5.5535, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 6, Loss: 4.9612, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 7, Loss: 5.0182, LR: 0.000010, Memory: 1356.09 MB\n",
            "Step 8, Loss: 5.7747, LR: 0.000010, Memory: 1356.09 MB\n",
            "Step 9, Loss: 5.7407, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 10, Loss: 5.9486, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 11, Loss: 5.7483, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 12, Loss: 5.6575, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 13, Loss: 5.8247, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 14, Loss: 5.9019, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 15, Loss: 5.6779, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 16, Loss: 6.0318, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 17, Loss: 4.7248, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 18, Loss: 5.6366, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 19, Loss: 5.3539, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 20, Loss: 5.1937, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 21, Loss: 4.9075, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 22, Loss: 5.0229, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 23, Loss: 5.2110, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 24, Loss: 5.0575, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 25, Loss: 5.5601, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 26, Loss: 5.7408, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 27, Loss: 5.4280, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 28, Loss: 5.6337, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 29, Loss: 6.1735, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 30, Loss: 4.9953, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 31, Loss: 6.0467, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 32, Loss: 5.7740, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 33, Loss: 5.5412, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 34, Loss: 5.7702, LR: 0.000012, Memory: 1356.09 MB\n",
            "Step 35, Loss: 5.1423, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 36, Loss: 5.7725, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 37, Loss: 5.6289, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 38, Loss: 4.8945, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 39, Loss: 5.8072, LR: 0.000012, Memory: 1356.09 MB\n",
            "Step 40, Loss: 5.4251, LR: 0.000012, Memory: 1356.09 MB\n",
            "Step 41, Loss: 6.0593, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 42, Loss: 5.5461, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 43, Loss: 5.9032, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 44, Loss: 5.0135, LR: 0.000012, Memory: 1356.09 MB\n",
            "Step 45, Loss: 6.0363, LR: 0.000012, Memory: 1356.09 MB\n",
            "Step 46, Loss: 5.5941, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 47, Loss: 5.5217, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 48, Loss: 5.8882, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 49, Loss: 5.5131, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 50, Loss: 5.1904, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 51, Loss: 5.4017, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 52, Loss: 5.5072, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 53, Loss: 5.8075, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 54, Loss: 5.6399, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 55, Loss: 5.5269, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 56, Loss: 5.4248, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 57, Loss: 5.1761, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 58, Loss: 4.9458, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 59, Loss: 5.6202, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 60, Loss: 5.9656, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 61, Loss: 5.2641, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 62, Loss: 4.9028, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 63, Loss: 6.0438, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 64, Loss: 5.2090, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 65, Loss: 5.6838, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 66, Loss: 5.3079, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 67, Loss: 5.7343, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 68, Loss: 6.0822, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 69, Loss: 5.6186, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 70, Loss: 5.7482, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 71, Loss: 5.9893, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 72, Loss: 5.2739, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 73, Loss: 6.0079, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 74, Loss: 5.7626, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 75, Loss: 5.7929, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 76, Loss: 4.6556, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 77, Loss: 5.9615, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 78, Loss: 5.6816, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 79, Loss: 5.6562, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 80, Loss: 5.7005, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 81, Loss: 5.4701, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 82, Loss: 5.1786, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 83, Loss: 5.8593, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 84, Loss: 5.4612, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 85, Loss: 6.2007, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 86, Loss: 6.2112, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 87, Loss: 5.6655, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 88, Loss: 5.8521, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 89, Loss: 5.9257, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 90, Loss: 5.6303, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 91, Loss: 5.6226, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 92, Loss: 5.4043, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 93, Loss: 6.0898, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 94, Loss: 5.9339, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 95, Loss: 5.7553, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 96, Loss: 5.8647, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 97, Loss: 5.3663, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 98, Loss: 5.8341, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 99, Loss: 5.5205, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 100, Loss: 5.3613, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 101, Loss: 5.3916, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 102, Loss: 5.7422, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 103, Loss: 5.1343, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 104, Loss: 5.4032, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 105, Loss: 5.7725, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 106, Loss: 5.4158, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 107, Loss: 5.8835, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 108, Loss: 5.4079, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 109, Loss: 5.7326, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 110, Loss: 5.6688, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 111, Loss: 5.8207, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 112, Loss: 2.9200, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 113, Loss: 4.8545, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 114, Loss: 5.9948, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 115, Loss: 5.1856, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 116, Loss: 5.8648, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 117, Loss: 5.8198, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 118, Loss: 5.8741, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 119, Loss: 5.7195, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 120, Loss: 3.8823, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 121, Loss: 5.4087, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 122, Loss: 5.5186, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 123, Loss: 5.8263, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 124, Loss: 5.9826, LR: 0.000017, Memory: 1356.09 MB\n",
            "Step 125, Loss: 5.1256, LR: 0.000017, Memory: 1356.09 MB\n",
            "Step 126, Loss: 5.7457, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 127, Loss: 6.0676, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 128, Loss: 5.8387, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 129, Loss: 6.0474, LR: 0.000017, Memory: 1356.09 MB\n",
            "Step 130, Loss: 5.1901, LR: 0.000017, Memory: 1356.09 MB\n",
            "Step 131, Loss: 5.3518, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 132, Loss: 5.6589, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 133, Loss: 5.4850, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 134, Loss: 5.8607, LR: 0.000017, Memory: 1356.09 MB\n",
            "Step 135, Loss: 5.4798, LR: 0.000017, Memory: 1356.09 MB\n",
            "Step 136, Loss: 5.1313, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 137, Loss: 5.1709, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 138, Loss: 5.9590, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 139, Loss: 5.8044, LR: 0.000017, Memory: 1356.09 MB\n",
            "Step 140, Loss: 5.2201, LR: 0.000017, Memory: 1356.09 MB\n",
            "Step 141, Loss: 5.6226, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 142, Loss: 5.6284, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 143, Loss: 5.3334, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 144, Loss: 4.9711, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 145, Loss: 6.3722, LR: 0.000018, Memory: 1356.09 MB\n",
            "Step 146, Loss: 5.5447, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 147, Loss: 5.9210, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 148, Loss: 5.1612, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 149, Loss: 5.8672, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 150, Loss: 6.0867, LR: 0.000018, Memory: 1356.09 MB\n",
            "Step 151, Loss: 5.8024, LR: 0.000018, Memory: 1356.09 MB\n",
            "Step 152, Loss: 6.3557, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 153, Loss: 5.7950, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 154, Loss: 4.2950, LR: 0.000018, Memory: 1356.09 MB\n",
            "Step 155, Loss: 5.7103, LR: 0.000018, Memory: 1356.09 MB\n",
            "Step 156, Loss: 5.3808, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 157, Loss: 5.8082, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 158, Loss: 6.0439, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 159, Loss: 5.5334, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 160, Loss: 5.4815, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 161, Loss: 5.9245, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 162, Loss: 6.0623, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 163, Loss: 4.1996, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 164, Loss: 5.2976, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 165, Loss: 5.1371, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 166, Loss: 5.4251, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 167, Loss: 5.6213, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 168, Loss: 5.4624, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 169, Loss: 5.2242, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 170, Loss: 5.1499, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 171, Loss: 5.6330, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 172, Loss: 5.2917, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 173, Loss: 5.5571, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 174, Loss: 5.9224, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 175, Loss: 5.6544, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 176, Loss: 5.2984, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 177, Loss: 5.0732, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 178, Loss: 5.3755, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 179, Loss: 5.9192, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 180, Loss: 6.0997, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 181, Loss: 5.8153, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 182, Loss: 5.5653, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 183, Loss: 5.6254, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 184, Loss: 5.7015, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 185, Loss: 5.6753, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 186, Loss: 5.6935, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 187, Loss: 5.5095, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 188, Loss: 5.3419, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 189, Loss: 5.8744, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 190, Loss: 4.8790, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 191, Loss: 4.1292, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 192, Loss: 5.9370, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 193, Loss: 5.9428, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 194, Loss: 5.1835, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 195, Loss: 5.8659, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 196, Loss: 6.4521, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 197, Loss: 5.1777, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 198, Loss: 5.5047, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 199, Loss: 5.8155, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 200, Loss: 5.7623, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 201, Loss: 5.7321, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 202, Loss: 5.6118, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 203, Loss: 5.8905, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 204, Loss: 6.1380, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 205, Loss: 5.3542, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 206, Loss: 6.0885, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 207, Loss: 5.8248, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 208, Loss: 5.4981, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 209, Loss: 5.2931, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 210, Loss: 5.7350, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 211, Loss: 5.7763, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 212, Loss: 6.3255, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 213, Loss: 5.3388, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 214, Loss: 4.9838, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 215, Loss: 5.3873, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 216, Loss: 5.8753, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 217, Loss: 5.0503, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 218, Loss: 5.2200, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 219, Loss: 5.5394, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 220, Loss: 5.3092, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 221, Loss: 5.7778, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 222, Loss: 5.6743, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 223, Loss: 5.3421, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 224, Loss: 5.5353, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 225, Loss: 5.5876, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 226, Loss: 5.8839, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 227, Loss: 5.5723, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 228, Loss: 5.6391, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 229, Loss: 5.3664, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 230, Loss: 5.5755, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 231, Loss: 5.6025, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 232, Loss: 5.8213, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 233, Loss: 5.9601, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 234, Loss: 5.6015, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 235, Loss: 5.8518, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 236, Loss: 5.4646, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 237, Loss: 5.6994, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 238, Loss: 5.1715, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 239, Loss: 5.5206, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 240, Loss: 5.7653, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 241, Loss: 5.6944, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 242, Loss: 5.7794, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 243, Loss: 5.9446, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 244, Loss: 5.8020, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 245, Loss: 6.1542, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 246, Loss: 5.4790, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 247, Loss: 5.5243, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 248, Loss: 5.6183, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 249, Loss: 5.2517, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 250, Loss: 6.0192, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 251, Loss: 6.0520, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 252, Loss: 5.8839, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 253, Loss: 6.1540, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 254, Loss: 5.5950, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 255, Loss: 5.5813, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 256, Loss: 4.8960, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 257, Loss: 5.9054, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 258, Loss: 5.3915, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 259, Loss: 5.5268, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 260, Loss: 4.9340, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 261, Loss: 4.1229, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 262, Loss: 5.8652, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 263, Loss: 5.2827, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 264, Loss: 5.8234, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 265, Loss: 5.5227, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 266, Loss: 5.1103, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 267, Loss: 5.9343, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 268, Loss: 5.8242, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 269, Loss: 5.5309, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 270, Loss: 5.8258, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 271, Loss: 5.2926, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 272, Loss: 5.7287, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 273, Loss: 5.3134, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 274, Loss: 5.8983, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 275, Loss: 5.0420, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 276, Loss: 5.3657, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 277, Loss: 4.8558, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 278, Loss: 5.3304, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 279, Loss: 5.6067, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 280, Loss: 5.5920, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 281, Loss: 5.9271, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 282, Loss: 5.6258, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 283, Loss: 5.9988, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 284, Loss: 5.8006, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 285, Loss: 5.7103, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 286, Loss: 5.8960, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 287, Loss: 5.7204, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 288, Loss: 6.1393, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 289, Loss: 5.8172, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 290, Loss: 5.7524, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 291, Loss: 5.5736, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 292, Loss: 5.6473, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 293, Loss: 5.7258, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 294, Loss: 5.7571, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 295, Loss: 6.0243, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 296, Loss: 5.5959, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 297, Loss: 5.4219, LR: 0.000026, Memory: 1356.10 MB\n",
            "Step 298, Loss: 5.6322, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 299, Loss: 4.5267, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 300, Loss: 6.1541, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 301, Loss: 5.8335, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 302, Loss: 5.7086, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 303, Loss: 5.8402, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 304, Loss: 5.8763, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 305, Loss: 5.8341, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 306, Loss: 4.8199, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 307, Loss: 5.4881, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 308, Loss: 5.2033, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 309, Loss: 5.5139, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 310, Loss: 5.4624, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 311, Loss: 6.1831, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 312, Loss: 5.7714, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 313, Loss: 5.6900, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 314, Loss: 6.3513, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 315, Loss: 4.7807, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 316, Loss: 5.7967, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 317, Loss: 6.0415, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 318, Loss: 5.3864, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 319, Loss: 5.8152, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 320, Loss: 5.9065, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 321, Loss: 5.7312, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 322, Loss: 5.3996, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 323, Loss: 5.1537, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 324, Loss: 5.4364, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 325, Loss: 5.2935, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 326, Loss: 5.9282, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 327, Loss: 5.9347, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 328, Loss: 5.7815, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 329, Loss: 5.4426, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 330, Loss: 5.6860, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 331, Loss: 5.6216, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 332, Loss: 5.8678, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 333, Loss: 5.6610, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 334, Loss: 6.2901, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 335, Loss: 5.1667, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 336, Loss: 5.8638, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 337, Loss: 6.4369, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 338, Loss: 5.3787, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 339, Loss: 5.2011, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 340, Loss: 5.9846, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 341, Loss: 5.9568, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 342, Loss: 5.1022, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 343, Loss: 5.8991, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 344, Loss: 5.1666, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 345, Loss: 5.4478, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 346, Loss: 5.4315, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 347, Loss: 5.4587, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 348, Loss: 5.3256, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 349, Loss: 5.1462, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 350, Loss: 5.3445, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 351, Loss: 5.5544, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 352, Loss: 5.9477, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 353, Loss: 5.9566, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 354, Loss: 6.3518, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 355, Loss: 5.6523, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 356, Loss: 5.6315, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 357, Loss: 6.1013, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 358, Loss: 5.3721, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 359, Loss: 5.2316, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 360, Loss: 4.9771, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 361, Loss: 5.3079, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 362, Loss: 6.0150, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 363, Loss: 6.1596, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 364, Loss: 4.9555, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 365, Loss: 5.4225, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 366, Loss: 5.0006, LR: 0.000030, Memory: 1356.09 MB\n",
            "Step 367, Loss: 5.3177, LR: 0.000030, Memory: 1356.09 MB\n",
            "Step 368, Loss: 6.0841, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 369, Loss: 5.7404, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 370, Loss: 5.2182, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 371, Loss: 5.6865, LR: 0.000030, Memory: 1356.09 MB\n",
            "Step 372, Loss: 5.7431, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 373, Loss: 5.5216, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 374, Loss: 5.2677, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 375, Loss: 6.1979, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 376, Loss: 6.2770, LR: 0.000030, Memory: 1356.09 MB\n",
            "Step 377, Loss: 5.8135, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 378, Loss: 4.9401, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 379, Loss: 5.7701, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 380, Loss: 5.6856, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 381, Loss: 6.3838, LR: 0.000030, Memory: 1356.09 MB\n",
            "Step 382, Loss: 5.3807, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 383, Loss: 5.6302, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 384, Loss: 5.7673, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 385, Loss: 5.6896, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 386, Loss: 5.1911, LR: 0.000031, Memory: 1356.09 MB\n",
            "Step 387, Loss: 5.7180, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 388, Loss: 5.6394, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 389, Loss: 5.7275, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 390, Loss: 4.1490, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 391, Loss: 5.7558, LR: 0.000031, Memory: 1356.09 MB\n",
            "Step 392, Loss: 5.5573, LR: 0.000031, Memory: 1356.09 MB\n",
            "Step 393, Loss: 5.2233, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 394, Loss: 5.3206, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 395, Loss: 5.1674, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 396, Loss: 5.9743, LR: 0.000031, Memory: 1356.09 MB\n",
            "Step 397, Loss: 5.3676, LR: 0.000031, Memory: 1356.09 MB\n",
            "Step 398, Loss: 5.1763, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 399, Loss: 5.3355, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 400, Loss: 5.5826, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 401, Loss: 5.2978, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 402, Loss: 6.1231, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 403, Loss: 4.9914, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 404, Loss: 5.7270, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 405, Loss: 5.6664, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 406, Loss: 5.1847, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 407, Loss: 5.4224, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 408, Loss: 5.4288, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 409, Loss: 5.3934, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 410, Loss: 5.6325, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 411, Loss: 6.0986, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 412, Loss: 5.8754, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 413, Loss: 6.0998, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 414, Loss: 6.0441, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 415, Loss: 6.1571, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 416, Loss: 6.0695, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 417, Loss: 5.8380, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 418, Loss: 6.0930, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 419, Loss: 5.2116, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 420, Loss: 5.6582, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 421, Loss: 5.5271, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 422, Loss: 5.0458, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 423, Loss: 5.5778, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 424, Loss: 5.8852, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 425, Loss: 5.9253, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 426, Loss: 5.6041, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 427, Loss: 5.7197, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 428, Loss: 5.7167, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 429, Loss: 5.9775, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 430, Loss: 5.5500, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 431, Loss: 5.5286, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 432, Loss: 4.8889, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 433, Loss: 5.2310, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 434, Loss: 5.2148, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 435, Loss: 5.2102, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 436, Loss: 5.8674, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 437, Loss: 6.0621, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 438, Loss: 5.8298, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 439, Loss: 5.7762, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 440, Loss: 4.9338, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 441, Loss: 4.8290, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 442, Loss: 5.9011, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 443, Loss: 3.3567, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 444, Loss: 5.6618, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 445, Loss: 6.1983, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 446, Loss: 5.1362, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 447, Loss: 5.4831, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 448, Loss: 5.7828, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 449, Loss: 5.0174, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 450, Loss: 6.1185, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 451, Loss: 5.6566, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 452, Loss: 5.7107, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 453, Loss: 5.6046, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 454, Loss: 5.9252, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 455, Loss: 5.6480, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 456, Loss: 5.5130, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 457, Loss: 5.0308, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 458, Loss: 5.5158, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 459, Loss: 5.3787, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 460, Loss: 5.2844, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 461, Loss: 5.7741, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 462, Loss: 5.8545, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 463, Loss: 5.8810, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 464, Loss: 5.5893, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 465, Loss: 5.4442, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 466, Loss: 5.8469, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 467, Loss: 6.1024, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 468, Loss: 5.5521, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 469, Loss: 5.5944, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 470, Loss: 5.3784, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 471, Loss: 5.9456, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 472, Loss: 5.0157, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 473, Loss: 5.7243, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 474, Loss: 6.2128, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 475, Loss: 5.4406, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 476, Loss: 5.3282, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 477, Loss: 5.6551, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 478, Loss: 5.4184, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 479, Loss: 3.1586, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 480, Loss: 5.7000, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 481, Loss: 4.9991, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 482, Loss: 5.8050, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 483, Loss: 5.2972, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 484, Loss: 5.5841, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 485, Loss: 5.5514, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 486, Loss: 5.6985, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 487, Loss: 4.9863, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 488, Loss: 5.4152, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 489, Loss: 5.9140, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 490, Loss: 5.6846, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 491, Loss: 6.3082, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 492, Loss: 5.7188, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 493, Loss: 5.8780, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 494, Loss: 5.6670, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 495, Loss: 5.7448, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 496, Loss: 5.2925, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 497, Loss: 5.3907, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 498, Loss: 5.4958, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 499, Loss: 5.6985, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 500, Loss: 5.5428, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 501, Loss: 5.9489, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 502, Loss: 6.0075, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 503, Loss: 5.3621, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 504, Loss: 5.4742, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 505, Loss: 5.2499, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 506, Loss: 6.0167, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 507, Loss: 5.7110, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 508, Loss: 5.2440, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 509, Loss: 5.3592, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 510, Loss: 5.7922, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 511, Loss: 5.2183, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 512, Loss: 5.9551, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 513, Loss: 5.8740, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 514, Loss: 5.8098, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 515, Loss: 5.4484, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 516, Loss: 4.9400, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 517, Loss: 5.7029, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 518, Loss: 5.2599, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 519, Loss: 5.6871, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 520, Loss: 5.6956, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 521, Loss: 5.0932, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 522, Loss: 4.6791, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 523, Loss: 5.1750, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 524, Loss: 5.4484, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 525, Loss: 5.2411, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 526, Loss: 5.5007, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 527, Loss: 5.3659, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 528, Loss: 5.8759, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 529, Loss: 5.5329, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 530, Loss: 5.9086, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 531, Loss: 5.3800, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 532, Loss: 5.9723, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 533, Loss: 5.5034, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 534, Loss: 5.6674, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 535, Loss: 5.3226, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 536, Loss: 4.7120, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 537, Loss: 5.5107, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 538, Loss: 6.1538, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 539, Loss: 5.6977, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 540, Loss: 5.0691, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 541, Loss: 5.1130, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 542, Loss: 5.8289, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 543, Loss: 4.7481, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 544, Loss: 5.8054, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 545, Loss: 5.4428, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 546, Loss: 5.1501, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 547, Loss: 5.9023, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 548, Loss: 4.7556, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 549, Loss: 5.8244, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 550, Loss: 5.7202, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 551, Loss: 4.9242, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 552, Loss: 6.1003, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 553, Loss: 6.0123, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 554, Loss: 5.7970, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 555, Loss: 5.3781, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 556, Loss: 5.3336, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 557, Loss: 5.8761, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 558, Loss: 5.4421, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 559, Loss: 5.8984, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 560, Loss: 6.0297, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 561, Loss: 5.2843, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 562, Loss: 6.0041, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 563, Loss: 5.7602, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 564, Loss: 5.3158, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 565, Loss: 5.4840, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 566, Loss: 5.7360, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 567, Loss: 5.6034, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 568, Loss: 5.1783, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 569, Loss: 5.5570, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 570, Loss: 6.0002, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 571, Loss: 5.1776, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 572, Loss: 5.2953, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 573, Loss: 5.0441, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 574, Loss: 2.8361, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 575, Loss: 6.0348, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 576, Loss: 6.2345, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 577, Loss: 6.2380, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 578, Loss: 5.6506, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 579, Loss: 5.8018, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 580, Loss: 5.8103, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 581, Loss: 5.7273, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 582, Loss: 5.6682, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 583, Loss: 5.6940, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 584, Loss: 5.0895, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 585, Loss: 5.8338, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 586, Loss: 5.6515, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 587, Loss: 6.1788, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 588, Loss: 5.3933, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 589, Loss: 5.8964, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 590, Loss: 5.1343, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 591, Loss: 5.4476, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 592, Loss: 5.5855, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 593, Loss: 6.0824, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 594, Loss: 5.5600, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 595, Loss: 6.2365, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 596, Loss: 6.1065, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 597, Loss: 5.3297, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 598, Loss: 5.1030, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 599, Loss: 5.2672, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 600, Loss: 5.2568, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 601, Loss: 3.3438, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 602, Loss: 5.4304, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 603, Loss: 6.0246, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 604, Loss: 5.7799, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 605, Loss: 5.9058, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 606, Loss: 5.9599, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 607, Loss: 5.5320, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 608, Loss: 5.8786, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 609, Loss: 5.9257, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 610, Loss: 5.4927, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 611, Loss: 5.6198, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 612, Loss: 6.0195, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 613, Loss: 5.5450, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 614, Loss: 5.7806, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 615, Loss: 5.0483, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 616, Loss: 5.2987, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 617, Loss: 5.4430, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 618, Loss: 6.1357, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 619, Loss: 5.3250, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 620, Loss: 5.6378, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 621, Loss: 5.5082, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 622, Loss: 5.6174, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 623, Loss: 6.0036, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 624, Loss: 5.3919, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 625, Loss: 5.5135, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 626, Loss: 5.9010, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 627, Loss: 6.1352, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 628, Loss: 5.0941, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 629, Loss: 4.7894, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 630, Loss: 5.8182, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 631, Loss: 5.5599, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 632, Loss: 5.6831, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 633, Loss: 5.7468, LR: 0.000044, Memory: 1356.10 MB\n",
            "Step 634, Loss: 5.5993, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 635, Loss: 6.1998, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 636, Loss: 5.5242, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 637, Loss: 6.0903, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 638, Loss: 5.6082, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 639, Loss: 5.2106, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 640, Loss: 2.3996, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 641, Loss: 5.7073, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 642, Loss: 5.8262, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 643, Loss: 6.0546, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 644, Loss: 6.0098, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 645, Loss: 6.0578, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 646, Loss: 5.6800, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 647, Loss: 3.4157, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 648, Loss: 5.8726, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 649, Loss: 5.4871, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 650, Loss: 5.6276, LR: 0.000045, Memory: 1356.10 MB\n",
            "Step 651, Loss: 5.6090, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 652, Loss: 5.5006, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 653, Loss: 6.2614, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 654, Loss: 5.1334, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 655, Loss: 4.8783, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 656, Loss: 6.0008, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 657, Loss: 5.6498, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 658, Loss: 5.6244, LR: 0.000045, Memory: 1356.10 MB\n",
            "Step 659, Loss: 5.3195, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 660, Loss: 5.8255, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 661, Loss: 5.7513, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 662, Loss: 5.9844, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 663, Loss: 5.7972, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 664, Loss: 5.8293, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 665, Loss: 2.8099, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 666, Loss: 5.4993, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 667, Loss: 5.9297, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 668, Loss: 5.3952, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 669, Loss: 5.8038, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 670, Loss: 5.6029, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 671, Loss: 5.7398, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 672, Loss: 5.4961, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 673, Loss: 5.8872, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 674, Loss: 5.6243, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 675, Loss: 5.5606, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 676, Loss: 5.4502, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 677, Loss: 5.8244, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 678, Loss: 5.6076, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 679, Loss: 5.3511, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 680, Loss: 5.4323, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 681, Loss: 5.7352, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 682, Loss: 5.8045, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 683, Loss: 5.1639, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 684, Loss: 5.7977, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 685, Loss: 5.5210, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 686, Loss: 5.9987, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 687, Loss: 5.6177, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 688, Loss: 5.3449, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 689, Loss: 5.2932, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 690, Loss: 5.7536, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 691, Loss: 6.0654, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 692, Loss: 5.4023, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 693, Loss: 5.4111, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 694, Loss: 6.3089, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 695, Loss: 5.3666, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 696, Loss: 5.8297, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 697, Loss: 5.3111, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 698, Loss: 5.6564, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 699, Loss: 5.7536, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 700, Loss: 5.2707, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 701, Loss: 5.5797, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 702, Loss: 5.9614, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 703, Loss: 5.0447, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 704, Loss: 4.9878, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 705, Loss: 5.2499, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 706, Loss: 6.0011, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 707, Loss: 5.4793, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 708, Loss: 6.0090, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 709, Loss: 6.0143, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 710, Loss: 5.6805, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 711, Loss: 5.8514, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 712, Loss: 5.7466, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 713, Loss: 5.9742, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 714, Loss: 5.5743, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 715, Loss: 5.6888, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 716, Loss: 5.9296, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 717, Loss: 5.2988, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 718, Loss: 5.4658, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 719, Loss: 5.5270, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 720, Loss: 5.5426, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 721, Loss: 5.4865, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 722, Loss: 5.8051, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 723, Loss: 5.2134, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 724, Loss: 5.7375, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 725, Loss: 5.8688, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 726, Loss: 5.7572, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 727, Loss: 4.4049, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 728, Loss: 5.6948, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 729, Loss: 5.0618, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 730, Loss: 6.2420, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 731, Loss: 5.5733, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 732, Loss: 5.9852, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 733, Loss: 5.8953, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 734, Loss: 5.5382, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 735, Loss: 5.4492, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 736, Loss: 3.3746, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 737, Loss: 5.8753, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 738, Loss: 5.9680, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 739, Loss: 5.5804, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 740, Loss: 5.4546, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 741, Loss: 5.4174, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 742, Loss: 5.3028, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 743, Loss: 6.0648, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 744, Loss: 4.4185, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 745, Loss: 6.1734, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 746, Loss: 5.8338, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 747, Loss: 5.6740, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 748, Loss: 4.8020, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 749, Loss: 5.5359, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 750, Loss: 5.3033, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 751, Loss: 5.2093, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 752, Loss: 5.4662, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 753, Loss: 5.3825, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 754, Loss: 5.3252, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 755, Loss: 6.1144, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 756, Loss: 4.9398, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 757, Loss: 5.7823, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 758, Loss: 5.9446, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 759, Loss: 4.9445, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 760, Loss: 5.8849, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 761, Loss: 5.9149, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 762, Loss: 5.4829, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 763, Loss: 5.5322, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 764, Loss: 5.6080, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 765, Loss: 5.2379, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 766, Loss: 5.9421, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 767, Loss: 5.5314, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 768, Loss: 5.6529, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 769, Loss: 5.1751, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 770, Loss: 6.0826, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 771, Loss: 5.4467, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 772, Loss: 5.5226, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 773, Loss: 5.6128, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 774, Loss: 5.2669, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 775, Loss: 6.9440, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 776, Loss: 5.3192, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 777, Loss: 5.6081, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 778, Loss: 5.4108, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 779, Loss: 5.7151, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 780, Loss: 5.0356, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 781, Loss: 5.9403, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 782, Loss: 4.1019, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 783, Loss: 5.9917, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 784, Loss: 6.0281, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 785, Loss: 5.8264, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 786, Loss: 5.2212, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 787, Loss: 5.6626, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 788, Loss: 5.4620, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 789, Loss: 5.5275, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 790, Loss: 5.6351, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 791, Loss: 5.7263, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 792, Loss: 5.7169, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 793, Loss: 5.9864, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 794, Loss: 5.9217, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 795, Loss: 2.1669, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 796, Loss: 5.5949, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 797, Loss: 5.9485, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 798, Loss: 5.7748, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 799, Loss: 5.7953, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 800, Loss: 3.4644, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 801, Loss: 5.7364, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 802, Loss: 5.5169, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 803, Loss: 5.1309, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 804, Loss: 5.8379, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 805, Loss: 5.8748, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 806, Loss: 5.6721, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 807, Loss: 5.8439, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 808, Loss: 5.2546, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 809, Loss: 6.2102, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 810, Loss: 4.6027, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 811, Loss: 5.1772, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 812, Loss: 5.4127, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 813, Loss: 5.7896, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 814, Loss: 5.1773, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 815, Loss: 6.0614, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 816, Loss: 5.2426, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 817, Loss: 5.8668, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 818, Loss: 5.5648, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 819, Loss: 6.0305, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 820, Loss: 5.8650, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 821, Loss: 5.6824, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 822, Loss: 5.4673, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 823, Loss: 5.6800, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 824, Loss: 5.8509, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 825, Loss: 6.0557, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 826, Loss: 5.4852, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 827, Loss: 5.9847, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 828, Loss: 6.0718, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 829, Loss: 4.6095, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 830, Loss: 5.5423, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 831, Loss: 5.7646, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 832, Loss: 5.6145, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 833, Loss: 5.8348, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 834, Loss: 5.1182, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 835, Loss: 6.0263, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 836, Loss: 5.6342, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 837, Loss: 5.4727, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 838, Loss: 5.9537, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 839, Loss: 4.9067, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 840, Loss: 5.5092, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 841, Loss: 5.8329, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 842, Loss: 5.7454, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 843, Loss: 5.8113, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 844, Loss: 5.6528, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 845, Loss: 5.8258, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 846, Loss: 5.1625, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 847, Loss: 5.7513, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 848, Loss: 5.8871, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 849, Loss: 5.4702, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 850, Loss: 5.9682, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 851, Loss: 5.8912, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 852, Loss: 5.4929, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 853, Loss: 5.3447, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 854, Loss: 4.5194, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 855, Loss: 5.5318, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 856, Loss: 5.6100, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 857, Loss: 4.9619, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 858, Loss: 5.5625, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 859, Loss: 5.4951, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 860, Loss: 5.6644, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 861, Loss: 5.6642, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 862, Loss: 5.4974, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 863, Loss: 5.4196, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 864, Loss: 6.0567, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 865, Loss: 5.9110, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 866, Loss: 4.9860, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 867, Loss: 5.9923, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 868, Loss: 5.8294, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 869, Loss: 5.7665, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 870, Loss: 5.9095, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 871, Loss: 5.4984, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 872, Loss: 5.4133, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 873, Loss: 5.8809, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 874, Loss: 5.3282, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 875, Loss: 5.7818, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 876, Loss: 5.6059, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 877, Loss: 6.0108, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 878, Loss: 5.7378, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 879, Loss: 5.5283, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 880, Loss: 5.2848, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 881, Loss: 5.9977, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 882, Loss: 5.5701, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 883, Loss: 5.1842, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 884, Loss: 4.6541, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 885, Loss: 5.9894, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 886, Loss: 5.2370, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 887, Loss: 5.6192, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 888, Loss: 5.9227, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 889, Loss: 5.3527, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 890, Loss: 5.3266, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 891, Loss: 5.8938, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 892, Loss: 4.6996, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 893, Loss: 6.0181, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 894, Loss: 6.2517, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 895, Loss: 5.2165, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 896, Loss: 5.4766, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 897, Loss: 5.7958, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 898, Loss: 5.1377, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 899, Loss: 5.5221, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 900, Loss: 5.4965, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 901, Loss: 5.3446, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 902, Loss: 5.7973, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 903, Loss: 5.2512, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 904, Loss: 5.3067, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 905, Loss: 5.7260, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 906, Loss: 5.9065, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 907, Loss: 5.3274, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 908, Loss: 5.8276, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 909, Loss: 4.8436, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 910, Loss: 5.6254, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 911, Loss: 4.1996, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 912, Loss: 5.4320, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 913, Loss: 5.6867, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 914, Loss: 5.7320, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 915, Loss: 5.9904, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 916, Loss: 5.1466, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 917, Loss: 5.3845, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 918, Loss: 5.4767, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 919, Loss: 5.7719, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 920, Loss: 5.2914, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 921, Loss: 5.6646, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 922, Loss: 5.9677, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 923, Loss: 5.5208, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 924, Loss: 5.6533, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 925, Loss: 5.4610, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 926, Loss: 5.2266, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 927, Loss: 6.0377, LR: 0.000048, Memory: 1356.10 MB\n",
            "Step 928, Loss: 5.2041, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 929, Loss: 5.0494, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 930, Loss: 5.8412, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 931, Loss: 4.8589, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 932, Loss: 5.5958, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 933, Loss: 5.8647, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 934, Loss: 5.6490, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 935, Loss: 5.6868, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 936, Loss: 5.3097, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 937, Loss: 5.4905, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 938, Loss: 5.9164, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 939, Loss: 5.6413, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 940, Loss: 5.6806, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 941, Loss: 5.3553, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 942, Loss: 5.7796, LR: 0.000048, Memory: 1356.10 MB\n",
            "Step 943, Loss: 5.7796, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 944, Loss: 5.4334, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 945, Loss: 5.5224, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 946, Loss: 5.4633, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 947, Loss: 5.9005, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 948, Loss: 5.9663, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 949, Loss: 5.4415, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 950, Loss: 5.5877, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 951, Loss: 5.6223, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 952, Loss: 5.1428, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 953, Loss: 5.7178, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 954, Loss: 5.3874, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 955, Loss: 5.9990, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 956, Loss: 5.6279, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 957, Loss: 5.5095, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 958, Loss: 5.2518, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 959, Loss: 5.5385, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 960, Loss: 5.9125, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 961, Loss: 5.4606, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 962, Loss: 5.3690, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 963, Loss: 6.2392, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 964, Loss: 5.8395, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 965, Loss: 5.6620, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 966, Loss: 5.7913, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 967, Loss: 5.5661, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 968, Loss: 5.7671, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 969, Loss: 5.6864, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 970, Loss: 5.9428, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 971, Loss: 5.5094, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 972, Loss: 5.2289, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 973, Loss: 5.5847, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 974, Loss: 5.4175, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 975, Loss: 5.4861, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 976, Loss: 5.7126, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 977, Loss: 5.2995, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 978, Loss: 5.6614, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 979, Loss: 5.8928, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 980, Loss: 5.6558, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 981, Loss: 5.7085, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 982, Loss: 5.9807, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 983, Loss: 5.7234, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 984, Loss: 5.5934, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 985, Loss: 5.8717, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 986, Loss: 5.8399, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 987, Loss: 5.1299, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 988, Loss: 5.4656, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 989, Loss: 5.0694, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 990, Loss: 5.9062, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 991, Loss: 5.7155, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 992, Loss: 5.6156, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 993, Loss: 6.1357, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 994, Loss: 6.2427, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 995, Loss: 5.6646, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 996, Loss: 6.0548, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 997, Loss: 5.5077, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 998, Loss: 6.2464, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 999, Loss: 5.2692, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1000, Loss: 5.6648, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1001, Loss: 5.0784, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1002, Loss: 5.7822, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1003, Loss: 5.3957, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1004, Loss: 6.0550, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1005, Loss: 5.9052, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1006, Loss: 4.8933, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1007, Loss: 5.6298, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1008, Loss: 5.5324, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1009, Loss: 5.6068, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1010, Loss: 5.5386, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1011, Loss: 5.2948, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 1012, Loss: 5.3880, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1013, Loss: 5.3059, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1014, Loss: 5.6872, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 1015, Loss: 5.5430, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1016, Loss: 5.4284, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1017, Loss: 6.0107, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1018, Loss: 5.6170, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1019, Loss: 5.5215, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1020, Loss: 5.4207, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1021, Loss: 5.5181, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1022, Loss: 5.9012, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1023, Loss: 5.6654, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1024, Loss: 5.2575, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1025, Loss: 6.2198, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1026, Loss: 5.9797, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1027, Loss: 6.0067, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1028, Loss: 5.3345, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1029, Loss: 5.7228, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1030, Loss: 5.4848, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1031, Loss: 5.4044, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1032, Loss: 5.1620, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1033, Loss: 5.4624, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1034, Loss: 5.2956, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1035, Loss: 4.4816, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1036, Loss: 5.6186, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1037, Loss: 4.4478, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1038, Loss: 6.0241, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1039, Loss: 6.2846, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1040, Loss: 5.2626, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1041, Loss: 5.5764, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1042, Loss: 5.5793, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1043, Loss: 3.5178, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1044, Loss: 5.5908, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1045, Loss: 5.2790, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1046, Loss: 5.2966, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1047, Loss: 5.5831, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1048, Loss: 4.3706, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1049, Loss: 5.5323, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1050, Loss: 4.6622, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1051, Loss: 5.4439, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1052, Loss: 5.7483, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1053, Loss: 4.9739, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1054, Loss: 5.5882, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1055, Loss: 5.5435, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1056, Loss: 5.8434, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1057, Loss: 5.8833, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1058, Loss: 5.6513, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1059, Loss: 5.3711, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1060, Loss: 5.3825, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1061, Loss: 5.6350, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1062, Loss: 5.2633, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1063, Loss: 5.1740, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1064, Loss: 5.8967, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1065, Loss: 5.9835, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1066, Loss: 4.6781, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1067, Loss: 5.5089, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1068, Loss: 5.6304, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1069, Loss: 5.3457, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1070, Loss: 6.3060, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1071, Loss: 5.7632, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1072, Loss: 6.1844, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1073, Loss: 5.3642, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1074, Loss: 6.0275, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1075, Loss: 6.2165, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1076, Loss: 5.0833, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1077, Loss: 5.1840, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1078, Loss: 6.0056, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1079, Loss: 5.3968, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1080, Loss: 5.2056, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1081, Loss: 5.9114, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1082, Loss: 5.7941, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1083, Loss: 5.6169, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1084, Loss: 5.7195, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1085, Loss: 6.0382, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1086, Loss: 5.4777, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1087, Loss: 5.6851, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1088, Loss: 5.5845, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1089, Loss: 5.3232, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1090, Loss: 6.1640, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1091, Loss: 5.6519, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1092, Loss: 3.0347, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1093, Loss: 5.6399, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1094, Loss: 5.4605, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1095, Loss: 5.1306, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1096, Loss: 5.7921, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1097, Loss: 5.5778, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1098, Loss: 5.8585, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1099, Loss: 5.7527, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1100, Loss: 6.1474, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1101, Loss: 5.5447, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1102, Loss: 5.3977, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1103, Loss: 5.9758, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1104, Loss: 5.8573, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1105, Loss: 5.3780, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1106, Loss: 6.1126, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1107, Loss: 5.8881, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1108, Loss: 5.9074, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1109, Loss: 4.9303, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1110, Loss: 4.9549, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1111, Loss: 5.7392, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1112, Loss: 5.9530, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 1113, Loss: 4.2552, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1114, Loss: 5.7770, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1115, Loss: 5.0023, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1116, Loss: 5.2473, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 1117, Loss: 4.7875, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1118, Loss: 5.6778, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1119, Loss: 5.4467, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1120, Loss: 6.0469, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1121, Loss: 5.2401, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1122, Loss: 5.8476, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1123, Loss: 5.1391, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1124, Loss: 5.6576, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1125, Loss: 5.3757, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1126, Loss: 5.2471, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1127, Loss: 5.3787, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1128, Loss: 5.4109, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1129, Loss: 4.1793, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1130, Loss: 5.5946, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1131, Loss: 5.9039, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1132, Loss: 4.7261, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1133, Loss: 5.6690, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1134, Loss: 5.3425, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1135, Loss: 5.1488, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1136, Loss: 4.9229, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1137, Loss: 5.4346, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1138, Loss: 5.0131, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1139, Loss: 5.8168, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1140, Loss: 5.4358, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1141, Loss: 5.2426, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1142, Loss: 5.5427, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1143, Loss: 5.5172, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1144, Loss: 5.1921, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1145, Loss: 5.2930, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1146, Loss: 5.6043, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1147, Loss: 5.8784, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1148, Loss: 5.5026, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1149, Loss: 5.1797, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1150, Loss: 5.2107, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1151, Loss: 5.2865, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1152, Loss: 5.7899, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1153, Loss: 5.0859, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1154, Loss: 5.3432, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1155, Loss: 4.8096, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1156, Loss: 5.7811, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1157, Loss: 5.4582, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1158, Loss: 5.1691, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1159, Loss: 5.3046, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1160, Loss: 5.3785, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1161, Loss: 5.5979, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1162, Loss: 5.5546, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1163, Loss: 5.5534, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1164, Loss: 5.4685, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1165, Loss: 5.3067, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1166, Loss: 5.6854, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1167, Loss: 5.6581, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1168, Loss: 5.6648, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1169, Loss: 5.9527, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1170, Loss: 5.3863, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1171, Loss: 5.2649, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1172, Loss: 4.8265, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1173, Loss: 5.8944, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1174, Loss: 5.7903, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1175, Loss: 5.4571, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1176, Loss: 5.7640, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1177, Loss: 5.2182, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1178, Loss: 5.4881, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1179, Loss: 5.3824, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1180, Loss: 5.3161, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1181, Loss: 5.4105, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1182, Loss: 5.7820, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1183, Loss: 5.4350, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1184, Loss: 5.8061, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1185, Loss: 6.0338, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1186, Loss: 5.4668, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1187, Loss: 5.8642, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1188, Loss: 5.7371, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1189, Loss: 5.6974, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1190, Loss: 5.5099, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1191, Loss: 5.3384, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1192, Loss: 5.8296, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1193, Loss: 5.8557, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1194, Loss: 5.0237, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1195, Loss: 5.4665, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1196, Loss: 4.9695, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1197, Loss: 6.0308, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1198, Loss: 6.0243, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1199, Loss: 5.7050, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1200, Loss: 6.1317, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1201, Loss: 5.6355, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1202, Loss: 5.1840, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1203, Loss: 5.4366, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1204, Loss: 6.0088, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1205, Loss: 5.0264, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1206, Loss: 5.5974, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1207, Loss: 5.9039, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1208, Loss: 5.6242, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1209, Loss: 5.8527, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1210, Loss: 5.5654, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1211, Loss: 6.0783, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1212, Loss: 5.5786, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1213, Loss: 5.1688, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1214, Loss: 5.4407, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1215, Loss: 5.3120, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1216, Loss: 5.6031, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1217, Loss: 4.8517, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1218, Loss: 5.9253, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1219, Loss: 5.6314, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1220, Loss: 5.9645, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1221, Loss: 6.3559, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1222, Loss: 5.4096, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1223, Loss: 2.3972, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1224, Loss: 5.5000, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1225, Loss: 5.3603, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1226, Loss: 5.9907, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1227, Loss: 5.0965, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1228, Loss: 5.5791, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1229, Loss: 5.7415, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1230, Loss: 5.4930, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1231, Loss: 5.7271, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1232, Loss: 5.4421, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1233, Loss: 5.5510, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1234, Loss: 5.6063, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1235, Loss: 5.5031, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1236, Loss: 5.5162, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1237, Loss: 5.6845, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1238, Loss: 5.6049, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1239, Loss: 5.4661, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1240, Loss: 5.8104, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1241, Loss: 5.9278, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1242, Loss: 5.5053, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1243, Loss: 4.8811, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1244, Loss: 2.1654, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1245, Loss: 5.1577, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1246, Loss: 5.8172, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1247, Loss: 5.7609, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1248, Loss: 5.2145, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1249, Loss: 5.2713, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1250, Loss: 5.7271, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1251, Loss: 5.6391, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1252, Loss: 5.5642, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1253, Loss: 5.4867, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1254, Loss: 5.6793, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1255, Loss: 5.4350, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1256, Loss: 5.8051, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1257, Loss: 5.9611, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1258, Loss: 5.0045, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1259, Loss: 5.1113, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1260, Loss: 5.4446, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1261, Loss: 5.3705, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1262, Loss: 6.2989, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1263, Loss: 5.1573, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1264, Loss: 4.7780, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1265, Loss: 5.9214, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1266, Loss: 4.9734, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1267, Loss: 5.6224, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1268, Loss: 5.0915, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1269, Loss: 5.2252, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1270, Loss: 6.0569, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1271, Loss: 5.8009, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1272, Loss: 5.3694, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1273, Loss: 5.2006, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1274, Loss: 4.9447, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1275, Loss: 5.6722, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1276, Loss: 5.0861, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1277, Loss: 5.7072, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1278, Loss: 5.5715, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1279, Loss: 5.4540, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1280, Loss: 5.7478, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1281, Loss: 5.6266, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1282, Loss: 6.2248, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1283, Loss: 5.8009, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1284, Loss: 5.3143, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1285, Loss: 5.4842, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1286, Loss: 5.1890, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1287, Loss: 5.3463, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1288, Loss: 5.5851, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1289, Loss: 5.6465, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1290, Loss: 5.9033, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1291, Loss: 4.9172, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1292, Loss: 5.8157, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1293, Loss: 5.2624, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1294, Loss: 6.4776, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1295, Loss: 5.1144, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1296, Loss: 5.0172, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1297, Loss: 5.5234, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1298, Loss: 3.8942, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1299, Loss: 5.7222, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1300, Loss: 5.7337, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1301, Loss: 4.4823, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1302, Loss: 5.8440, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1303, Loss: 5.4746, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1304, Loss: 5.7611, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1305, Loss: 5.5599, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1306, Loss: 6.2121, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1307, Loss: 5.6707, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1308, Loss: 5.5874, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1309, Loss: 6.2701, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1310, Loss: 5.2645, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1311, Loss: 5.6525, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1312, Loss: 4.7205, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1313, Loss: 5.0982, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1314, Loss: 5.8015, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1315, Loss: 5.0955, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1316, Loss: 6.0810, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1317, Loss: 5.6340, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1318, Loss: 5.4835, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1319, Loss: 5.7442, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1320, Loss: 4.7205, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1321, Loss: 6.2410, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1322, Loss: 5.2484, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1323, Loss: 5.4807, LR: 0.000044, Memory: 1356.10 MB\n",
            "Step 1324, Loss: 4.5216, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1325, Loss: 5.4583, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1326, Loss: 5.6785, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1327, Loss: 5.1907, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1328, Loss: 5.3698, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1329, Loss: 6.0606, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1330, Loss: 5.4624, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1331, Loss: 5.6737, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1332, Loss: 5.6561, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1333, Loss: 5.8387, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1334, Loss: 5.3148, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1335, Loss: 5.2514, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1336, Loss: 5.7406, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1337, Loss: 5.5066, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1338, Loss: 5.0116, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1339, Loss: 5.7211, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1340, Loss: 5.9368, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1341, Loss: 4.7856, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1342, Loss: 5.5821, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1343, Loss: 5.0046, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1344, Loss: 5.0569, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1345, Loss: 6.0208, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1346, Loss: 4.9620, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1347, Loss: 2.5162, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1348, Loss: 5.2790, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1349, Loss: 5.2133, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1350, Loss: 5.6698, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1351, Loss: 5.1215, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1352, Loss: 5.1751, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1353, Loss: 5.3443, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1354, Loss: 5.8276, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1355, Loss: 5.4979, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1356, Loss: 5.6523, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1357, Loss: 4.9916, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1358, Loss: 5.7841, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1359, Loss: 5.6854, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1360, Loss: 5.5144, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1361, Loss: 5.4902, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1362, Loss: 5.2231, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1363, Loss: 6.0308, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1364, Loss: 5.6244, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1365, Loss: 5.5932, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1366, Loss: 5.9530, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1367, Loss: 5.3532, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1368, Loss: 5.8549, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1369, Loss: 4.9625, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1370, Loss: 5.7048, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1371, Loss: 5.8208, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1372, Loss: 5.9301, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1373, Loss: 5.6181, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1374, Loss: 5.6388, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1375, Loss: 5.7072, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1376, Loss: 4.9040, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1377, Loss: 5.2296, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1378, Loss: 5.3609, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1379, Loss: 5.8179, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1380, Loss: 5.9617, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1381, Loss: 5.0243, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1382, Loss: 5.5561, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1383, Loss: 5.4069, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1384, Loss: 5.8693, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1385, Loss: 5.1427, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1386, Loss: 5.5542, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1387, Loss: 5.9874, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1388, Loss: 5.1668, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1389, Loss: 4.9181, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1390, Loss: 5.5319, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1391, Loss: 5.6133, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1392, Loss: 5.6441, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1393, Loss: 4.9960, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1394, Loss: 5.5978, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1395, Loss: 5.6813, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1396, Loss: 5.5312, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1397, Loss: 5.3869, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1398, Loss: 5.0745, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1399, Loss: 4.8635, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1400, Loss: 4.7741, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1401, Loss: 5.2747, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1402, Loss: 5.4494, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1403, Loss: 5.3753, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1404, Loss: 5.2807, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1405, Loss: 5.8459, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1406, Loss: 5.0262, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1407, Loss: 5.8783, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1408, Loss: 4.8826, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1409, Loss: 5.3476, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1410, Loss: 5.8957, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1411, Loss: 4.1922, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1412, Loss: 5.7509, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1413, Loss: 5.2912, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1414, Loss: 5.7402, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1415, Loss: 5.3884, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1416, Loss: 5.5078, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1417, Loss: 5.8419, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1418, Loss: 5.1139, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1419, Loss: 5.2875, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1420, Loss: 5.3949, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1421, Loss: 6.0300, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1422, Loss: 4.8751, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1423, Loss: 4.9588, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1424, Loss: 5.1133, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1425, Loss: 6.1744, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1426, Loss: 5.2124, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1427, Loss: 5.3932, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1428, Loss: 5.6607, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1429, Loss: 5.4558, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1430, Loss: 5.3692, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1431, Loss: 4.7187, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1432, Loss: 5.4650, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1433, Loss: 5.0765, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1434, Loss: 4.6358, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1435, Loss: 5.6488, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1436, Loss: 5.4416, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1437, Loss: 5.6538, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1438, Loss: 5.3849, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1439, Loss: 5.3464, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1440, Loss: 5.1597, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1441, Loss: 5.5220, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1442, Loss: 5.2431, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1443, Loss: 5.6635, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1444, Loss: 5.5070, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1445, Loss: 6.0036, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1446, Loss: 5.1666, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1447, Loss: 4.9899, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1448, Loss: 6.1862, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1449, Loss: 6.2872, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1450, Loss: 5.4477, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1451, Loss: 5.1598, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1452, Loss: 5.1602, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1453, Loss: 5.3247, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1454, Loss: 5.0391, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1455, Loss: 5.2522, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1456, Loss: 5.5581, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1457, Loss: 5.4089, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1458, Loss: 5.1953, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1459, Loss: 5.2681, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1460, Loss: 5.3044, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1461, Loss: 5.2142, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1462, Loss: 5.7641, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1463, Loss: 5.0133, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1464, Loss: 4.8590, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1465, Loss: 5.3757, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1466, Loss: 5.2784, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1467, Loss: 5.4190, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1468, Loss: 5.2886, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1469, Loss: 5.7171, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1470, Loss: 4.8622, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1471, Loss: 5.8432, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1472, Loss: 4.7915, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1473, Loss: 5.2982, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1474, Loss: 3.1131, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1475, Loss: 4.6475, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1476, Loss: 6.0305, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1477, Loss: 5.5257, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1478, Loss: 5.3177, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1479, Loss: 5.3451, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1480, Loss: 5.1006, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1481, Loss: 5.4958, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1482, Loss: 6.0074, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1483, Loss: 5.6967, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1484, Loss: 5.2244, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1485, Loss: 5.1430, LR: 0.000043, Memory: 1421.12 MB\n",
            "Epoch 3/5, Avg Loss: 22.1331, Time: 535.95s, Speed: 44.35 examples/s\n",
            "Model weights saved to /content/drive/MyDrive/LLM/custom_llm_epoch_5.pth\n",
            "Step 1, Loss: 5.2597, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 2, Loss: 5.5665, LR: 0.000010, Memory: 1356.09 MB\n",
            "Step 3, Loss: 5.4101, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 4, Loss: 5.9712, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 5, Loss: 5.7101, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 6, Loss: 5.3524, LR: 0.000010, Memory: 1356.09 MB\n",
            "Step 7, Loss: 5.5225, LR: 0.000010, Memory: 1356.09 MB\n",
            "Step 8, Loss: 5.1653, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 9, Loss: 5.3791, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 10, Loss: 6.3704, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 11, Loss: 5.8195, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 12, Loss: 5.6155, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 13, Loss: 5.1059, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 14, Loss: 5.1608, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 15, Loss: 5.5290, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 16, Loss: 5.1363, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 17, Loss: 4.6580, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 18, Loss: 5.5639, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 19, Loss: 5.5466, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 20, Loss: 5.3713, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 21, Loss: 5.8239, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 22, Loss: 5.2312, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 23, Loss: 5.4401, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 24, Loss: 5.2626, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 25, Loss: 5.2737, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 26, Loss: 5.3724, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 27, Loss: 5.8683, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 28, Loss: 5.8151, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 29, Loss: 4.9533, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 30, Loss: 5.1591, LR: 0.000012, Memory: 1356.09 MB\n",
            "Step 31, Loss: 5.1469, LR: 0.000012, Memory: 1356.09 MB\n",
            "Step 32, Loss: 4.7463, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 33, Loss: 5.3368, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 34, Loss: 5.4804, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 35, Loss: 5.1387, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 36, Loss: 5.1127, LR: 0.000012, Memory: 1356.09 MB\n",
            "Step 37, Loss: 5.0960, LR: 0.000012, Memory: 1356.09 MB\n",
            "Step 38, Loss: 5.4249, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 39, Loss: 4.9094, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 40, Loss: 5.5736, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 41, Loss: 5.3932, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 42, Loss: 5.7250, LR: 0.000012, Memory: 1356.09 MB\n",
            "Step 43, Loss: 5.2271, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 44, Loss: 5.0547, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 45, Loss: 5.7015, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 46, Loss: 5.1046, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 47, Loss: 5.4918, LR: 0.000012, Memory: 1356.09 MB\n",
            "Step 48, Loss: 5.2076, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 49, Loss: 5.2943, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 50, Loss: 4.9370, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 51, Loss: 4.9188, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 52, Loss: 4.6202, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 53, Loss: 5.5015, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 54, Loss: 4.9635, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 55, Loss: 5.1213, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 56, Loss: 5.2040, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 57, Loss: 5.1307, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 58, Loss: 5.1354, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 59, Loss: 5.3822, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 60, Loss: 5.8395, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 61, Loss: 5.7265, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 62, Loss: 5.7888, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 63, Loss: 5.2133, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 64, Loss: 4.9923, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 65, Loss: 4.4419, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 66, Loss: 5.3742, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 67, Loss: 5.2467, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 68, Loss: 4.6085, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 69, Loss: 5.7055, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 70, Loss: 5.1169, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 71, Loss: 5.8070, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 72, Loss: 5.6230, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 73, Loss: 5.2816, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 74, Loss: 5.3185, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 75, Loss: 5.3813, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 76, Loss: 5.2539, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 77, Loss: 5.1376, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 78, Loss: 5.4579, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 79, Loss: 5.7831, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 80, Loss: 5.1525, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 81, Loss: 5.4110, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 82, Loss: 5.5248, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 83, Loss: 5.2774, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 84, Loss: 5.2082, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 85, Loss: 5.3579, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 86, Loss: 5.2361, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 87, Loss: 5.3887, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 88, Loss: 5.1907, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 89, Loss: 5.1011, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 90, Loss: 5.1960, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 91, Loss: 3.8457, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 92, Loss: 5.8428, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 93, Loss: 5.2212, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 94, Loss: 5.3233, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 95, Loss: 5.6604, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 96, Loss: 5.4873, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 97, Loss: 5.7738, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 98, Loss: 5.4953, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 99, Loss: 6.0630, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 100, Loss: 5.7404, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 101, Loss: 4.3558, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 102, Loss: 5.4361, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 103, Loss: 5.3622, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 104, Loss: 5.4108, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 105, Loss: 5.4273, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 106, Loss: 2.8368, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 107, Loss: 5.7052, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 108, Loss: 0.8537, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 109, Loss: 5.5001, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 110, Loss: 4.1052, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 111, Loss: 5.0504, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 112, Loss: 5.4681, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 113, Loss: 5.2235, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 114, Loss: 4.7662, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 115, Loss: 5.7649, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 116, Loss: 5.2371, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 117, Loss: 5.3043, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 118, Loss: 5.5222, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 119, Loss: 4.6678, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 120, Loss: 5.4166, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 121, Loss: 5.5498, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 122, Loss: 5.2297, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 123, Loss: 4.6770, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 124, Loss: 5.5537, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 125, Loss: 5.1594, LR: 0.000017, Memory: 1356.09 MB\n",
            "Step 126, Loss: 4.3581, LR: 0.000017, Memory: 1356.09 MB\n",
            "Step 127, Loss: 5.6410, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 128, Loss: 4.9706, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 129, Loss: 5.4085, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 130, Loss: 2.9448, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 131, Loss: 6.2019, LR: 0.000017, Memory: 1356.09 MB\n",
            "Step 132, Loss: 5.0406, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 133, Loss: 5.6576, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 134, Loss: 5.4123, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 135, Loss: 5.3453, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 136, Loss: 5.7273, LR: 0.000017, Memory: 1356.09 MB\n",
            "Step 137, Loss: 5.6540, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 138, Loss: 5.1552, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 139, Loss: 5.6565, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 140, Loss: 5.2279, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 141, Loss: 5.9121, LR: 0.000018, Memory: 1356.09 MB\n",
            "Step 142, Loss: 5.2099, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 143, Loss: 5.4900, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 144, Loss: 4.7390, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 145, Loss: 4.5748, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 146, Loss: 6.0618, LR: 0.000018, Memory: 1356.09 MB\n",
            "Step 147, Loss: 4.5704, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 148, Loss: 4.7264, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 149, Loss: 5.3427, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 150, Loss: 5.4293, LR: 0.000018, Memory: 1356.09 MB\n",
            "Step 151, Loss: 5.7690, LR: 0.000018, Memory: 1356.09 MB\n",
            "Step 152, Loss: 5.2769, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 153, Loss: 5.5170, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 154, Loss: 5.4917, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 155, Loss: 5.2598, LR: 0.000018, Memory: 1356.09 MB\n",
            "Step 156, Loss: 5.7858, LR: 0.000018, Memory: 1356.09 MB\n",
            "Step 157, Loss: 5.7497, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 158, Loss: 5.0886, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 159, Loss: 5.3993, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 160, Loss: 4.5889, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 161, Loss: 5.5992, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 162, Loss: 5.0146, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 163, Loss: 5.6095, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 164, Loss: 5.4570, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 165, Loss: 5.4272, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 166, Loss: 4.9299, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 167, Loss: 4.9579, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 168, Loss: 5.7071, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 169, Loss: 5.5475, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 170, Loss: 5.4138, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 171, Loss: 4.4169, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 172, Loss: 5.5518, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 173, Loss: 5.6721, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 174, Loss: 5.3706, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 175, Loss: 5.3963, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 176, Loss: 5.9521, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 177, Loss: 5.3082, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 178, Loss: 4.1436, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 179, Loss: 4.5909, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 180, Loss: 5.5727, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 181, Loss: 5.9618, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 182, Loss: 5.3243, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 183, Loss: 5.2500, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 184, Loss: 5.0933, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 185, Loss: 5.5662, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 186, Loss: 4.1523, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 187, Loss: 5.5030, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 188, Loss: 5.5036, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 189, Loss: 5.9801, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 190, Loss: 5.5758, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 191, Loss: 4.8370, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 192, Loss: 4.8314, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 193, Loss: 5.6063, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 194, Loss: 5.4407, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 195, Loss: 5.2018, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 196, Loss: 5.1809, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 197, Loss: 4.9558, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 198, Loss: 5.4546, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 199, Loss: 6.1879, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 200, Loss: 5.0692, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 201, Loss: 5.6988, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 202, Loss: 4.7231, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 203, Loss: 5.3180, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 204, Loss: 5.3913, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 205, Loss: 5.3556, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 206, Loss: 4.9282, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 207, Loss: 5.0525, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 208, Loss: 5.5284, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 209, Loss: 5.3111, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 210, Loss: 4.9217, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 211, Loss: 4.9704, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 212, Loss: 5.0428, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 213, Loss: 5.5616, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 214, Loss: 5.0610, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 215, Loss: 4.8632, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 216, Loss: 5.2979, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 217, Loss: 5.5462, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 218, Loss: 5.2544, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 219, Loss: 5.2423, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 220, Loss: 5.6783, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 221, Loss: 5.4377, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 222, Loss: 5.5744, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 223, Loss: 5.1884, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 224, Loss: 5.3840, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 225, Loss: 4.9091, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 226, Loss: 4.9810, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 227, Loss: 5.2557, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 228, Loss: 5.9643, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 229, Loss: 5.4891, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 230, Loss: 4.9513, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 231, Loss: 5.0228, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 232, Loss: 5.2829, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 233, Loss: 5.2008, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 234, Loss: 5.2196, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 235, Loss: 5.3607, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 236, Loss: 5.1625, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 237, Loss: 5.5300, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 238, Loss: 5.1961, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 239, Loss: 5.4544, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 240, Loss: 5.2417, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 241, Loss: 4.6637, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 242, Loss: 5.2762, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 243, Loss: 5.0639, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 244, Loss: 5.0060, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 245, Loss: 3.5775, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 246, Loss: 4.6772, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 247, Loss: 5.4411, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 248, Loss: 5.1347, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 249, Loss: 4.9719, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 250, Loss: 5.4164, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 251, Loss: 4.8730, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 252, Loss: 5.6950, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 253, Loss: 5.3419, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 254, Loss: 5.5064, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 255, Loss: 5.5802, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 256, Loss: 5.5945, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 257, Loss: 5.4873, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 258, Loss: 5.3414, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 259, Loss: 4.9519, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 260, Loss: 5.7037, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 261, Loss: 5.7345, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 262, Loss: 5.2894, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 263, Loss: 5.2210, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 264, Loss: 5.2649, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 265, Loss: 5.2051, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 266, Loss: 5.4726, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 267, Loss: 3.7007, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 268, Loss: 5.2765, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 269, Loss: 5.3595, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 270, Loss: 4.8599, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 271, Loss: 4.4346, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 272, Loss: 5.9184, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 273, Loss: 5.3990, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 274, Loss: 5.7100, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 275, Loss: 5.1997, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 276, Loss: 5.7338, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 277, Loss: 5.0567, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 278, Loss: 5.5741, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 279, Loss: 5.5364, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 280, Loss: 5.1834, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 281, Loss: 5.4671, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 282, Loss: 5.1447, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 283, Loss: 5.2967, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 284, Loss: 5.3877, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 285, Loss: 5.7185, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 286, Loss: 5.9035, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 287, Loss: 5.2310, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 288, Loss: 5.1714, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 289, Loss: 4.9724, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 290, Loss: 5.7738, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 291, Loss: 5.3295, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 292, Loss: 5.4403, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 293, Loss: 4.7666, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 294, Loss: 5.3015, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 295, Loss: 4.6056, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 296, Loss: 5.7342, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 297, Loss: 5.3268, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 298, Loss: 4.6030, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 299, Loss: 5.5354, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 300, Loss: 5.8607, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 301, Loss: 5.0992, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 302, Loss: 5.3051, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 303, Loss: 5.7447, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 304, Loss: 5.6134, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 305, Loss: 6.0043, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 306, Loss: 5.5170, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 307, Loss: 4.9329, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 308, Loss: 5.6419, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 309, Loss: 5.6934, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 310, Loss: 5.2848, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 311, Loss: 5.1015, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 312, Loss: 5.7730, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 313, Loss: 1.5081, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 314, Loss: 5.3091, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 315, Loss: 5.4070, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 316, Loss: 5.6892, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 317, Loss: 5.5128, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 318, Loss: 5.3159, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 319, Loss: 5.1715, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 320, Loss: 5.0729, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 321, Loss: 5.4685, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 322, Loss: 4.1553, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 323, Loss: 5.6955, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 324, Loss: 5.0276, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 325, Loss: 5.7787, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 326, Loss: 5.6031, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 327, Loss: 4.9162, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 328, Loss: 5.0975, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 329, Loss: 5.1798, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 330, Loss: 4.6109, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 331, Loss: 5.6697, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 332, Loss: 4.7494, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 333, Loss: 5.1064, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 334, Loss: 5.7850, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 335, Loss: 5.5543, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 336, Loss: 5.6655, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 337, Loss: 5.0824, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 338, Loss: 4.7685, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 339, Loss: 5.0901, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 340, Loss: 5.6094, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 341, Loss: 5.1668, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 342, Loss: 5.3355, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 343, Loss: 5.1816, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 344, Loss: 5.6747, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 345, Loss: 5.5276, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 346, Loss: 5.6318, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 347, Loss: 4.7941, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 348, Loss: 5.4126, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 349, Loss: 4.7686, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 350, Loss: 5.2329, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 351, Loss: 5.7274, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 352, Loss: 5.1665, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 353, Loss: 4.8251, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 354, Loss: 5.1217, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 355, Loss: 5.1322, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 356, Loss: 5.2438, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 357, Loss: 5.4755, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 358, Loss: 5.1555, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 359, Loss: 4.7315, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 360, Loss: 5.3477, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 361, Loss: 5.6660, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 362, Loss: 4.7769, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 363, Loss: 4.7235, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 364, Loss: 5.6811, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 365, Loss: 5.3441, LR: 0.000030, Memory: 1356.09 MB\n",
            "Step 366, Loss: 4.9947, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 367, Loss: 5.5707, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 368, Loss: 4.8861, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 369, Loss: 6.3224, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 370, Loss: 5.4227, LR: 0.000030, Memory: 1356.09 MB\n",
            "Step 371, Loss: 5.3895, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 372, Loss: 5.6625, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 373, Loss: 5.4779, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 374, Loss: 5.2895, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 375, Loss: 5.1372, LR: 0.000030, Memory: 1356.09 MB\n",
            "Step 376, Loss: 5.2651, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 377, Loss: 5.1186, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 378, Loss: 5.2260, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 379, Loss: 5.0515, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 380, Loss: 4.9856, LR: 0.000030, Memory: 1356.09 MB\n",
            "Step 381, Loss: 5.5702, LR: 0.000030, Memory: 1356.09 MB\n",
            "Step 382, Loss: 5.2328, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 383, Loss: 5.3465, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 384, Loss: 5.2412, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 385, Loss: 5.6242, LR: 0.000031, Memory: 1356.09 MB\n",
            "Step 386, Loss: 5.3227, LR: 0.000031, Memory: 1356.09 MB\n",
            "Step 387, Loss: 5.2951, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 388, Loss: 5.2692, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 389, Loss: 5.3349, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 390, Loss: 5.4540, LR: 0.000031, Memory: 1356.09 MB\n",
            "Step 391, Loss: 5.2598, LR: 0.000031, Memory: 1356.09 MB\n",
            "Step 392, Loss: 5.0618, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 393, Loss: 5.3741, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 394, Loss: 5.0732, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 395, Loss: 5.3829, LR: 0.000031, Memory: 1356.09 MB\n",
            "Step 396, Loss: 5.8486, LR: 0.000031, Memory: 1356.09 MB\n",
            "Step 397, Loss: 4.9959, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 398, Loss: 4.9915, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 399, Loss: 5.1924, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 400, Loss: 4.9370, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 401, Loss: 5.8263, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 402, Loss: 4.7355, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 403, Loss: 5.2208, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 404, Loss: 5.0528, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 405, Loss: 5.7106, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 406, Loss: 5.5023, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 407, Loss: 5.0619, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 408, Loss: 5.5966, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 409, Loss: 5.1280, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 410, Loss: 5.2750, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 411, Loss: 5.1574, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 412, Loss: 5.7820, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 413, Loss: 4.6513, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 414, Loss: 3.4629, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 415, Loss: 4.7494, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 416, Loss: 5.7349, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 417, Loss: 5.8723, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 418, Loss: 5.8082, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 419, Loss: 5.3065, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 420, Loss: 4.8483, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 421, Loss: 5.3152, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 422, Loss: 4.5487, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 423, Loss: 5.5806, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 424, Loss: 5.0822, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 425, Loss: 5.6147, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 426, Loss: 5.5260, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 427, Loss: 5.0139, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 428, Loss: 5.4881, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 429, Loss: 3.5292, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 430, Loss: 5.1380, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 431, Loss: 5.9169, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 432, Loss: 5.6817, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 433, Loss: 5.1508, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 434, Loss: 4.9831, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 435, Loss: 5.3772, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 436, Loss: 5.0801, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 437, Loss: 5.2517, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 438, Loss: 5.4810, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 439, Loss: 4.8064, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 440, Loss: 5.1127, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 441, Loss: 5.5633, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 442, Loss: 5.4226, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 443, Loss: 5.3957, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 444, Loss: 5.3182, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 445, Loss: 5.8729, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 446, Loss: 5.2246, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 447, Loss: 5.4470, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 448, Loss: 5.5870, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 449, Loss: 4.9555, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 450, Loss: 5.4212, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 451, Loss: 5.7070, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 452, Loss: 5.0873, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 453, Loss: 5.5980, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 454, Loss: 5.5732, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 455, Loss: 4.5743, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 456, Loss: 5.4271, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 457, Loss: 4.9095, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 458, Loss: 5.4268, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 459, Loss: 5.2770, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 460, Loss: 4.9493, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 461, Loss: 4.9143, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 462, Loss: 5.7006, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 463, Loss: 5.3594, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 464, Loss: 5.8006, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 465, Loss: 4.8689, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 466, Loss: 6.0172, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 467, Loss: 5.4941, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 468, Loss: 4.9044, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 469, Loss: 4.8747, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 470, Loss: 5.0657, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 471, Loss: 5.2726, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 472, Loss: 4.8140, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 473, Loss: 5.0812, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 474, Loss: 4.9639, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 475, Loss: 5.5536, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 476, Loss: 4.9587, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 477, Loss: 5.0253, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 478, Loss: 3.6496, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 479, Loss: 5.3741, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 480, Loss: 5.3382, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 481, Loss: 4.6881, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 482, Loss: 5.0214, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 483, Loss: 5.9403, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 484, Loss: 5.0285, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 485, Loss: 5.3296, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 486, Loss: 5.9011, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 487, Loss: 5.0007, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 488, Loss: 4.8929, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 489, Loss: 5.5938, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 490, Loss: 5.4842, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 491, Loss: 2.0263, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 492, Loss: 5.8250, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 493, Loss: 5.5197, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 494, Loss: 5.4673, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 495, Loss: 5.8943, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 496, Loss: 4.8563, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 497, Loss: 5.5122, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 498, Loss: 5.4664, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 499, Loss: 4.9351, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 500, Loss: 5.5868, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 501, Loss: 5.3367, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 502, Loss: 5.8442, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 503, Loss: 4.1283, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 504, Loss: 5.1009, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 505, Loss: 5.6393, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 506, Loss: 6.0714, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 507, Loss: 4.9414, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 508, Loss: 4.6850, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 509, Loss: 5.4983, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 510, Loss: 5.6695, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 511, Loss: 5.2893, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 512, Loss: 3.8578, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 513, Loss: 5.5732, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 514, Loss: 5.3439, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 515, Loss: 5.8149, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 516, Loss: 5.1069, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 517, Loss: 5.1685, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 518, Loss: 5.7940, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 519, Loss: 5.3960, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 520, Loss: 5.3214, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 521, Loss: 4.2956, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 522, Loss: 4.8984, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 523, Loss: 5.0304, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 524, Loss: 5.3131, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 525, Loss: 5.7610, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 526, Loss: 5.0657, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 527, Loss: 5.2403, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 528, Loss: 5.2993, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 529, Loss: 5.6302, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 530, Loss: 5.4164, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 531, Loss: 5.3629, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 532, Loss: 6.0997, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 533, Loss: 5.3206, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 534, Loss: 6.1120, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 535, Loss: 5.7131, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 536, Loss: 5.4866, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 537, Loss: 4.7434, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 538, Loss: 5.4214, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 539, Loss: 5.5514, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 540, Loss: 5.5016, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 541, Loss: 5.3951, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 542, Loss: 6.1035, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 543, Loss: 5.2461, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 544, Loss: 5.1891, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 545, Loss: 4.9175, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 546, Loss: 5.3730, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 547, Loss: 5.4916, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 548, Loss: 5.4189, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 549, Loss: 4.0364, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 550, Loss: 5.3306, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 551, Loss: 5.4483, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 552, Loss: 4.1993, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 553, Loss: 5.5970, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 554, Loss: 4.6039, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 555, Loss: 6.0258, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 556, Loss: 5.5463, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 557, Loss: 5.6055, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 558, Loss: 5.2170, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 559, Loss: 5.2703, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 560, Loss: 4.9889, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 561, Loss: 5.1331, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 562, Loss: 5.5450, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 563, Loss: 5.4754, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 564, Loss: 5.5323, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 565, Loss: 5.3404, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 566, Loss: 5.1832, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 567, Loss: 4.8069, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 568, Loss: 5.1552, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 569, Loss: 5.0910, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 570, Loss: 5.1024, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 571, Loss: 4.7343, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 572, Loss: 5.4958, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 573, Loss: 5.2862, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 574, Loss: 5.2117, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 575, Loss: 5.6823, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 576, Loss: 5.1042, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 577, Loss: 5.5430, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 578, Loss: 5.0672, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 579, Loss: 5.5200, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 580, Loss: 5.2349, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 581, Loss: 5.4534, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 582, Loss: 5.7068, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 583, Loss: 5.3397, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 584, Loss: 5.3813, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 585, Loss: 5.3943, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 586, Loss: 5.3756, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 587, Loss: 5.5580, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 588, Loss: 5.7906, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 589, Loss: 4.6863, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 590, Loss: 5.5502, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 591, Loss: 5.1297, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 592, Loss: 5.3699, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 593, Loss: 5.3987, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 594, Loss: 5.3016, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 595, Loss: 5.1510, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 596, Loss: 5.2634, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 597, Loss: 5.0353, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 598, Loss: 5.9210, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 599, Loss: 5.5433, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 600, Loss: 5.6897, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 601, Loss: 5.4117, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 602, Loss: 6.0034, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 603, Loss: 5.5452, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 604, Loss: 5.5737, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 605, Loss: 4.2816, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 606, Loss: 5.0337, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 607, Loss: 5.4945, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 608, Loss: 5.2691, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 609, Loss: 5.3672, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 610, Loss: 5.0268, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 611, Loss: 5.2464, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 612, Loss: 4.8520, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 613, Loss: 5.1594, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 614, Loss: 5.4829, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 615, Loss: 5.2113, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 616, Loss: 4.9751, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 617, Loss: 4.8519, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 618, Loss: 5.3207, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 619, Loss: 4.6370, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 620, Loss: 4.5595, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 621, Loss: 5.3404, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 622, Loss: 5.4100, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 623, Loss: 5.1049, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 624, Loss: 5.6140, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 625, Loss: 5.4913, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 626, Loss: 5.7084, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 627, Loss: 5.2981, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 628, Loss: 5.3226, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 629, Loss: 5.0772, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 630, Loss: 5.8157, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 631, Loss: 4.9312, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 632, Loss: 5.0432, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 633, Loss: 5.7295, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 634, Loss: 5.4344, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 635, Loss: 4.9504, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 636, Loss: 4.7980, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 637, Loss: 5.5784, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 638, Loss: 5.4815, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 639, Loss: 5.3585, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 640, Loss: 5.6677, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 641, Loss: 5.4874, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 642, Loss: 3.3797, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 643, Loss: 4.4329, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 644, Loss: 5.3590, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 645, Loss: 6.0180, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 646, Loss: 4.8336, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 647, Loss: 5.3285, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 648, Loss: 3.6272, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 649, Loss: 5.7043, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 650, Loss: 5.3510, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 651, Loss: 4.7692, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 652, Loss: 5.6660, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 653, Loss: 5.7085, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 654, Loss: 5.0990, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 655, Loss: 5.6753, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 656, Loss: 4.8100, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 657, Loss: 3.9858, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 658, Loss: 5.8314, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 659, Loss: 4.9464, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 660, Loss: 5.5731, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 661, Loss: 5.7810, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 662, Loss: 5.6367, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 663, Loss: 4.9576, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 664, Loss: 5.7589, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 665, Loss: 4.0630, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 666, Loss: 4.9330, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 667, Loss: 5.5903, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 668, Loss: 5.4419, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 669, Loss: 4.9636, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 670, Loss: 5.7271, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 671, Loss: 4.7007, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 672, Loss: 5.3511, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 673, Loss: 5.5552, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 674, Loss: 5.1742, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 675, Loss: 5.1041, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 676, Loss: 5.4165, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 677, Loss: 5.5098, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 678, Loss: 5.7909, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 679, Loss: 4.8874, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 680, Loss: 4.9134, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 681, Loss: 5.2015, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 682, Loss: 5.1543, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 683, Loss: 5.4593, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 684, Loss: 5.3401, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 685, Loss: 5.8579, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 686, Loss: 5.4281, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 687, Loss: 5.0780, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 688, Loss: 5.7186, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 689, Loss: 5.5162, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 690, Loss: 5.5769, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 691, Loss: 5.7017, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 692, Loss: 4.8411, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 693, Loss: 4.8284, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 694, Loss: 5.6125, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 695, Loss: 5.3585, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 696, Loss: 4.0679, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 697, Loss: 5.3069, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 698, Loss: 5.7923, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 699, Loss: 5.2196, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 700, Loss: 5.0942, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 701, Loss: 5.0446, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 702, Loss: 4.6079, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 703, Loss: 6.0560, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 704, Loss: 5.3532, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 705, Loss: 5.3100, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 706, Loss: 5.2182, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 707, Loss: 4.8218, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 708, Loss: 5.6026, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 709, Loss: 5.4561, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 710, Loss: 4.9943, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 711, Loss: 4.9687, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 712, Loss: 5.5748, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 713, Loss: 5.1516, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 714, Loss: 5.2881, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 715, Loss: 5.3978, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 716, Loss: 5.4430, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 717, Loss: 5.5168, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 718, Loss: 5.1540, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 719, Loss: 4.5129, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 720, Loss: 5.3265, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 721, Loss: 5.1086, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 722, Loss: 4.7921, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 723, Loss: 5.5566, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 724, Loss: 4.8799, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 725, Loss: 5.1889, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 726, Loss: 5.3699, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 727, Loss: 5.3359, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 728, Loss: 5.2972, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 729, Loss: 5.5747, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 730, Loss: 5.3235, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 731, Loss: 5.3708, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 732, Loss: 5.6764, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 733, Loss: 5.6455, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 734, Loss: 5.6536, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 735, Loss: 5.0335, LR: 0.000050, Memory: 1356.10 MB\n",
            "Step 736, Loss: 5.2223, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 737, Loss: 5.7931, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 738, Loss: 5.1303, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 739, Loss: 5.3020, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 740, Loss: 5.5092, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 741, Loss: 5.0345, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 742, Loss: 5.0309, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 743, Loss: 4.6742, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 744, Loss: 5.5248, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 745, Loss: 5.1648, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 746, Loss: 5.6614, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 747, Loss: 5.0080, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 748, Loss: 5.8146, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 749, Loss: 4.5767, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 750, Loss: 5.3449, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 751, Loss: 5.2433, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 752, Loss: 5.4110, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 753, Loss: 5.3722, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 754, Loss: 4.9272, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 755, Loss: 5.3608, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 756, Loss: 5.1504, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 757, Loss: 5.5798, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 758, Loss: 5.5129, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 759, Loss: 5.4071, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 760, Loss: 5.1357, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 761, Loss: 5.5276, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 762, Loss: 5.4013, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 763, Loss: 5.1820, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 764, Loss: 5.0722, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 765, Loss: 5.2708, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 766, Loss: 5.7799, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 767, Loss: 5.5517, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 768, Loss: 5.2181, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 769, Loss: 4.4904, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 770, Loss: 5.4215, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 771, Loss: 5.1423, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 772, Loss: 5.3411, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 773, Loss: 5.7768, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 774, Loss: 5.9287, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 775, Loss: 5.1097, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 776, Loss: 5.3620, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 777, Loss: 5.5608, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 778, Loss: 4.9424, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 779, Loss: 5.7300, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 780, Loss: 5.4472, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 781, Loss: 4.9399, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 782, Loss: 4.6800, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 783, Loss: 5.1702, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 784, Loss: 5.7133, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 785, Loss: 5.2177, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 786, Loss: 4.7730, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 787, Loss: 5.4188, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 788, Loss: 5.6191, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 789, Loss: 5.3035, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 790, Loss: 5.2280, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 791, Loss: 5.6662, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 792, Loss: 5.1629, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 793, Loss: 5.5618, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 794, Loss: 4.2550, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 795, Loss: 5.2012, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 796, Loss: 5.5430, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 797, Loss: 5.3727, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 798, Loss: 4.1004, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 799, Loss: 4.6292, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 800, Loss: 5.1485, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 801, Loss: 5.4278, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 802, Loss: 5.2046, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 803, Loss: 5.1875, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 804, Loss: 5.3140, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 805, Loss: 5.1846, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 806, Loss: 5.7164, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 807, Loss: 4.7110, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 808, Loss: 2.1626, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 809, Loss: 4.9864, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 810, Loss: 5.0306, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 811, Loss: 5.0097, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 812, Loss: 5.4156, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 813, Loss: 5.8615, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 814, Loss: 5.1328, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 815, Loss: 4.3823, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 816, Loss: 5.0996, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 817, Loss: 5.4607, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 818, Loss: 5.3587, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 819, Loss: 5.2716, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 820, Loss: 4.9357, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 821, Loss: 5.5291, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 822, Loss: 5.2991, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 823, Loss: 5.2744, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 824, Loss: 5.6786, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 825, Loss: 5.4853, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 826, Loss: 4.8703, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 827, Loss: 5.4376, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 828, Loss: 5.2963, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 829, Loss: 5.2195, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 830, Loss: 5.6386, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 831, Loss: 5.4733, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 832, Loss: 5.6033, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 833, Loss: 5.2525, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 834, Loss: 5.6835, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 835, Loss: 5.3062, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 836, Loss: 5.3366, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 837, Loss: 4.9959, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 838, Loss: 5.9721, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 839, Loss: 5.0042, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 840, Loss: 5.1346, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 841, Loss: 5.5672, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 842, Loss: 6.0389, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 843, Loss: 5.4122, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 844, Loss: 5.2596, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 845, Loss: 4.9855, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 846, Loss: 5.0891, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 847, Loss: 5.3576, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 848, Loss: 5.4680, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 849, Loss: 5.0631, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 850, Loss: 5.1549, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 851, Loss: 5.5445, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 852, Loss: 5.3101, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 853, Loss: 5.2625, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 854, Loss: 5.4292, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 855, Loss: 4.5504, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 856, Loss: 5.2002, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 857, Loss: 5.3413, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 858, Loss: 5.2786, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 859, Loss: 5.5420, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 860, Loss: 5.6697, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 861, Loss: 5.7542, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 862, Loss: 5.4668, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 863, Loss: 5.1687, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 864, Loss: 6.1359, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 865, Loss: 5.5134, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 866, Loss: 5.3991, LR: 0.000048, Memory: 1356.10 MB\n",
            "Step 867, Loss: 5.1041, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 868, Loss: 5.5734, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 869, Loss: 5.5832, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 870, Loss: 5.6141, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 871, Loss: 5.8167, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 872, Loss: 5.2744, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 873, Loss: 6.0166, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 874, Loss: 4.7400, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 875, Loss: 4.8815, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 876, Loss: 5.0031, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 877, Loss: 5.7753, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 878, Loss: 4.7400, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 879, Loss: 5.0467, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 880, Loss: 5.5204, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 881, Loss: 5.7221, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 882, Loss: 5.3956, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 883, Loss: 5.0906, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 884, Loss: 5.6200, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 885, Loss: 5.4866, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 886, Loss: 5.1334, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 887, Loss: 5.4582, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 888, Loss: 5.7348, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 889, Loss: 5.0365, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 890, Loss: 5.1428, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 891, Loss: 4.6040, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 892, Loss: 5.4402, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 893, Loss: 4.8957, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 894, Loss: 5.0116, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 895, Loss: 5.1783, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 896, Loss: 5.6459, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 897, Loss: 5.8216, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 898, Loss: 5.4919, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 899, Loss: 5.0615, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 900, Loss: 5.3628, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 901, Loss: 5.0433, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 902, Loss: 5.5760, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 903, Loss: 5.1682, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 904, Loss: 5.3289, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 905, Loss: 5.0234, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 906, Loss: 5.5699, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 907, Loss: 5.1088, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 908, Loss: 5.1242, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 909, Loss: 5.1932, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 910, Loss: 4.9371, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 911, Loss: 5.1359, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 912, Loss: 4.7200, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 913, Loss: 4.8877, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 914, Loss: 4.3074, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 915, Loss: 4.3928, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 916, Loss: 5.6445, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 917, Loss: 5.0859, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 918, Loss: 5.3447, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 919, Loss: 4.4549, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 920, Loss: 1.4261, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 921, Loss: 5.6531, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 922, Loss: 4.9663, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 923, Loss: 5.6650, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 924, Loss: 5.3031, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 925, Loss: 6.4726, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 926, Loss: 5.4491, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 927, Loss: 5.2198, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 928, Loss: 5.7338, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 929, Loss: 5.2590, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 930, Loss: 5.0557, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 931, Loss: 5.2418, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 932, Loss: 4.7237, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 933, Loss: 4.9985, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 934, Loss: 5.4144, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 935, Loss: 5.1633, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 936, Loss: 5.4608, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 937, Loss: 5.4624, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 938, Loss: 5.3434, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 939, Loss: 5.5599, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 940, Loss: 5.2704, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 941, Loss: 4.9320, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 942, Loss: 5.5931, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 943, Loss: 5.2253, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 944, Loss: 5.3961, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 945, Loss: 5.2971, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 946, Loss: 4.9610, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 947, Loss: 4.8065, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 948, Loss: 5.6069, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 949, Loss: 5.2449, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 950, Loss: 5.1156, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 951, Loss: 5.2477, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 952, Loss: 5.3424, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 953, Loss: 5.5747, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 954, Loss: 5.5972, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 955, Loss: 4.9818, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 956, Loss: 5.2172, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 957, Loss: 5.3811, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 958, Loss: 5.7497, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 959, Loss: 5.5018, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 960, Loss: 5.7367, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 961, Loss: 5.4491, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 962, Loss: 5.4470, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 963, Loss: 5.5436, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 964, Loss: 4.6015, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 965, Loss: 5.2219, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 966, Loss: 5.1735, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 967, Loss: 5.3253, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 968, Loss: 4.8702, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 969, Loss: 5.8210, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 970, Loss: 5.1045, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 971, Loss: 5.1932, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 972, Loss: 4.8903, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 973, Loss: 4.6900, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 974, Loss: 5.3503, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 975, Loss: 5.0141, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 976, Loss: 5.9799, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 977, Loss: 5.4388, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 978, Loss: 5.0123, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 979, Loss: 2.5609, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 980, Loss: 5.4988, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 981, Loss: 5.0864, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 982, Loss: 5.3885, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 983, Loss: 4.7650, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 984, Loss: 5.3531, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 985, Loss: 5.4315, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 986, Loss: 4.8345, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 987, Loss: 4.1697, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 988, Loss: 5.3347, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 989, Loss: 3.9507, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 990, Loss: 5.3782, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 991, Loss: 5.6654, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 992, Loss: 5.9145, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 993, Loss: 5.1016, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 994, Loss: 5.3470, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 995, Loss: 5.2490, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 996, Loss: 5.0368, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 997, Loss: 5.7568, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 998, Loss: 5.8441, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 999, Loss: 5.3394, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1000, Loss: 5.5021, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1001, Loss: 5.4218, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1002, Loss: 5.2794, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1003, Loss: 4.8018, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1004, Loss: 5.1657, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1005, Loss: 5.4749, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1006, Loss: 4.9068, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1007, Loss: 5.1088, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1008, Loss: 5.0101, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1009, Loss: 5.1843, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1010, Loss: 4.7775, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1011, Loss: 4.3553, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1012, Loss: 5.4130, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1013, Loss: 4.9185, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1014, Loss: 5.2111, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1015, Loss: 5.2565, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1016, Loss: 4.9601, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1017, Loss: 5.5252, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1018, Loss: 5.5186, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1019, Loss: 4.7963, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1020, Loss: 4.6790, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1021, Loss: 5.3562, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1022, Loss: 5.1498, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1023, Loss: 5.6263, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1024, Loss: 5.1769, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1025, Loss: 3.6119, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1026, Loss: 4.4178, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1027, Loss: 5.4648, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1028, Loss: 4.9073, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1029, Loss: 5.0925, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1030, Loss: 5.6162, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1031, Loss: 4.8608, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1032, Loss: 5.6883, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1033, Loss: 5.4016, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1034, Loss: 5.7249, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1035, Loss: 5.0560, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1036, Loss: 5.4921, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1037, Loss: 5.3930, LR: 0.000046, Memory: 1421.13 MB\n",
            "Step 1038, Loss: 4.9435, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1039, Loss: 5.1381, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1040, Loss: 4.2875, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1041, Loss: 5.3132, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1042, Loss: 5.5318, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1043, Loss: 5.5618, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1044, Loss: 5.0735, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1045, Loss: 5.3808, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1046, Loss: 5.2227, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1047, Loss: 5.2123, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1048, Loss: 5.7196, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1049, Loss: 5.6518, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1050, Loss: 4.6305, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1051, Loss: 5.0715, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1052, Loss: 3.4216, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1053, Loss: 5.4037, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1054, Loss: 5.5595, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1055, Loss: 5.4955, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1056, Loss: 5.7660, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1057, Loss: 5.0129, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1058, Loss: 5.5838, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1059, Loss: 5.4863, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1060, Loss: 5.6536, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1061, Loss: 5.0756, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 1062, Loss: 4.9993, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1063, Loss: 5.4455, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 1064, Loss: 4.5613, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1065, Loss: 5.0197, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1066, Loss: 5.2012, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1067, Loss: 5.0918, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1068, Loss: 5.5028, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1069, Loss: 5.0124, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1070, Loss: 5.6904, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1071, Loss: 5.2588, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1072, Loss: 5.1686, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1073, Loss: 5.2414, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1074, Loss: 4.3779, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1075, Loss: 3.7186, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1076, Loss: 5.3140, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1077, Loss: 5.3125, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1078, Loss: 5.1868, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1079, Loss: 5.1381, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1080, Loss: 5.3757, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1081, Loss: 5.5070, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1082, Loss: 5.0563, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1083, Loss: 5.1020, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1084, Loss: 5.4259, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1085, Loss: 5.2057, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1086, Loss: 4.7870, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1087, Loss: 4.9996, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1088, Loss: 4.9870, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1089, Loss: 5.2077, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1090, Loss: 5.2115, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1091, Loss: 5.2360, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1092, Loss: 5.4218, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1093, Loss: 5.2059, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1094, Loss: 4.8277, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1095, Loss: 4.7793, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1096, Loss: 5.1111, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1097, Loss: 5.3886, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1098, Loss: 4.8195, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1099, Loss: 5.2250, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1100, Loss: 5.0014, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1101, Loss: 5.1484, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1102, Loss: 5.5640, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1103, Loss: 3.7096, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1104, Loss: 5.2007, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1105, Loss: 5.3309, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1106, Loss: 4.7376, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1107, Loss: 5.8202, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1108, Loss: 4.3803, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1109, Loss: 5.2031, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1110, Loss: 4.6935, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1111, Loss: 4.7017, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1112, Loss: 4.4730, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1113, Loss: 6.1246, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1114, Loss: 5.6400, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1115, Loss: 5.1273, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1116, Loss: 4.6788, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1117, Loss: 4.3187, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1118, Loss: 5.5076, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1119, Loss: 4.8157, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1120, Loss: 5.5625, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1121, Loss: 5.2517, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1122, Loss: 5.0106, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1123, Loss: 5.5460, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1124, Loss: 4.5829, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1125, Loss: 5.0813, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1126, Loss: 4.6707, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1127, Loss: 4.4182, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1128, Loss: 5.1973, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1129, Loss: 4.6171, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1130, Loss: 5.2118, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1131, Loss: 4.9419, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1132, Loss: 5.0158, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1133, Loss: 5.3026, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1134, Loss: 5.4984, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1135, Loss: 4.9069, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1136, Loss: 4.6925, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1137, Loss: 5.3110, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1138, Loss: 5.2565, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1139, Loss: 5.6643, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1140, Loss: 5.1895, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1141, Loss: 5.4653, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1142, Loss: 4.5208, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1143, Loss: 5.1607, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1144, Loss: 5.6097, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1145, Loss: 5.5403, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1146, Loss: 5.5903, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1147, Loss: 5.1672, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1148, Loss: 5.2071, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1149, Loss: 4.8930, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1150, Loss: 4.7109, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1151, Loss: 5.8051, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1152, Loss: 5.1668, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1153, Loss: 5.2698, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1154, Loss: 4.7665, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1155, Loss: 5.0505, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1156, Loss: 5.5191, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1157, Loss: 5.3459, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1158, Loss: 4.8259, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1159, Loss: 5.6177, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1160, Loss: 5.6475, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1161, Loss: 5.5212, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1162, Loss: 5.5306, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1163, Loss: 5.4154, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1164, Loss: 4.4973, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1165, Loss: 5.1406, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1166, Loss: 5.2342, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1167, Loss: 5.6595, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1168, Loss: 5.0948, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1169, Loss: 5.6971, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1170, Loss: 4.6377, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1171, Loss: 4.5646, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1172, Loss: 4.8082, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1173, Loss: 2.0370, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1174, Loss: 5.2243, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1175, Loss: 5.2560, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1176, Loss: 5.4448, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1177, Loss: 5.0719, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1178, Loss: 5.7115, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1179, Loss: 5.5126, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1180, Loss: 3.3342, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1181, Loss: 5.0486, LR: 0.000044, Memory: 2270.33 MB\n",
            "Step 1182, Loss: 5.3276, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1183, Loss: 5.6730, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1184, Loss: 5.2023, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1185, Loss: 3.9176, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1186, Loss: 4.8722, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1187, Loss: 5.4395, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1188, Loss: 5.4650, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1189, Loss: 5.0582, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1190, Loss: 5.0261, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1191, Loss: 5.0621, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1192, Loss: 5.0825, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1193, Loss: 4.6429, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1194, Loss: 5.0537, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1195, Loss: 4.3791, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1196, Loss: 5.6635, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1197, Loss: 4.8386, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1198, Loss: 5.0710, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1199, Loss: 5.3807, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1200, Loss: 4.6644, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1201, Loss: 5.5911, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1202, Loss: 5.3394, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1203, Loss: 5.3338, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1204, Loss: 5.5162, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1205, Loss: 5.0520, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1206, Loss: 4.6252, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1207, Loss: 4.9844, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1208, Loss: 5.0348, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1209, Loss: 5.0268, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1210, Loss: 4.4179, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1211, Loss: 5.1979, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1212, Loss: 5.3701, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1213, Loss: 5.2449, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1214, Loss: 5.2504, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1215, Loss: 5.4827, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1216, Loss: 4.9013, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1217, Loss: 4.8293, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1218, Loss: 5.4511, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1219, Loss: 4.9436, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1220, Loss: 5.3773, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1221, Loss: 4.9825, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1222, Loss: 5.2906, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1223, Loss: 5.5679, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1224, Loss: 4.8955, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1225, Loss: 5.6696, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1226, Loss: 5.1535, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1227, Loss: 5.2591, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1228, Loss: 5.2284, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1229, Loss: 5.5816, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1230, Loss: 5.1932, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1231, Loss: 5.2843, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1232, Loss: 5.2634, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1233, Loss: 5.0773, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1234, Loss: 5.0833, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1235, Loss: 5.7100, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1236, Loss: 3.4776, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1237, Loss: 5.3979, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1238, Loss: 5.1951, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1239, Loss: 5.7509, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1240, Loss: 4.9582, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1241, Loss: 5.4536, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1242, Loss: 5.5011, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1243, Loss: 5.4681, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1244, Loss: 5.3384, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1245, Loss: 5.6491, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1246, Loss: 5.3820, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1247, Loss: 4.9668, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1248, Loss: 5.7222, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1249, Loss: 5.4887, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1250, Loss: 5.1684, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1251, Loss: 4.2693, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1252, Loss: 5.2877, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1253, Loss: 4.8295, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1254, Loss: 4.5901, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1255, Loss: 5.4799, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1256, Loss: 4.7874, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1257, Loss: 5.6334, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1258, Loss: 4.6192, LR: 0.000043, Memory: 1356.10 MB\n",
            "Step 1259, Loss: 4.9988, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1260, Loss: 5.1689, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1261, Loss: 5.3093, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1262, Loss: 5.2298, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1263, Loss: 4.9230, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1264, Loss: 5.5436, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1265, Loss: 4.9792, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1266, Loss: 4.8415, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1267, Loss: 5.3062, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1268, Loss: 5.0057, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1269, Loss: 4.8827, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1270, Loss: 5.3116, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1271, Loss: 4.9782, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1272, Loss: 5.3763, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1273, Loss: 4.6521, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1274, Loss: 5.0762, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1275, Loss: 5.5416, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1276, Loss: 5.8951, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1277, Loss: 4.9185, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1278, Loss: 5.2905, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1279, Loss: 4.9531, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1280, Loss: 5.4847, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1281, Loss: 5.5763, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1282, Loss: 5.4759, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1283, Loss: 5.6490, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1284, Loss: 5.0286, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1285, Loss: 4.6453, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1286, Loss: 5.0706, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1287, Loss: 3.3914, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1288, Loss: 5.1392, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1289, Loss: 5.2018, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1290, Loss: 5.2169, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1291, Loss: 4.8488, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1292, Loss: 5.5936, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1293, Loss: 5.5580, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1294, Loss: 5.5620, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1295, Loss: 4.9795, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1296, Loss: 4.4396, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1297, Loss: 5.2053, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1298, Loss: 4.8647, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1299, Loss: 5.1517, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1300, Loss: 5.2592, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1301, Loss: 4.6333, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1302, Loss: 4.8939, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1303, Loss: 5.1351, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1304, Loss: 6.0710, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1305, Loss: 5.0581, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1306, Loss: 5.5256, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1307, Loss: 4.7919, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1308, Loss: 5.2311, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1309, Loss: 5.4054, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1310, Loss: 5.6156, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1311, Loss: 5.7164, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1312, Loss: 5.5247, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1313, Loss: 5.0746, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1314, Loss: 5.6080, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1315, Loss: 4.8912, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1316, Loss: 5.5697, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1317, Loss: 5.3652, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1318, Loss: 5.3300, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1319, Loss: 5.4657, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1320, Loss: 5.5148, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1321, Loss: 5.4920, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1322, Loss: 5.4437, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1323, Loss: 5.1181, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1324, Loss: 5.3512, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1325, Loss: 4.2629, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1326, Loss: 4.8848, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1327, Loss: 4.6855, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1328, Loss: 4.6479, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1329, Loss: 5.0020, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1330, Loss: 5.4871, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1331, Loss: 5.3339, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1332, Loss: 5.9700, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1333, Loss: 5.0978, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1334, Loss: 5.1096, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1335, Loss: 4.8919, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1336, Loss: 5.0961, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1337, Loss: 4.6183, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1338, Loss: 5.6670, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1339, Loss: 5.1028, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1340, Loss: 5.1794, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1341, Loss: 5.4734, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1342, Loss: 5.3380, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1343, Loss: 5.4407, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1344, Loss: 4.9819, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1345, Loss: 5.4416, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1346, Loss: 5.2254, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1347, Loss: 5.0049, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1348, Loss: 5.1132, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1349, Loss: 4.9131, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1350, Loss: 5.4927, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1351, Loss: 5.2109, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1352, Loss: 5.2908, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1353, Loss: 5.4960, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1354, Loss: 5.4810, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1355, Loss: 4.9027, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1356, Loss: 5.4296, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1357, Loss: 5.5699, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1358, Loss: 4.9245, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1359, Loss: 5.0880, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1360, Loss: 2.3413, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1361, Loss: 5.9497, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1362, Loss: 5.4919, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1363, Loss: 5.5085, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1364, Loss: 5.2307, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1365, Loss: 5.5997, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1366, Loss: 5.4227, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1367, Loss: 5.4185, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1368, Loss: 4.8698, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1369, Loss: 4.9849, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1370, Loss: 5.0986, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1371, Loss: 5.1387, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1372, Loss: 5.4475, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1373, Loss: 5.5004, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1374, Loss: 4.9023, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1375, Loss: 4.9202, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1376, Loss: 5.3520, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1377, Loss: 4.3852, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1378, Loss: 4.7281, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1379, Loss: 5.7899, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1380, Loss: 5.3367, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1381, Loss: 5.2537, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1382, Loss: 5.1315, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1383, Loss: 5.0146, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1384, Loss: 5.1187, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1385, Loss: 5.0042, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1386, Loss: 5.2833, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1387, Loss: 5.5185, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1388, Loss: 5.3803, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1389, Loss: 4.5594, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1390, Loss: 5.1024, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1391, Loss: 5.2221, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1392, Loss: 5.3418, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1393, Loss: 5.6436, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1394, Loss: 4.4890, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1395, Loss: 5.4691, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1396, Loss: 2.7834, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1397, Loss: 5.3932, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1398, Loss: 5.4932, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1399, Loss: 5.3121, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1400, Loss: 5.7651, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1401, Loss: 5.5408, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1402, Loss: 5.0179, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1403, Loss: 5.5154, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1404, Loss: 5.5016, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1405, Loss: 4.7751, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1406, Loss: 4.7862, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1407, Loss: 5.4188, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1408, Loss: 4.6284, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1409, Loss: 5.6252, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1410, Loss: 5.9138, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1411, Loss: 5.1363, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1412, Loss: 5.3805, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1413, Loss: 5.0702, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1414, Loss: 5.1319, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1415, Loss: 4.9567, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1416, Loss: 4.8981, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1417, Loss: 5.3286, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1418, Loss: 5.7088, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1419, Loss: 5.4475, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1420, Loss: 5.1546, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1421, Loss: 5.7108, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1422, Loss: 5.2689, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1423, Loss: 4.6044, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1424, Loss: 5.3580, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1425, Loss: 4.9791, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1426, Loss: 5.3410, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1427, Loss: 5.6325, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1428, Loss: 5.2261, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1429, Loss: 5.1748, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1430, Loss: 5.6321, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1431, Loss: 4.6810, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1432, Loss: 5.3324, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1433, Loss: 5.0064, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1434, Loss: 4.7297, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1435, Loss: 4.8218, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1436, Loss: 4.8835, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1437, Loss: 4.9259, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1438, Loss: 4.6770, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1439, Loss: 5.4949, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1440, Loss: 5.2954, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1441, Loss: 5.3903, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1442, Loss: 4.5690, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1443, Loss: 5.4067, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1444, Loss: 4.9967, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1445, Loss: 4.9984, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1446, Loss: 5.4678, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1447, Loss: 5.4821, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1448, Loss: 4.7794, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1449, Loss: 5.3939, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1450, Loss: 5.3646, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1451, Loss: 4.9560, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1452, Loss: 4.8679, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1453, Loss: 4.0759, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1454, Loss: 4.2954, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1455, Loss: 4.5245, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1456, Loss: 5.0536, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1457, Loss: 5.1242, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1458, Loss: 4.7795, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1459, Loss: 5.7135, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1460, Loss: 5.5264, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1461, Loss: 5.9234, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1462, Loss: 5.1467, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1463, Loss: 5.3402, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1464, Loss: 5.5133, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1465, Loss: 5.6610, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1466, Loss: 5.4698, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1467, Loss: 5.0005, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1468, Loss: 5.3763, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1469, Loss: 5.2603, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1470, Loss: 4.8075, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1471, Loss: 5.3480, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1472, Loss: 5.5235, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1473, Loss: 4.6693, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1474, Loss: 5.7138, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1475, Loss: 5.2331, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1476, Loss: 5.7924, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1477, Loss: 5.1971, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1478, Loss: 5.5738, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1479, Loss: 4.4609, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1480, Loss: 4.6285, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1481, Loss: 4.1401, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1482, Loss: 5.6932, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1483, Loss: 5.4559, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1484, Loss: 5.5799, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1485, Loss: 5.0070, LR: 0.000039, Memory: 1356.09 MB\n",
            "Epoch 4/5, Avg Loss: 20.8956, Time: 536.05s, Speed: 44.34 examples/s\n",
            "Model weights saved to /content/drive/MyDrive/LLM/custom_llm_epoch_6.pth\n",
            "Step 1, Loss: 5.3550, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 2, Loss: 4.7344, LR: 0.000010, Memory: 1356.09 MB\n",
            "Step 3, Loss: 5.3751, LR: 0.000010, Memory: 1356.09 MB\n",
            "Step 4, Loss: 5.3309, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 5, Loss: 4.7747, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 6, Loss: 4.7964, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 7, Loss: 4.5329, LR: 0.000010, Memory: 1356.09 MB\n",
            "Step 8, Loss: 5.5230, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 9, Loss: 4.9287, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 10, Loss: 5.3045, LR: 0.000010, Memory: 1421.12 MB\n",
            "Step 11, Loss: 4.7901, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 12, Loss: 4.6936, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 13, Loss: 4.8738, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 14, Loss: 5.8427, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 15, Loss: 5.3796, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 16, Loss: 3.8799, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 17, Loss: 5.4948, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 18, Loss: 4.3368, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 19, Loss: 4.8689, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 20, Loss: 4.9718, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 21, Loss: 5.1798, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 22, Loss: 5.4459, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 23, Loss: 4.5618, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 24, Loss: 5.1302, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 25, Loss: 4.6719, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 26, Loss: 2.8124, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 27, Loss: 5.0308, LR: 0.000011, Memory: 1421.12 MB\n",
            "Step 28, Loss: 5.4300, LR: 0.000011, Memory: 1356.09 MB\n",
            "Step 29, Loss: 5.4247, LR: 0.000012, Memory: 1356.09 MB\n",
            "Step 30, Loss: 5.2257, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 31, Loss: 4.8129, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 32, Loss: 5.1461, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 33, Loss: 5.1082, LR: 0.000012, Memory: 1356.09 MB\n",
            "Step 34, Loss: 5.3642, LR: 0.000012, Memory: 1356.09 MB\n",
            "Step 35, Loss: 5.4435, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 36, Loss: 5.2372, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 37, Loss: 5.3080, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 38, Loss: 5.2091, LR: 0.000012, Memory: 1356.09 MB\n",
            "Step 39, Loss: 1.7368, LR: 0.000012, Memory: 1356.09 MB\n",
            "Step 40, Loss: 5.0343, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 41, Loss: 5.0007, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 42, Loss: 4.1877, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 43, Loss: 5.2517, LR: 0.000012, Memory: 1356.09 MB\n",
            "Step 44, Loss: 4.5616, LR: 0.000012, Memory: 1356.09 MB\n",
            "Step 45, Loss: 5.0663, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 46, Loss: 5.1602, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 47, Loss: 5.0676, LR: 0.000012, Memory: 1421.12 MB\n",
            "Step 48, Loss: 5.3638, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 49, Loss: 4.9982, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 50, Loss: 4.4579, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 51, Loss: 5.0783, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 52, Loss: 5.5215, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 53, Loss: 5.0920, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 54, Loss: 4.8968, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 55, Loss: 5.1378, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 56, Loss: 4.8915, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 57, Loss: 4.8663, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 58, Loss: 4.5070, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 59, Loss: 4.6961, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 60, Loss: 5.3066, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 61, Loss: 5.3619, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 62, Loss: 5.1702, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 63, Loss: 4.6335, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 64, Loss: 5.3009, LR: 0.000013, Memory: 1421.12 MB\n",
            "Step 65, Loss: 4.7447, LR: 0.000013, Memory: 1356.09 MB\n",
            "Step 66, Loss: 4.6962, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 67, Loss: 4.1035, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 68, Loss: 5.1382, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 69, Loss: 5.5680, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 70, Loss: 4.9141, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 71, Loss: 5.3034, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 72, Loss: 5.0733, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 73, Loss: 3.5854, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 74, Loss: 4.8246, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 75, Loss: 4.6177, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 76, Loss: 3.9987, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 77, Loss: 5.1314, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 78, Loss: 5.1214, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 79, Loss: 5.1623, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 80, Loss: 5.0744, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 81, Loss: 5.0748, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 82, Loss: 5.0799, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 83, Loss: 5.1307, LR: 0.000014, Memory: 1356.09 MB\n",
            "Step 84, Loss: 4.9384, LR: 0.000014, Memory: 1421.12 MB\n",
            "Step 85, Loss: 4.8973, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 86, Loss: 4.5003, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 87, Loss: 5.3560, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 88, Loss: 5.1270, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 89, Loss: 4.6215, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 90, Loss: 4.7069, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 91, Loss: 4.7649, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 92, Loss: 4.8615, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 93, Loss: 5.0418, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 94, Loss: 4.7316, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 95, Loss: 4.6871, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 96, Loss: 5.2680, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 97, Loss: 5.1898, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 98, Loss: 4.9029, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 99, Loss: 4.9671, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 100, Loss: 4.4169, LR: 0.000015, Memory: 1356.09 MB\n",
            "Step 101, Loss: 5.4534, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 102, Loss: 4.8609, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 103, Loss: 4.5963, LR: 0.000015, Memory: 1421.12 MB\n",
            "Step 104, Loss: 5.0406, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 105, Loss: 4.7287, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 106, Loss: 5.1325, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 107, Loss: 4.7595, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 108, Loss: 5.0362, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 109, Loss: 4.2979, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 110, Loss: 5.0084, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 111, Loss: 4.7526, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 112, Loss: 5.1144, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 113, Loss: 4.8839, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 114, Loss: 4.9943, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 115, Loss: 4.6199, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 116, Loss: 4.1958, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 117, Loss: 4.9849, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 118, Loss: 5.4701, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 119, Loss: 4.8158, LR: 0.000016, Memory: 1421.12 MB\n",
            "Step 120, Loss: 5.0330, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 121, Loss: 4.6702, LR: 0.000016, Memory: 1356.09 MB\n",
            "Step 122, Loss: 5.1873, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 123, Loss: 5.0902, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 124, Loss: 4.0321, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 125, Loss: 5.6915, LR: 0.000017, Memory: 1356.09 MB\n",
            "Step 126, Loss: 5.5651, LR: 0.000017, Memory: 1356.09 MB\n",
            "Step 127, Loss: 4.6097, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 128, Loss: 5.0927, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 129, Loss: 4.4837, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 130, Loss: 5.1687, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 131, Loss: 5.0885, LR: 0.000017, Memory: 1356.09 MB\n",
            "Step 132, Loss: 5.3315, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 133, Loss: 4.7169, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 134, Loss: 5.4170, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 135, Loss: 4.8523, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 136, Loss: 5.0818, LR: 0.000017, Memory: 1356.09 MB\n",
            "Step 137, Loss: 5.0648, LR: 0.000017, Memory: 1356.09 MB\n",
            "Step 138, Loss: 4.7680, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 139, Loss: 4.7702, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 140, Loss: 5.3420, LR: 0.000017, Memory: 1421.12 MB\n",
            "Step 141, Loss: 4.8001, LR: 0.000018, Memory: 1356.09 MB\n",
            "Step 142, Loss: 4.6047, LR: 0.000018, Memory: 1356.09 MB\n",
            "Step 143, Loss: 5.2664, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 144, Loss: 4.9208, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 145, Loss: 4.7911, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 146, Loss: 5.2017, LR: 0.000018, Memory: 1356.09 MB\n",
            "Step 147, Loss: 5.3241, LR: 0.000018, Memory: 1356.09 MB\n",
            "Step 148, Loss: 4.8381, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 149, Loss: 5.0612, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 150, Loss: 5.1156, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 151, Loss: 4.7099, LR: 0.000018, Memory: 1356.09 MB\n",
            "Step 152, Loss: 4.1892, LR: 0.000018, Memory: 1356.09 MB\n",
            "Step 153, Loss: 4.9363, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 154, Loss: 4.8342, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 155, Loss: 4.6765, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 156, Loss: 4.8304, LR: 0.000018, Memory: 1356.09 MB\n",
            "Step 157, Loss: 5.0130, LR: 0.000018, Memory: 1356.09 MB\n",
            "Step 158, Loss: 5.2463, LR: 0.000018, Memory: 1421.12 MB\n",
            "Step 159, Loss: 4.6191, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 160, Loss: 5.1997, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 161, Loss: 5.1380, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 162, Loss: 4.4940, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 163, Loss: 4.8775, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 164, Loss: 5.2175, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 165, Loss: 5.5238, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 166, Loss: 4.6228, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 167, Loss: 4.1866, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 168, Loss: 4.8876, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 169, Loss: 5.2503, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 170, Loss: 5.2371, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 171, Loss: 5.3957, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 172, Loss: 4.9774, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 173, Loss: 5.0486, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 174, Loss: 5.2317, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 175, Loss: 5.4561, LR: 0.000019, Memory: 1421.12 MB\n",
            "Step 176, Loss: 4.7682, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 177, Loss: 4.8669, LR: 0.000019, Memory: 1356.09 MB\n",
            "Step 178, Loss: 5.0087, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 179, Loss: 4.7019, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 180, Loss: 5.3751, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 181, Loss: 5.7074, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 182, Loss: 4.6490, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 183, Loss: 5.0562, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 184, Loss: 5.1256, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 185, Loss: 5.3992, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 186, Loss: 5.2804, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 187, Loss: 5.2850, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 188, Loss: 5.1403, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 189, Loss: 4.9631, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 190, Loss: 5.0485, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 191, Loss: 4.3716, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 192, Loss: 4.8469, LR: 0.000020, Memory: 1356.09 MB\n",
            "Step 193, Loss: 5.0545, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 194, Loss: 5.3734, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 195, Loss: 5.0558, LR: 0.000020, Memory: 1421.12 MB\n",
            "Step 196, Loss: 4.8392, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 197, Loss: 4.8033, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 198, Loss: 5.0115, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 199, Loss: 4.6122, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 200, Loss: 5.2107, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 201, Loss: 5.6553, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 202, Loss: 5.7969, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 203, Loss: 5.3677, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 204, Loss: 5.6392, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 205, Loss: 4.9332, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 206, Loss: 5.4612, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 207, Loss: 5.3635, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 208, Loss: 1.5080, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 209, Loss: 3.9962, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 210, Loss: 5.1030, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 211, Loss: 4.8962, LR: 0.000021, Memory: 1356.09 MB\n",
            "Step 212, Loss: 5.3997, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 213, Loss: 4.7630, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 214, Loss: 5.1787, LR: 0.000021, Memory: 1421.12 MB\n",
            "Step 215, Loss: 4.7423, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 216, Loss: 5.0461, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 217, Loss: 5.1318, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 218, Loss: 4.5389, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 219, Loss: 5.3166, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 220, Loss: 4.8603, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 221, Loss: 4.2456, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 222, Loss: 4.9315, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 223, Loss: 4.8886, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 224, Loss: 5.2701, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 225, Loss: 4.9634, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 226, Loss: 5.4770, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 227, Loss: 5.1290, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 228, Loss: 4.9725, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 229, Loss: 5.0523, LR: 0.000022, Memory: 1356.09 MB\n",
            "Step 230, Loss: 4.9378, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 231, Loss: 5.1053, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 232, Loss: 4.8238, LR: 0.000022, Memory: 1421.12 MB\n",
            "Step 233, Loss: 5.0675, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 234, Loss: 4.8838, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 235, Loss: 5.1511, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 236, Loss: 4.4175, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 237, Loss: 5.5070, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 238, Loss: 5.2083, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 239, Loss: 5.1226, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 240, Loss: 4.9483, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 241, Loss: 5.7876, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 242, Loss: 4.9186, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 243, Loss: 4.8266, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 244, Loss: 4.6815, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 245, Loss: 5.1151, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 246, Loss: 5.0354, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 247, Loss: 4.4045, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 248, Loss: 4.6445, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 249, Loss: 4.7160, LR: 0.000023, Memory: 1356.09 MB\n",
            "Step 250, Loss: 4.9550, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 251, Loss: 4.6486, LR: 0.000023, Memory: 1421.12 MB\n",
            "Step 252, Loss: 5.3908, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 253, Loss: 5.4202, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 254, Loss: 4.5586, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 255, Loss: 5.1319, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 256, Loss: 5.2924, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 257, Loss: 5.0325, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 258, Loss: 4.5980, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 259, Loss: 3.8657, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 260, Loss: 4.6739, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 261, Loss: 5.1721, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 262, Loss: 4.9762, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 263, Loss: 5.0243, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 264, Loss: 5.3876, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 265, Loss: 4.8088, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 266, Loss: 4.5685, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 267, Loss: 5.2445, LR: 0.000024, Memory: 1421.12 MB\n",
            "Step 268, Loss: 5.4220, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 269, Loss: 4.7926, LR: 0.000024, Memory: 1356.09 MB\n",
            "Step 270, Loss: 4.9718, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 271, Loss: 5.0568, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 272, Loss: 5.0136, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 273, Loss: 5.0860, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 274, Loss: 4.8579, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 275, Loss: 4.7159, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 276, Loss: 5.4385, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 277, Loss: 4.6519, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 278, Loss: 5.5393, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 279, Loss: 5.6578, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 280, Loss: 5.1310, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 281, Loss: 4.6878, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 282, Loss: 4.3714, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 283, Loss: 5.5088, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 284, Loss: 4.9367, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 285, Loss: 5.0559, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 286, Loss: 4.9045, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 287, Loss: 5.1756, LR: 0.000025, Memory: 1421.12 MB\n",
            "Step 288, Loss: 5.7086, LR: 0.000025, Memory: 1356.09 MB\n",
            "Step 289, Loss: 4.9981, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 290, Loss: 5.1696, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 291, Loss: 5.3463, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 292, Loss: 5.5496, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 293, Loss: 5.4155, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 294, Loss: 4.9786, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 295, Loss: 5.0182, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 296, Loss: 5.1047, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 297, Loss: 5.3266, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 298, Loss: 4.9747, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 299, Loss: 1.3704, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 300, Loss: 4.7947, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 301, Loss: 4.8868, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 302, Loss: 4.9933, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 303, Loss: 5.1090, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 304, Loss: 2.9511, LR: 0.000026, Memory: 1356.09 MB\n",
            "Step 305, Loss: 5.1440, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 306, Loss: 5.4036, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 307, Loss: 5.2540, LR: 0.000026, Memory: 1421.12 MB\n",
            "Step 308, Loss: 4.5853, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 309, Loss: 4.8634, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 310, Loss: 5.0009, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 311, Loss: 5.3951, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 312, Loss: 5.2338, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 313, Loss: 4.7439, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 314, Loss: 5.5889, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 315, Loss: 4.5171, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 316, Loss: 5.0456, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 317, Loss: 5.0812, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 318, Loss: 4.9689, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 319, Loss: 5.2316, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 320, Loss: 5.2580, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 321, Loss: 5.2979, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 322, Loss: 4.9051, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 323, Loss: 5.6701, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 324, Loss: 4.8843, LR: 0.000027, Memory: 1421.12 MB\n",
            "Step 325, Loss: 4.3973, LR: 0.000027, Memory: 1356.09 MB\n",
            "Step 326, Loss: 4.6388, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 327, Loss: 5.4120, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 328, Loss: 4.9772, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 329, Loss: 4.9171, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 330, Loss: 4.9521, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 331, Loss: 3.7306, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 332, Loss: 4.2731, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 333, Loss: 3.9019, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 334, Loss: 5.2490, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 335, Loss: 4.0446, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 336, Loss: 4.6728, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 337, Loss: 5.3975, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 338, Loss: 4.6758, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 339, Loss: 4.4542, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 340, Loss: 4.4178, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 341, Loss: 5.4099, LR: 0.000028, Memory: 1356.09 MB\n",
            "Step 342, Loss: 4.7842, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 343, Loss: 4.7083, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 344, Loss: 5.0804, LR: 0.000028, Memory: 1421.12 MB\n",
            "Step 345, Loss: 4.8225, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 346, Loss: 5.1983, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 347, Loss: 4.5387, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 348, Loss: 4.8928, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 349, Loss: 4.4826, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 350, Loss: 4.3990, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 351, Loss: 5.0838, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 352, Loss: 5.3038, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 353, Loss: 4.8091, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 354, Loss: 4.9234, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 355, Loss: 4.6772, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 356, Loss: 4.8074, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 357, Loss: 5.4100, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 358, Loss: 5.2575, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 359, Loss: 5.2454, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 360, Loss: 5.0385, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 361, Loss: 4.8352, LR: 0.000029, Memory: 1356.09 MB\n",
            "Step 362, Loss: 5.6797, LR: 0.000029, Memory: 1421.12 MB\n",
            "Step 363, Loss: 5.6642, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 364, Loss: 5.2896, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 365, Loss: 4.8919, LR: 0.000030, Memory: 1356.09 MB\n",
            "Step 366, Loss: 4.9547, LR: 0.000030, Memory: 1356.09 MB\n",
            "Step 367, Loss: 4.9579, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 368, Loss: 5.3609, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 369, Loss: 5.2247, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 370, Loss: 5.2092, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 371, Loss: 4.8772, LR: 0.000030, Memory: 1356.09 MB\n",
            "Step 372, Loss: 5.1323, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 373, Loss: 4.9064, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 374, Loss: 3.8514, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 375, Loss: 4.8097, LR: 0.000030, Memory: 1356.09 MB\n",
            "Step 376, Loss: 4.5688, LR: 0.000030, Memory: 1356.09 MB\n",
            "Step 377, Loss: 5.5717, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 378, Loss: 5.4391, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 379, Loss: 5.3595, LR: 0.000030, Memory: 1421.12 MB\n",
            "Step 380, Loss: 4.5464, LR: 0.000030, Memory: 1356.09 MB\n",
            "Step 381, Loss: 5.3183, LR: 0.000030, Memory: 1356.09 MB\n",
            "Step 382, Loss: 5.2744, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 383, Loss: 5.0724, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 384, Loss: 5.3224, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 385, Loss: 4.8817, LR: 0.000031, Memory: 1356.09 MB\n",
            "Step 386, Loss: 4.8822, LR: 0.000031, Memory: 1356.09 MB\n",
            "Step 387, Loss: 4.4418, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 388, Loss: 5.3966, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 389, Loss: 5.3555, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 390, Loss: 5.3784, LR: 0.000031, Memory: 1356.09 MB\n",
            "Step 391, Loss: 4.9635, LR: 0.000031, Memory: 1356.09 MB\n",
            "Step 392, Loss: 5.2604, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 393, Loss: 4.3072, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 394, Loss: 5.0472, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 395, Loss: 5.1761, LR: 0.000031, Memory: 1356.09 MB\n",
            "Step 396, Loss: 4.6741, LR: 0.000031, Memory: 1356.09 MB\n",
            "Step 397, Loss: 5.1313, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 398, Loss: 4.3134, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 399, Loss: 4.7647, LR: 0.000031, Memory: 1421.12 MB\n",
            "Step 400, Loss: 5.2083, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 401, Loss: 5.1974, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 402, Loss: 4.8679, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 403, Loss: 5.1189, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 404, Loss: 5.3548, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 405, Loss: 4.5091, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 406, Loss: 5.5679, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 407, Loss: 5.4541, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 408, Loss: 4.2875, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 409, Loss: 5.1403, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 410, Loss: 4.9552, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 411, Loss: 5.3079, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 412, Loss: 5.5154, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 413, Loss: 5.2176, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 414, Loss: 5.5467, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 415, Loss: 5.1183, LR: 0.000032, Memory: 1356.09 MB\n",
            "Step 416, Loss: 5.3405, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 417, Loss: 4.1815, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 418, Loss: 5.1400, LR: 0.000032, Memory: 1421.12 MB\n",
            "Step 419, Loss: 5.3510, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 420, Loss: 5.4286, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 421, Loss: 5.1697, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 422, Loss: 4.4508, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 423, Loss: 4.9348, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 424, Loss: 5.1434, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 425, Loss: 4.4784, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 426, Loss: 4.6083, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 427, Loss: 4.3966, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 428, Loss: 5.3065, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 429, Loss: 5.3852, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 430, Loss: 5.4638, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 431, Loss: 5.1628, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 432, Loss: 5.3846, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 433, Loss: 5.0562, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 434, Loss: 4.9160, LR: 0.000033, Memory: 1356.09 MB\n",
            "Step 435, Loss: 5.6796, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 436, Loss: 5.2211, LR: 0.000033, Memory: 1421.12 MB\n",
            "Step 437, Loss: 4.9709, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 438, Loss: 5.1793, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 439, Loss: 4.8594, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 440, Loss: 5.0383, LR: 0.000034, Memory: 1421.13 MB\n",
            "Step 441, Loss: 5.5867, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 442, Loss: 3.9235, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 443, Loss: 5.3002, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 444, Loss: 4.7234, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 445, Loss: 5.2599, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 446, Loss: 5.2671, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 447, Loss: 5.3870, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 448, Loss: 5.1658, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 449, Loss: 4.9512, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 450, Loss: 5.2681, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 451, Loss: 5.1297, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 452, Loss: 5.0262, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 453, Loss: 5.1054, LR: 0.000034, Memory: 1356.09 MB\n",
            "Step 454, Loss: 5.1451, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 455, Loss: 4.4165, LR: 0.000034, Memory: 1421.12 MB\n",
            "Step 456, Loss: 5.1218, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 457, Loss: 3.9839, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 458, Loss: 5.0098, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 459, Loss: 4.9110, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 460, Loss: 4.8755, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 461, Loss: 4.4326, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 462, Loss: 4.7705, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 463, Loss: 4.7217, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 464, Loss: 5.1995, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 465, Loss: 5.0193, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 466, Loss: 4.3524, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 467, Loss: 5.0293, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 468, Loss: 4.9309, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 469, Loss: 5.6719, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 470, Loss: 4.7608, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 471, Loss: 4.9845, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 472, Loss: 5.3456, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 473, Loss: 4.8847, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 474, Loss: 5.1908, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 475, Loss: 4.6780, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 476, Loss: 5.5154, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 477, Loss: 5.2092, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 478, Loss: 4.7096, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 479, Loss: 5.7160, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 480, Loss: 4.2747, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 481, Loss: 2.6437, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 482, Loss: 5.0039, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 483, Loss: 5.2589, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 484, Loss: 5.0631, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 485, Loss: 5.2505, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 486, Loss: 5.1156, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 487, Loss: 5.1919, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 488, Loss: 4.8321, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 489, Loss: 4.6929, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 490, Loss: 3.3237, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 491, Loss: 5.2840, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 492, Loss: 5.0019, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 493, Loss: 4.6706, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 494, Loss: 4.2134, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 495, Loss: 4.9849, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 496, Loss: 5.2474, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 497, Loss: 4.9618, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 498, Loss: 5.1481, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 499, Loss: 4.8729, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 500, Loss: 4.7265, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 501, Loss: 4.7821, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 502, Loss: 4.0003, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 503, Loss: 4.1948, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 504, Loss: 5.3703, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 505, Loss: 5.4228, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 506, Loss: 5.5248, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 507, Loss: 5.0035, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 508, Loss: 4.8190, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 509, Loss: 4.4553, LR: 0.000037, Memory: 1356.10 MB\n",
            "Step 510, Loss: 5.1405, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 511, Loss: 4.6306, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 512, Loss: 5.1915, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 513, Loss: 4.8509, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 514, Loss: 5.2094, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 515, Loss: 4.8854, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 516, Loss: 4.8564, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 517, Loss: 5.5038, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 518, Loss: 5.2341, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 519, Loss: 4.7201, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 520, Loss: 5.4919, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 521, Loss: 4.8924, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 522, Loss: 4.8339, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 523, Loss: 4.9343, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 524, Loss: 4.1879, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 525, Loss: 5.3786, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 526, Loss: 4.8480, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 527, Loss: 5.1708, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 528, Loss: 4.7287, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 529, Loss: 5.5579, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 530, Loss: 3.9842, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 531, Loss: 5.1520, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 532, Loss: 4.6932, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 533, Loss: 5.2265, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 534, Loss: 5.4187, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 535, Loss: 3.1244, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 536, Loss: 4.8665, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 537, Loss: 5.3476, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 538, Loss: 5.4424, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 539, Loss: 4.6235, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 540, Loss: 5.2864, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 541, Loss: 5.0557, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 542, Loss: 5.0217, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 543, Loss: 5.2292, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 544, Loss: 4.9519, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 545, Loss: 4.7932, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 546, Loss: 3.6032, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 547, Loss: 4.8946, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 548, Loss: 4.8818, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 549, Loss: 4.9208, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 550, Loss: 4.8527, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 551, Loss: 4.9764, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 552, Loss: 4.5345, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 553, Loss: 5.0594, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 554, Loss: 5.0340, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 555, Loss: 5.5330, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 556, Loss: 4.5275, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 557, Loss: 4.4765, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 558, Loss: 5.2374, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 559, Loss: 5.5696, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 560, Loss: 4.6921, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 561, Loss: 5.4215, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 562, Loss: 4.9178, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 563, Loss: 5.1769, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 564, Loss: 5.0675, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 565, Loss: 5.5397, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 566, Loss: 4.9461, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 567, Loss: 4.8906, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 568, Loss: 4.7154, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 569, Loss: 4.9071, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 570, Loss: 4.6419, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 571, Loss: 4.7637, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 572, Loss: 5.1431, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 573, Loss: 5.5363, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 574, Loss: 2.9504, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 575, Loss: 5.3496, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 576, Loss: 5.3488, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 577, Loss: 5.2811, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 578, Loss: 4.6335, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 579, Loss: 5.1133, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 580, Loss: 4.8704, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 581, Loss: 5.0227, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 582, Loss: 3.6168, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 583, Loss: 5.3537, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 584, Loss: 4.7736, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 585, Loss: 5.4884, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 586, Loss: 4.8626, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 587, Loss: 4.7515, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 588, Loss: 5.2035, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 589, Loss: 5.3360, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 590, Loss: 5.2672, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 591, Loss: 5.1886, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 592, Loss: 5.0138, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 593, Loss: 5.2584, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 594, Loss: 5.4430, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 595, Loss: 4.7535, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 596, Loss: 4.2794, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 597, Loss: 4.9927, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 598, Loss: 5.1651, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 599, Loss: 4.8410, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 600, Loss: 5.8558, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 601, Loss: 4.8538, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 602, Loss: 4.8796, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 603, Loss: 5.1064, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 604, Loss: 4.8526, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 605, Loss: 5.1355, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 606, Loss: 5.1143, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 607, Loss: 4.5803, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 608, Loss: 5.0873, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 609, Loss: 4.9083, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 610, Loss: 5.2182, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 611, Loss: 5.1973, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 612, Loss: 4.3779, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 613, Loss: 5.2430, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 614, Loss: 5.3618, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 615, Loss: 4.8116, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 616, Loss: 5.1751, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 617, Loss: 5.0923, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 618, Loss: 5.3981, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 619, Loss: 4.7938, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 620, Loss: 5.2730, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 621, Loss: 5.2498, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 622, Loss: 5.0134, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 623, Loss: 4.4496, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 624, Loss: 5.4393, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 625, Loss: 5.1238, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 626, Loss: 4.1673, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 627, Loss: 5.2866, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 628, Loss: 4.9413, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 629, Loss: 5.3924, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 630, Loss: 5.2079, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 631, Loss: 5.1347, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 632, Loss: 5.3614, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 633, Loss: 4.9980, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 634, Loss: 5.7411, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 635, Loss: 5.4110, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 636, Loss: 5.1967, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 637, Loss: 5.1552, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 638, Loss: 4.9972, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 639, Loss: 4.6225, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 640, Loss: 5.7725, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 641, Loss: 4.9239, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 642, Loss: 4.8966, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 643, Loss: 4.7039, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 644, Loss: 4.8655, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 645, Loss: 4.3302, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 646, Loss: 4.9503, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 647, Loss: 5.8321, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 648, Loss: 4.7602, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 649, Loss: 5.1736, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 650, Loss: 4.6801, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 651, Loss: 5.1738, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 652, Loss: 5.0260, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 653, Loss: 5.0578, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 654, Loss: 5.4437, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 655, Loss: 4.3731, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 656, Loss: 5.5459, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 657, Loss: 5.3780, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 658, Loss: 5.0140, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 659, Loss: 4.7548, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 660, Loss: 4.8768, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 661, Loss: 4.7684, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 662, Loss: 4.5305, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 663, Loss: 4.8151, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 664, Loss: 5.0530, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 665, Loss: 4.8856, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 666, Loss: 4.9043, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 667, Loss: 5.0826, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 668, Loss: 4.9243, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 669, Loss: 4.1353, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 670, Loss: 4.8981, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 671, Loss: 4.9119, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 672, Loss: 4.7605, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 673, Loss: 5.0950, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 674, Loss: 5.0298, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 675, Loss: 4.7144, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 676, Loss: 5.4319, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 677, Loss: 5.1837, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 678, Loss: 5.1328, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 679, Loss: 4.6997, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 680, Loss: 4.6679, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 681, Loss: 4.8901, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 682, Loss: 5.6934, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 683, Loss: 5.0952, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 684, Loss: 5.2001, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 685, Loss: 5.3925, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 686, Loss: 5.4909, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 687, Loss: 5.3089, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 688, Loss: 4.3923, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 689, Loss: 5.1039, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 690, Loss: 4.7746, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 691, Loss: 4.7472, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 692, Loss: 4.6478, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 693, Loss: 3.9852, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 694, Loss: 5.1617, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 695, Loss: 5.0687, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 696, Loss: 5.1346, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 697, Loss: 5.6235, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 698, Loss: 5.3455, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 699, Loss: 5.1917, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 700, Loss: 5.0330, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 701, Loss: 4.9787, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 702, Loss: 4.8163, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 703, Loss: 4.8412, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 704, Loss: 5.3446, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 705, Loss: 4.5026, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 706, Loss: 4.6951, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 707, Loss: 5.2517, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 708, Loss: 5.1813, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 709, Loss: 5.0436, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 710, Loss: 5.1573, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 711, Loss: 5.0090, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 712, Loss: 4.8585, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 713, Loss: 4.9689, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 714, Loss: 5.2657, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 715, Loss: 5.2296, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 716, Loss: 5.0561, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 717, Loss: 1.9204, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 718, Loss: 5.1637, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 719, Loss: 4.6599, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 720, Loss: 5.1125, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 721, Loss: 4.9306, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 722, Loss: 4.5543, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 723, Loss: 5.4357, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 724, Loss: 5.1383, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 725, Loss: 4.5898, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 726, Loss: 5.1131, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 727, Loss: 5.1305, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 728, Loss: 5.3749, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 729, Loss: 5.5015, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 730, Loss: 4.8296, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 731, Loss: 5.2379, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 732, Loss: 5.2114, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 733, Loss: 4.4747, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 734, Loss: 4.6667, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 735, Loss: 5.3871, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 736, Loss: 5.1669, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 737, Loss: 4.9306, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 738, Loss: 4.1974, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 739, Loss: 4.8255, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 740, Loss: 5.4805, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 741, Loss: 5.2267, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 742, Loss: 5.7051, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 743, Loss: 4.3675, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 744, Loss: 5.4365, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 745, Loss: 4.8302, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 746, Loss: 4.9637, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 747, Loss: 5.3421, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 748, Loss: 1.6596, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 749, Loss: 5.3183, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 750, Loss: 5.1742, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 751, Loss: 2.5657, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 752, Loss: 5.1671, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 753, Loss: 5.2011, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 754, Loss: 4.8123, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 755, Loss: 4.8249, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 756, Loss: 5.3146, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 757, Loss: 4.8587, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 758, Loss: 5.2110, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 759, Loss: 5.3646, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 760, Loss: 4.7851, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 761, Loss: 5.4545, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 762, Loss: 4.6192, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 763, Loss: 5.2831, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 764, Loss: 4.9749, LR: 0.000050, Memory: 1421.12 MB\n",
            "Step 765, Loss: 4.8238, LR: 0.000050, Memory: 1356.09 MB\n",
            "Step 766, Loss: 5.0803, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 767, Loss: 4.9712, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 768, Loss: 4.9883, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 769, Loss: 4.6211, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 770, Loss: 5.3667, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 771, Loss: 4.8379, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 772, Loss: 5.1330, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 773, Loss: 4.6645, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 774, Loss: 4.9180, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 775, Loss: 4.8128, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 776, Loss: 3.8387, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 777, Loss: 4.5568, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 778, Loss: 4.5545, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 779, Loss: 5.0735, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 780, Loss: 4.4643, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 781, Loss: 4.8769, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 782, Loss: 4.9084, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 783, Loss: 5.0272, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 784, Loss: 4.9066, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 785, Loss: 4.8330, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 786, Loss: 5.2870, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 787, Loss: 4.4465, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 788, Loss: 4.8253, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 789, Loss: 4.8463, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 790, Loss: 5.0091, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 791, Loss: 5.2622, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 792, Loss: 5.3449, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 793, Loss: 4.4774, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 794, Loss: 4.6827, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 795, Loss: 4.9318, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 796, Loss: 4.5595, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 797, Loss: 4.3461, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 798, Loss: 5.6387, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 799, Loss: 2.3074, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 800, Loss: 5.2467, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 801, Loss: 5.0427, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 802, Loss: 4.6319, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 803, Loss: 4.8116, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 804, Loss: 5.5056, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 805, Loss: 4.5463, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 806, Loss: 4.8913, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 807, Loss: 5.6549, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 808, Loss: 5.0052, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 809, Loss: 5.5512, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 810, Loss: 5.0177, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 811, Loss: 4.5671, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 812, Loss: 5.4666, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 813, Loss: 5.0016, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 814, Loss: 4.8682, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 815, Loss: 4.9801, LR: 0.000049, Memory: 1356.09 MB\n",
            "Step 816, Loss: 5.0380, LR: 0.000049, Memory: 1421.12 MB\n",
            "Step 817, Loss: 4.5721, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 818, Loss: 4.8981, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 819, Loss: 5.3607, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 820, Loss: 4.9222, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 821, Loss: 5.4078, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 822, Loss: 4.4788, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 823, Loss: 5.0242, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 824, Loss: 5.1042, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 825, Loss: 4.6297, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 826, Loss: 5.2175, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 827, Loss: 5.1103, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 828, Loss: 5.3413, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 829, Loss: 5.3036, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 830, Loss: 5.1763, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 831, Loss: 4.8681, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 832, Loss: 4.9080, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 833, Loss: 5.5166, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 834, Loss: 2.1063, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 835, Loss: 3.9955, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 836, Loss: 4.5204, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 837, Loss: 4.2590, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 838, Loss: 4.6676, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 839, Loss: 5.3056, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 840, Loss: 4.9330, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 841, Loss: 5.6275, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 842, Loss: 4.9653, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 843, Loss: 4.7709, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 844, Loss: 4.9570, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 845, Loss: 5.3856, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 846, Loss: 4.9676, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 847, Loss: 5.1658, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 848, Loss: 5.1585, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 849, Loss: 5.3446, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 850, Loss: 5.1165, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 851, Loss: 4.8084, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 852, Loss: 4.9791, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 853, Loss: 4.5511, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 854, Loss: 4.9588, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 855, Loss: 5.1769, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 856, Loss: 5.3171, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 857, Loss: 4.9865, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 858, Loss: 3.0038, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 859, Loss: 5.0418, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 860, Loss: 4.6733, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 861, Loss: 4.8449, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 862, Loss: 4.9403, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 863, Loss: 5.0795, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 864, Loss: 5.4937, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 865, Loss: 5.5351, LR: 0.000048, Memory: 1356.09 MB\n",
            "Step 866, Loss: 5.1263, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 867, Loss: 5.0594, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 868, Loss: 4.6400, LR: 0.000048, Memory: 1421.12 MB\n",
            "Step 869, Loss: 5.0944, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 870, Loss: 4.8106, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 871, Loss: 4.6843, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 872, Loss: 5.9088, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 873, Loss: 5.4948, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 874, Loss: 4.4876, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 875, Loss: 5.2009, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 876, Loss: 4.8269, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 877, Loss: 4.7688, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 878, Loss: 4.1728, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 879, Loss: 4.6292, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 880, Loss: 5.3053, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 881, Loss: 4.8642, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 882, Loss: 4.3629, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 883, Loss: 5.0048, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 884, Loss: 4.4877, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 885, Loss: 5.4011, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 886, Loss: 5.0049, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 887, Loss: 4.8860, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 888, Loss: 5.2346, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 889, Loss: 4.9085, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 890, Loss: 4.8211, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 891, Loss: 5.0640, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 892, Loss: 5.4263, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 893, Loss: 4.9875, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 894, Loss: 4.5840, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 895, Loss: 4.5490, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 896, Loss: 5.2991, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 897, Loss: 5.1038, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 898, Loss: 4.9185, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 899, Loss: 5.3723, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 900, Loss: 5.2783, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 901, Loss: 4.7297, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 902, Loss: 5.1232, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 903, Loss: 4.6723, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 904, Loss: 5.0266, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 905, Loss: 4.3355, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 906, Loss: 4.9725, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 907, Loss: 3.9967, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 908, Loss: 5.2527, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 909, Loss: 4.9966, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 910, Loss: 4.3810, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 911, Loss: 5.1542, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 912, Loss: 5.2057, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 913, Loss: 5.2517, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 914, Loss: 4.4417, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 915, Loss: 4.9798, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 916, Loss: 4.8913, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 917, Loss: 5.0716, LR: 0.000047, Memory: 1356.09 MB\n",
            "Step 918, Loss: 4.9280, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 919, Loss: 4.8229, LR: 0.000047, Memory: 1421.12 MB\n",
            "Step 920, Loss: 5.4276, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 921, Loss: 4.7943, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 922, Loss: 3.9936, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 923, Loss: 5.1900, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 924, Loss: 4.3979, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 925, Loss: 5.4999, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 926, Loss: 5.6941, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 927, Loss: 5.4137, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 928, Loss: 5.4090, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 929, Loss: 5.3586, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 930, Loss: 4.9127, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 931, Loss: 5.5246, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 932, Loss: 4.2320, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 933, Loss: 5.1628, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 934, Loss: 5.3096, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 935, Loss: 4.2618, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 936, Loss: 5.1150, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 937, Loss: 5.3480, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 938, Loss: 5.1613, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 939, Loss: 4.4444, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 940, Loss: 4.9662, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 941, Loss: 5.3781, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 942, Loss: 5.1775, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 943, Loss: 5.4202, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 944, Loss: 5.1370, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 945, Loss: 1.7940, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 946, Loss: 5.2355, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 947, Loss: 5.5567, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 948, Loss: 4.8867, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 949, Loss: 5.5905, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 950, Loss: 4.4988, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 951, Loss: 5.1008, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 952, Loss: 5.2762, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 953, Loss: 5.0312, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 954, Loss: 4.2854, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 955, Loss: 5.0157, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 956, Loss: 4.7749, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 957, Loss: 5.1495, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 958, Loss: 4.2972, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 959, Loss: 5.4233, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 960, Loss: 5.2831, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 961, Loss: 4.8782, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 962, Loss: 5.1514, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 963, Loss: 4.8702, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 964, Loss: 4.3047, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 965, Loss: 4.9139, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 966, Loss: 4.9425, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 967, Loss: 5.4159, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 968, Loss: 5.7244, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 969, Loss: 5.0117, LR: 0.000046, Memory: 1421.12 MB\n",
            "Step 970, Loss: 5.1308, LR: 0.000046, Memory: 1356.09 MB\n",
            "Step 971, Loss: 4.6719, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 972, Loss: 5.0577, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 973, Loss: 4.6310, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 974, Loss: 3.3295, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 975, Loss: 5.2634, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 976, Loss: 5.0368, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 977, Loss: 5.0787, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 978, Loss: 2.1032, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 979, Loss: 4.6505, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 980, Loss: 4.7084, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 981, Loss: 5.3190, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 982, Loss: 4.9284, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 983, Loss: 4.4544, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 984, Loss: 4.9850, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 985, Loss: 4.7215, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 986, Loss: 4.9627, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 987, Loss: 4.9984, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 988, Loss: 4.9233, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 989, Loss: 5.2540, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 990, Loss: 5.4587, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 991, Loss: 5.3015, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 992, Loss: 4.6801, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 993, Loss: 5.0554, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 994, Loss: 4.6388, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 995, Loss: 4.9998, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 996, Loss: 5.0550, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 997, Loss: 5.4933, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 998, Loss: 5.0329, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 999, Loss: 5.0504, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1000, Loss: 5.2593, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1001, Loss: 3.3976, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1002, Loss: 3.4698, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1003, Loss: 5.1436, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1004, Loss: 5.4191, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1005, Loss: 4.8411, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1006, Loss: 5.5084, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1007, Loss: 4.8803, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1008, Loss: 5.3126, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1009, Loss: 5.0393, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1010, Loss: 5.0495, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1011, Loss: 4.2610, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1012, Loss: 4.0203, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1013, Loss: 5.3752, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1014, Loss: 3.9376, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1015, Loss: 5.7127, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1016, Loss: 4.7501, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1017, Loss: 4.8841, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1018, Loss: 4.8961, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1019, Loss: 5.4857, LR: 0.000045, Memory: 1421.12 MB\n",
            "Step 1020, Loss: 5.4417, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1021, Loss: 4.5097, LR: 0.000045, Memory: 1356.09 MB\n",
            "Step 1022, Loss: 2.9136, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1023, Loss: 4.1481, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1024, Loss: 4.8292, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1025, Loss: 4.6191, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1026, Loss: 4.2334, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1027, Loss: 5.1712, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1028, Loss: 2.9262, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1029, Loss: 4.4730, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1030, Loss: 5.5807, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1031, Loss: 5.7593, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1032, Loss: 4.8582, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1033, Loss: 4.7239, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1034, Loss: 5.1295, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1035, Loss: 5.1561, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1036, Loss: 4.8845, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1037, Loss: 5.1510, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1038, Loss: 5.1322, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1039, Loss: 5.3607, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1040, Loss: 5.5476, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1041, Loss: 4.9391, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1042, Loss: 5.7282, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1043, Loss: 4.4400, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1044, Loss: 5.3486, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1045, Loss: 4.7895, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1046, Loss: 4.5967, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1047, Loss: 5.1266, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1048, Loss: 4.1393, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1049, Loss: 4.9230, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1050, Loss: 5.2120, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1051, Loss: 4.2158, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1052, Loss: 5.7554, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1053, Loss: 5.4306, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1054, Loss: 5.0046, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1055, Loss: 4.7134, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1056, Loss: 4.7781, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1057, Loss: 5.1631, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1058, Loss: 5.1225, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1059, Loss: 5.2565, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1060, Loss: 5.1277, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1061, Loss: 4.8424, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1062, Loss: 5.6411, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1063, Loss: 4.7032, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1064, Loss: 4.8345, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1065, Loss: 5.0032, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1066, Loss: 4.9592, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1067, Loss: 5.5309, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1068, Loss: 3.9977, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1069, Loss: 3.6507, LR: 0.000044, Memory: 1356.09 MB\n",
            "Step 1070, Loss: 4.9912, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1071, Loss: 5.7018, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1072, Loss: 4.6772, LR: 0.000044, Memory: 1421.12 MB\n",
            "Step 1073, Loss: 4.8348, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1074, Loss: 5.0875, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1075, Loss: 4.4777, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1076, Loss: 4.7737, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1077, Loss: 5.1420, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1078, Loss: 5.0792, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1079, Loss: 4.3225, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1080, Loss: 5.2617, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1081, Loss: 4.9759, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1082, Loss: 4.8967, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1083, Loss: 5.1240, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1084, Loss: 4.7111, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1085, Loss: 4.3399, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1086, Loss: 4.6310, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1087, Loss: 5.1060, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1088, Loss: 4.7970, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1089, Loss: 5.3633, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1090, Loss: 4.9949, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1091, Loss: 3.5496, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1092, Loss: 4.9593, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1093, Loss: 5.1298, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1094, Loss: 5.0956, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1095, Loss: 5.5942, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1096, Loss: 4.9316, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1097, Loss: 5.0616, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1098, Loss: 4.4845, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1099, Loss: 5.1959, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1100, Loss: 5.2051, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1101, Loss: 5.0063, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1102, Loss: 3.7589, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1103, Loss: 4.6597, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1104, Loss: 5.6518, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1105, Loss: 4.2821, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1106, Loss: 4.7093, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1107, Loss: 4.7926, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1108, Loss: 4.1956, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1109, Loss: 4.6162, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1110, Loss: 4.8918, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1111, Loss: 5.2237, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1112, Loss: 5.0983, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1113, Loss: 4.1510, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1114, Loss: 4.9529, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1115, Loss: 4.7648, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1116, Loss: 5.1227, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1117, Loss: 4.6937, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1118, Loss: 4.4310, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1119, Loss: 5.1798, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1120, Loss: 4.6987, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1121, Loss: 5.5857, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1122, Loss: 5.3012, LR: 0.000043, Memory: 1356.09 MB\n",
            "Step 1123, Loss: 5.2723, LR: 0.000043, Memory: 1421.12 MB\n",
            "Step 1124, Loss: 5.0181, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1125, Loss: 5.3028, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1126, Loss: 4.9422, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1127, Loss: 5.2132, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1128, Loss: 5.1606, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1129, Loss: 4.9436, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1130, Loss: 4.8120, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1131, Loss: 5.1651, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1132, Loss: 4.8498, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1133, Loss: 5.1920, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1134, Loss: 4.4987, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1135, Loss: 5.2463, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1136, Loss: 4.8110, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1137, Loss: 2.8804, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1138, Loss: 4.2996, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1139, Loss: 4.7203, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1140, Loss: 4.6780, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1141, Loss: 4.5555, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1142, Loss: 4.7657, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1143, Loss: 5.2681, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1144, Loss: 5.2455, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1145, Loss: 4.9505, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1146, Loss: 4.4930, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1147, Loss: 5.0353, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1148, Loss: 5.4277, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1149, Loss: 5.3621, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1150, Loss: 4.5984, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1151, Loss: 3.8691, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1152, Loss: 5.0713, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1153, Loss: 5.2114, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1154, Loss: 5.7212, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1155, Loss: 4.4917, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1156, Loss: 5.1453, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1157, Loss: 5.4349, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1158, Loss: 4.2812, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1159, Loss: 5.2716, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1160, Loss: 4.6308, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1161, Loss: 5.1300, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1162, Loss: 5.1087, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1163, Loss: 4.9899, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1164, Loss: 5.4648, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1165, Loss: 5.2529, LR: 0.000042, Memory: 1356.10 MB\n",
            "Step 1166, Loss: 4.8003, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1167, Loss: 5.3641, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1168, Loss: 5.0889, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1169, Loss: 4.9857, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1170, Loss: 5.2173, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1171, Loss: 5.0888, LR: 0.000042, Memory: 1356.09 MB\n",
            "Step 1172, Loss: 4.7681, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1173, Loss: 4.8714, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1174, Loss: 3.2298, LR: 0.000042, Memory: 1421.12 MB\n",
            "Step 1175, Loss: 4.8185, LR: 0.000041, Memory: 1356.10 MB\n",
            "Step 1176, Loss: 5.2171, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1177, Loss: 5.2805, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1178, Loss: 4.8815, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1179, Loss: 4.5455, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1180, Loss: 5.7124, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1181, Loss: 4.8180, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1182, Loss: 3.9894, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1183, Loss: 4.9961, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1184, Loss: 5.2021, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1185, Loss: 5.0857, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1186, Loss: 4.9040, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1187, Loss: 4.1639, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1188, Loss: 5.1834, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1189, Loss: 5.3860, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1190, Loss: 1.5633, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1191, Loss: 4.9402, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1192, Loss: 5.0737, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1193, Loss: 5.3470, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1194, Loss: 3.7925, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1195, Loss: 4.5099, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1196, Loss: 5.3773, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1197, Loss: 4.6821, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1198, Loss: 5.1276, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1199, Loss: 4.3588, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1200, Loss: 5.0469, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1201, Loss: 4.8963, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1202, Loss: 2.1124, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1203, Loss: 4.6448, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1204, Loss: 5.0907, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1205, Loss: 4.7389, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1206, Loss: 5.4811, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1207, Loss: 4.7921, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1208, Loss: 4.5497, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1209, Loss: 4.8367, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1210, Loss: 5.0428, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1211, Loss: 4.9569, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1212, Loss: 5.1356, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1213, Loss: 3.9112, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1214, Loss: 5.5853, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1215, Loss: 4.6870, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1216, Loss: 4.8477, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1217, Loss: 4.5952, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1218, Loss: 4.2566, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1219, Loss: 4.7347, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1220, Loss: 5.2972, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1221, Loss: 5.3448, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1222, Loss: 5.0696, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1223, Loss: 4.8794, LR: 0.000041, Memory: 1421.12 MB\n",
            "Step 1224, Loss: 5.3456, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1225, Loss: 5.0595, LR: 0.000041, Memory: 1356.09 MB\n",
            "Step 1226, Loss: 1.9935, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1227, Loss: 5.5926, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1228, Loss: 5.0231, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1229, Loss: 5.1207, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1230, Loss: 5.0828, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1231, Loss: 4.9338, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1232, Loss: 5.4298, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1233, Loss: 5.3043, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1234, Loss: 3.6915, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1235, Loss: 4.4168, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1236, Loss: 4.8075, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1237, Loss: 4.7684, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1238, Loss: 4.7186, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1239, Loss: 5.2556, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1240, Loss: 4.9024, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1241, Loss: 4.4959, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1242, Loss: 4.7703, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1243, Loss: 4.9233, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1244, Loss: 5.2976, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1245, Loss: 5.0280, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1246, Loss: 4.4880, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1247, Loss: 4.8128, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1248, Loss: 4.8470, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1249, Loss: 5.0786, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1250, Loss: 5.4784, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1251, Loss: 4.7870, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1252, Loss: 5.2182, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1253, Loss: 4.9037, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1254, Loss: 5.0677, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1255, Loss: 5.2562, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1256, Loss: 4.1858, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1257, Loss: 4.1774, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1258, Loss: 5.4206, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1259, Loss: 4.9809, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1260, Loss: 4.4480, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1261, Loss: 4.1430, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1262, Loss: 5.1048, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1263, Loss: 4.3430, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1264, Loss: 4.8817, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1265, Loss: 4.8126, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1266, Loss: 5.1268, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1267, Loss: 5.2171, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1268, Loss: 3.6643, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1269, Loss: 5.0304, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1270, Loss: 4.5913, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1271, Loss: 5.4713, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1272, Loss: 4.8768, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1273, Loss: 4.4434, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1274, Loss: 4.9585, LR: 0.000040, Memory: 1356.09 MB\n",
            "Step 1275, Loss: 5.4935, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1276, Loss: 5.0455, LR: 0.000040, Memory: 1421.12 MB\n",
            "Step 1277, Loss: 5.3282, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1278, Loss: 4.9744, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1279, Loss: 5.0991, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1280, Loss: 4.7403, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1281, Loss: 4.5776, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1282, Loss: 5.0506, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1283, Loss: 5.1102, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1284, Loss: 5.4198, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1285, Loss: 4.4352, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1286, Loss: 4.3185, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1287, Loss: 4.8398, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1288, Loss: 5.1417, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1289, Loss: 4.3357, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1290, Loss: 3.6616, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1291, Loss: 5.2683, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1292, Loss: 4.6733, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1293, Loss: 4.9753, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1294, Loss: 5.1626, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1295, Loss: 4.6872, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1296, Loss: 5.1342, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1297, Loss: 1.6173, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1298, Loss: 5.0063, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1299, Loss: 5.6074, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1300, Loss: 5.0606, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1301, Loss: 5.1499, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1302, Loss: 4.7666, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1303, Loss: 5.1957, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1304, Loss: 5.3614, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1305, Loss: 4.1997, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1306, Loss: 5.3221, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1307, Loss: 4.2703, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1308, Loss: 5.3734, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1309, Loss: 5.0884, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1310, Loss: 4.9721, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1311, Loss: 5.1183, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1312, Loss: 4.9898, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1313, Loss: 5.0430, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1314, Loss: 5.2137, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1315, Loss: 1.4410, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1316, Loss: 5.6062, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1317, Loss: 5.4172, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1318, Loss: 5.6365, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1319, Loss: 5.2520, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1320, Loss: 5.2707, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1321, Loss: 5.3678, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1322, Loss: 5.2777, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1323, Loss: 4.9054, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1324, Loss: 4.4946, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1325, Loss: 5.1583, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1326, Loss: 5.0724, LR: 0.000039, Memory: 1421.12 MB\n",
            "Step 1327, Loss: 4.9622, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1328, Loss: 4.7504, LR: 0.000039, Memory: 1356.09 MB\n",
            "Step 1329, Loss: 5.2145, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1330, Loss: 4.1797, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1331, Loss: 4.5355, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 1332, Loss: 5.1148, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 1333, Loss: 4.9457, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1334, Loss: 5.3606, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1335, Loss: 5.0108, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1336, Loss: 4.8410, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 1337, Loss: 5.8551, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 1338, Loss: 4.8918, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1339, Loss: 4.8887, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1340, Loss: 4.8763, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1341, Loss: 5.3078, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 1342, Loss: 4.3536, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 1343, Loss: 5.2482, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1344, Loss: 3.9848, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1345, Loss: 4.7547, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1346, Loss: 5.0586, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 1347, Loss: 5.0543, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 1348, Loss: 5.2753, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1349, Loss: 5.0687, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1350, Loss: 5.0210, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1351, Loss: 4.3179, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 1352, Loss: 5.3332, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 1353, Loss: 5.4606, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1354, Loss: 4.0172, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1355, Loss: 4.1329, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1356, Loss: 2.6792, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 1357, Loss: 4.7617, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 1358, Loss: 3.8985, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1359, Loss: 5.3731, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1360, Loss: 5.6159, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1361, Loss: 4.8477, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 1362, Loss: 4.7452, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1363, Loss: 4.3538, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1364, Loss: 4.1435, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1365, Loss: 4.9350, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 1366, Loss: 5.3851, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 1367, Loss: 5.0226, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1368, Loss: 4.6964, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1369, Loss: 4.5854, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1370, Loss: 5.4421, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 1371, Loss: 5.0594, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 1372, Loss: 5.1519, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1373, Loss: 4.5347, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1374, Loss: 4.6344, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1375, Loss: 4.9359, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 1376, Loss: 2.9779, LR: 0.000038, Memory: 1356.09 MB\n",
            "Step 1377, Loss: 4.7808, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1378, Loss: 4.7217, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1379, Loss: 4.5625, LR: 0.000038, Memory: 1421.12 MB\n",
            "Step 1380, Loss: 5.2157, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1381, Loss: 4.8170, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1382, Loss: 5.1601, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1383, Loss: 4.8785, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1384, Loss: 5.0553, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1385, Loss: 5.2690, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1386, Loss: 4.6824, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1387, Loss: 4.6158, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1388, Loss: 5.6220, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1389, Loss: 5.1381, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1390, Loss: 4.9101, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1391, Loss: 5.4116, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1392, Loss: 4.9063, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1393, Loss: 5.2874, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1394, Loss: 4.4757, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1395, Loss: 4.7722, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1396, Loss: 4.8576, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1397, Loss: 4.8718, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1398, Loss: 3.8323, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1399, Loss: 5.2563, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1400, Loss: 4.7473, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1401, Loss: 4.8592, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1402, Loss: 4.2076, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1403, Loss: 5.0008, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1404, Loss: 5.0649, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1405, Loss: 5.0550, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1406, Loss: 5.0764, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1407, Loss: 5.0909, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1408, Loss: 4.8325, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1409, Loss: 5.0906, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1410, Loss: 4.8983, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1411, Loss: 4.8098, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1412, Loss: 4.8797, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1413, Loss: 4.7484, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1414, Loss: 5.1513, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1415, Loss: 5.0064, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1416, Loss: 5.1707, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1417, Loss: 4.6040, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1418, Loss: 4.6326, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1419, Loss: 4.5369, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1420, Loss: 5.0097, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1421, Loss: 4.5009, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1422, Loss: 5.0083, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1423, Loss: 5.3583, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1424, Loss: 4.4935, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1425, Loss: 5.2008, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1426, Loss: 4.3858, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1427, Loss: 5.7271, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1428, Loss: 5.0943, LR: 0.000037, Memory: 1421.12 MB\n",
            "Step 1429, Loss: 4.9452, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1430, Loss: 4.2292, LR: 0.000037, Memory: 1356.09 MB\n",
            "Step 1431, Loss: 4.7579, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1432, Loss: 5.2770, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1433, Loss: 4.3483, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1434, Loss: 5.3811, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 1435, Loss: 4.2145, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 1436, Loss: 5.5785, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1437, Loss: 4.9110, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1438, Loss: 4.4671, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1439, Loss: 5.0219, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 1440, Loss: 5.0156, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1441, Loss: 5.4507, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1442, Loss: 4.1863, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1443, Loss: 4.5965, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1444, Loss: 5.0599, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 1445, Loss: 4.9926, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1446, Loss: 5.0656, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1447, Loss: 4.9583, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1448, Loss: 5.0811, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1449, Loss: 5.1903, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 1450, Loss: 4.8891, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 1451, Loss: 5.0928, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1452, Loss: 5.6159, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1453, Loss: 5.3377, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1454, Loss: 4.3084, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 1455, Loss: 4.8151, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 1456, Loss: 3.1688, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1457, Loss: 5.3262, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1458, Loss: 4.9202, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1459, Loss: 5.2266, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 1460, Loss: 4.5799, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 1461, Loss: 4.9433, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1462, Loss: 4.3988, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1463, Loss: 4.4932, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1464, Loss: 4.6450, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 1465, Loss: 5.9600, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 1466, Loss: 5.2222, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1467, Loss: 4.9228, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1468, Loss: 4.8262, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1469, Loss: 5.0715, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 1470, Loss: 5.2908, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 1471, Loss: 4.7150, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1472, Loss: 4.3856, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1473, Loss: 4.8465, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1474, Loss: 5.1592, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 1475, Loss: 5.3578, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 1476, Loss: 4.9836, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1477, Loss: 5.1323, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1478, Loss: 5.0261, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1479, Loss: 5.1626, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 1480, Loss: 5.0584, LR: 0.000036, Memory: 1356.09 MB\n",
            "Step 1481, Loss: 4.8693, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1482, Loss: 4.9424, LR: 0.000036, Memory: 1421.12 MB\n",
            "Step 1483, Loss: 5.0939, LR: 0.000035, Memory: 1421.12 MB\n",
            "Step 1484, Loss: 4.8287, LR: 0.000035, Memory: 1356.09 MB\n",
            "Step 1485, Loss: 5.0697, LR: 0.000035, Memory: 1356.09 MB\n",
            "Epoch 5/5, Avg Loss: 19.8063, Time: 536.74s, Speed: 44.28 examples/s\n",
            "Model weights saved to /content/drive/MyDrive/LLM/custom_llm_epoch_7.pth\n",
            "Scaled training phase complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "id": "Qgnfr--vaGtK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a154c58-cdf2-4378-e7b9-ed5f9132714a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Final Testing & Model Export\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from datasets import load_from_disk\n",
        "import sentencepiece as spm\n",
        "from google.colab import drive\n",
        "import onnx\n",
        "import torch.onnx\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# Define CustomLLM\n",
        "class CustomLLM(nn.Module):\n",
        "    def __init__(self, vocab_size=32000, d_model=768, num_heads=8, num_layers=8, ff_dim=3072):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=ff_dim,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
        "        self.fc = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.transformer(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "# Initialize model\n",
        "print(\"GPU Available:\", torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "try:\n",
        "    model = CustomLLM().to(device)\n",
        "    print(\"Model initialized and moved to device successfully!\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"Error initializing model: {e}\")\n",
        "    device = torch.device(\"cpu\")\n",
        "    model = CustomLLM().to(device)\n",
        "\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/LLM/custom_llm_epoch_7.pth\"\n",
        "try:\n",
        "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "    print(\"Final model loaded from checkpoint!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading checkpoint: {e}\")\n",
        "\n",
        "sp = spm.SentencePieceProcessor(model_file=\"/content/drive/MyDrive/LLM/mytokenizer.model\")\n",
        "print(\"Tokenizer loaded!\")\n",
        "\n",
        "\n",
        "def generate_text(model, tokenizer, prompt, max_length=50, temperature=1.0, repetition_penalty=1.2):\n",
        "    model.eval()\n",
        "    input_ids = torch.tensor([tokenizer.encode(prompt, out_type=int)], dtype=torch.long).to(device)\n",
        "    generated_ids = input_ids.clone()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_length):\n",
        "            outputs = model(input_ids)\n",
        "            next_token_logits = outputs[:, -1, :] / temperature\n",
        "\n",
        "            for prev_id in generated_ids[0]:\n",
        "                next_token_logits[0, prev_id] /= repetition_penalty\n",
        "\n",
        "            next_token = torch.multinomial(torch.softmax(next_token_logits, dim=-1), num_samples=1)\n",
        "            input_ids = torch.cat([input_ids, next_token], dim=-1)\n",
        "            generated_ids = torch.cat([generated_ids, next_token], dim=-1)\n",
        "\n",
        "\n",
        "            if tokenizer.eos_id() is not None and next_token.item() == tokenizer.eos_id():\n",
        "                break\n",
        "\n",
        "    generated_text = tokenizer.decode(generated_ids.squeeze().tolist())\n",
        "    return generated_text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.eval()\n",
        "example_input = torch.randint(0, 32000, (1, 128), dtype=torch.long).to(device)\n",
        "try:\n",
        "    traced_model = torch.jit.trace(model, example_input, strict=False)\n",
        "    torchscript_path = \"/content/drive/MyDrive/LLM/custom_llm_torchscript.pt\"\n",
        "    traced_model.save(torchscript_path)\n",
        "    print(f\"TorchScript model saved to {torchscript_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"TorchScript export failed: {e}\")\n",
        "\n",
        "\n",
        "onnx_path = \"/content/drive/MyDrive/LLM/custom_llm.onnx\"\n",
        "try:\n",
        "    torch.onnx.export(\n",
        "        model,\n",
        "        example_input,\n",
        "        onnx_path,\n",
        "        export_params=True,\n",
        "        opset_version=13,\n",
        "        do_constant_folding=True,\n",
        "        input_names=[\"input\"],\n",
        "        output_names=[\"output\"],\n",
        "        dynamic_axes={\"input\": {0: \"batch_size\", 1: \"sequence_length\"}, \"output\": {0: \"batch_size\", 1: \"sequence_length\"}},\n",
        "        verbose=True\n",
        "    )\n",
        "    print(f\"ONNX model saved to {onnx_path}\")\n",
        "    onnx_model = onnx.load(onnx_path)\n",
        "    onnx.checker.check_model(onnx_model)\n",
        "    print(\"ONNX model verified!\")\n",
        "except Exception as e:\n",
        "    print(f\"ONNX export failed: {e}\")\n",
        "\n",
        "# Ensure files are in Drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Model and tokenizer already uploaded to /content/drive/MyDrive/LLM/\")\n",
        "\n",
        "print(\"Final testing and export complete!\")"
      ],
      "metadata": {
        "id": "tIEC2A3kggGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50358e97-fcf8-43ec-9aaa-75073cbf22de"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: True\n",
            "Model initialized and moved to device successfully!\n",
            "Final model loaded from checkpoint!\n",
            "Tokenizer loaded!\n",
            "TorchScript export failed: Tracing failed sanity checks!\n",
            "ERROR: Graphs differed across invocations!\n",
            "\tGraph diff:\n",
            "\t\t  graph(%self.1 : __torch__.CustomLLM,\n",
            "\t\t        %x : Tensor):\n",
            "\t\t    %fc : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%self.1)\n",
            "\t\t    %transformer : __torch__.torch.nn.modules.transformer.TransformerEncoder = prim::GetAttr[name=\"transformer\"](%self.1)\n",
            "\t\t    %embedding : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%self.1)\n",
            "\t\t    %8 : bool = prim::Constant[value=0](), scope: __module.embedding # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2551:0\n",
            "\t\t    %9 : int = prim::Constant[value=-1](), scope: __module.embedding # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2551:0\n",
            "\t\t-   %weight.35 : Tensor = prim::GetAttr[name=\"weight\"](%embedding)\n",
            "\t\t?            -\n",
            "\t\t+   %weight.3 : Tensor = prim::GetAttr[name=\"weight\"](%embedding)\n",
            "\t\t-   %src : Tensor = aten::embedding(%weight.35, %x, %9, %8, %8), scope: __module.embedding # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2551:0\n",
            "\t\t?                                            -\n",
            "\t\t+   %src.1 : Tensor = aten::embedding(%weight.3, %x, %9, %8, %8), scope: __module.embedding # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2551:0\n",
            "\t\t?       ++\n",
            "\t\t-   %12 : bool = prim::Constant[value=0](), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n",
            "\t\t-   %13 : float = prim::Constant[value=0.](), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n",
            "\t\t-   %14 : NoneType = prim::Constant(), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %15 : int = prim::Constant[value=8](), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6406:0\n",
            "\t\t-   %16 : int = prim::Constant[value=-2](), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5619:0\n",
            "\t\t-   %17 : int = prim::Constant[value=3](), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1421:0\n",
            "\t\t-   %18 : int = prim::Constant[value=-1](), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5610:0\n",
            "\t\t-   %19 : str = prim::Constant[value=\"trunc\"](), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n",
            "\t\t-   %20 : Tensor = prim::Constant[value={8}](), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n",
            "\t\t-   %21 : int = prim::Constant[value=2](), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %22 : int = prim::Constant[value=0](), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1339:0\n",
            "\t\t?     -                              ^                                                              ----------------------------------------                                                             ^^^^^^^ ^    ^^^^\n",
            "\t\t+   %12 : int = prim::Constant[value=768](), scope: __module.transformer/__module.transformer.layers.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:887:0\n",
            "\t\t?    +                               ^^^                                                                                                                          ++ ^^^ ^^^^    ^^^\n",
            "\t\t-   %23 : int = prim::Constant[value=1](), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1339:0\n",
            "\t\t?    ^                               ^                                                              ----------------------------------------                                                             ^^^^^^^ ^    ^^^^\n",
            "\t\t+   %13 : int = prim::Constant[value=8](), scope: __module.transformer/__module.transformer.layers.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:887:0\n",
            "\t\t?    ^                               ^                                                                                                                          ++ ^^^ ^^^^    ^^^\n",
            "\t\t-   %24 : float = prim::Constant[value=0.10000000000000001](), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.dropout1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %25 : bool = prim::Constant[value=1](), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "\t\t?    ^^                               ^                                                              ------------------------------------                                                     ----- ^^^    ^^^^\n",
            "\t\t+   %14 : bool = prim::Constant[value=0](), scope: __module.transformer/__module.transformer.layers.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:887:0\n",
            "\t\t?    ^^                               ^                                                                                                                  +++++++++++++  ^^^^    ^^^\n",
            "\t\t-   %26 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "\t\t?    ^^^^^^^^^^                                                                                                            ------------------------------------                                                    ^^^^^^^^^^    ^^^^\n",
            "\t\t+   %15 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.transformer/__module.transformer.layers.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:887:0\n",
            "\t\t?    ^^^^^^^^^^                                                                                                                                                                ^^^^^^^^^^^^^^^^^^^    ^^^\n",
            "\t\t-   %27 : int = prim::Constant[value=768](), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "\t\t+   %16 : NoneType = prim::Constant(), scope: __module.transformer/__module.transformer.layers.0\n",
            "\t\t    %layers : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"layers\"](%transformer)\n",
            "\t\t    %_7 : __torch__.torch.nn.modules.transformer.TransformerEncoderLayer = prim::GetAttr[name=\"7\"](%layers)\n",
            "\t\t    %layers.13 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"layers\"](%transformer)\n",
            "\t\t    %_6 : __torch__.torch.nn.modules.transformer.TransformerEncoderLayer = prim::GetAttr[name=\"6\"](%layers.13)\n",
            "\t\t    %layers.11 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"layers\"](%transformer)\n",
            "\t\t    %_5 : __torch__.torch.nn.modules.transformer.TransformerEncoderLayer = prim::GetAttr[name=\"5\"](%layers.11)\n",
            "\t\t    %layers.9 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"layers\"](%transformer)\n",
            "\t\t    %_4 : __torch__.torch.nn.modules.transformer.TransformerEncoderLayer = prim::GetAttr[name=\"4\"](%layers.9)\n",
            "\t\t    %layers.7 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"layers\"](%transformer)\n",
            "\t\t    %_3 : __torch__.torch.nn.modules.transformer.TransformerEncoderLayer = prim::GetAttr[name=\"3\"](%layers.7)\n",
            "\t\t    %layers.5 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"layers\"](%transformer)\n",
            "\t\t    %_2 : __torch__.torch.nn.modules.transformer.TransformerEncoderLayer = prim::GetAttr[name=\"2\"](%layers.5)\n",
            "\t\t    %layers.3 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"layers\"](%transformer)\n",
            "\t\t    %_1 : __torch__.torch.nn.modules.transformer.TransformerEncoderLayer = prim::GetAttr[name=\"1\"](%layers.3)\n",
            "\t\t    %layers.1 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name=\"layers\"](%transformer)\n",
            "\t\t    %_0 : __torch__.torch.nn.modules.transformer.TransformerEncoderLayer = prim::GetAttr[name=\"0\"](%layers.1)\n",
            "\t\t+   %linear2.3 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_0)\n",
            "\t\t+   %bias.9 : Tensor = prim::GetAttr[name=\"bias\"](%linear2.3)\n",
            "\t\t+   %linear2.1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_0)\n",
            "\t\t+   %weight.13 : Tensor = prim::GetAttr[name=\"weight\"](%linear2.1)\n",
            "\t\t+   %linear1.3 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_0)\n",
            "\t\t+   %bias.7 : Tensor = prim::GetAttr[name=\"bias\"](%linear1.3)\n",
            "\t\t+   %linear1.1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_0)\n",
            "\t\t+   %weight.11 : Tensor = prim::GetAttr[name=\"weight\"](%linear1.1)\n",
            "\t\t+   %norm2.3 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_0)\n",
            "\t\t+   %bias.5 : Tensor = prim::GetAttr[name=\"bias\"](%norm2.3)\n",
            "\t\t    %norm2.1 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_0)\n",
            "\t\t+   %weight.9 : Tensor = prim::GetAttr[name=\"weight\"](%norm2.1)\n",
            "\t\t-   %dropout2.1 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout2\"](%_0)\n",
            "\t\t-   %linear2.1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_0)\n",
            "\t\t-   %dropout.1 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout\"](%_0)\n",
            "\t\t-   %linear1.1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_0)\n",
            "\t\t?    -- ^^   ^                                 ---  ^^ -                        -- ^^\n",
            "\t\t+   %norm1.3 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_0)\n",
            "\t\t?     ^ +  ^                              +++++  +++++   ^^  ++++                        ^ +\n",
            "\t\t+   %bias.3 : Tensor = prim::GetAttr[name=\"bias\"](%norm1.3)\n",
            "\t\t    %norm1.1 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_0)\n",
            "\t\t-   %dropout1.1 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout1\"](%_0)\n",
            "\t\t+   %weight.7 : Tensor = prim::GetAttr[name=\"weight\"](%norm1.1)\n",
            "\t\t+   %self_attn.7 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_0)\n",
            "\t\t+   %out_proj.3 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.7)\n",
            "\t\t+   %bias.1 : Tensor = prim::GetAttr[name=\"bias\"](%out_proj.3)\n",
            "\t\t+   %self_attn.5 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_0)\n",
            "\t\t+   %out_proj.1 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.5)\n",
            "\t\t+   %weight.5 : Tensor = prim::GetAttr[name=\"weight\"](%out_proj.1)\n",
            "\t\t+   %self_attn.3 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_0)\n",
            "\t\t+   %in_proj_bias.1 : Tensor = prim::GetAttr[name=\"in_proj_bias\"](%self_attn.3)\n",
            "\t\t    %self_attn.1 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_0)\n",
            "\t\t-   %out_proj.3 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.1)\n",
            "\t\t-   %bias.33 : Tensor = prim::GetAttr[name=\"bias\"](%out_proj.3)\n",
            "\t\t-   %out_proj.1 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.1)\n",
            "\t\t-   %weight.37 : Tensor = prim::GetAttr[name=\"weight\"](%out_proj.1)\n",
            "\t\t-   %in_proj_bias.1 : Tensor = prim::GetAttr[name=\"in_proj_bias\"](%self_attn.1)\n",
            "\t\t    %in_proj_weight.1 : Tensor = prim::GetAttr[name=\"in_proj_weight\"](%self_attn.1)\n",
            "\t\t+   %src.3 : Tensor = aten::_transformer_encoder_layer_fwd(%src.1, %12, %13, %in_proj_weight.1, %in_proj_bias.1, %weight.5, %bias.1, %14, %14, %15, %weight.7, %bias.3, %weight.9, %bias.5, %weight.11, %bias.7, %weight.13, %bias.9, %16, %16), scope: __module.transformer/__module.transformer.layers.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:887:0\n",
            "\t\t+   %linear2.7 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_1)\n",
            "\t\t-   %query.1 : Tensor = aten::transpose(%src, %23, %22), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1339:0\n",
            "\t\t-   %59 : int = aten::size(%query.1, %22), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %tgt_len.1 : Tensor = prim::NumToTensor(%59), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %61 : int = aten::size(%query.1, %23), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %bsz.1 : Tensor = prim::NumToTensor(%61), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %63 : int = aten::size(%query.1, %21), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %embed_dim.1 : Tensor = prim::NumToTensor(%63), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %head_dim.1 : Tensor = aten::div(%embed_dim.1, %20, %19), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n",
            "\t\t-   %66 : int = aten::Int(%head_dim.1), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %67 : int = aten::Int(%head_dim.1), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %68 : int = aten::Int(%head_dim.1), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %69 : int = aten::Int(%head_dim.1), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %70 : int = aten::Int(%head_dim.1), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %71 : int = aten::Int(%head_dim.1), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %72 : int = aten::size(%query.1, %18), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5610:0\n",
            "\t\t-   %73 : Tensor = aten::linear(%query.1, %in_proj_weight.1, %in_proj_bias.1), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5614:0\n",
            "\t\t-   %74 : int[] = prim::ListConstruct(%17, %72), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %75 : Tensor = aten::unflatten(%73, %18, %74), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1421:0\n",
            "\t\t-   %76 : Tensor = aten::unsqueeze(%75, %22), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5618:0\n",
            "\t\t-   %77 : Tensor = aten::transpose(%76, %22, %16), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5619:0\n",
            "\t\t-   %78 : Tensor = aten::squeeze(%77, %16), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5620:0\n",
            "\t\t-   %proj.1 : Tensor = aten::contiguous(%78, %22), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5621:0\n",
            "\t\t-   %q.1 : Tensor = aten::select(%proj.1, %22, %22), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %k.1 : Tensor = aten::select(%proj.1, %22, %23), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %v.1 : Tensor = aten::select(%proj.1, %22, %21), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %83 : Tensor = aten::mul(%bsz.1, %20), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %84 : int = aten::Int(%83), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %85 : int[] = prim::ListConstruct(%59, %84, %71), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %86 : Tensor = aten::view(%q.1, %85), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %q.3 : Tensor = aten::transpose(%86, %22, %23), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %88 : int = aten::size(%k.1, %22), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %89 : Tensor = aten::mul(%bsz.1, %20), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %90 : int = aten::Int(%89), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %91 : int[] = prim::ListConstruct(%88, %90, %70), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %92 : Tensor = aten::view(%k.1, %91), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %k.3 : Tensor = aten::transpose(%92, %22, %23), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %94 : int = aten::size(%v.1, %22), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %95 : Tensor = aten::mul(%bsz.1, %20), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %96 : int = aten::Int(%95), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %97 : int[] = prim::ListConstruct(%94, %96, %69), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %98 : Tensor = aten::view(%v.1, %97), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %v.3 : Tensor = aten::transpose(%98, %22, %23), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %100 : int = aten::size(%k.3, %23), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n",
            "\t\t-   %101 : int[] = prim::ListConstruct(%61, %15, %59, %68), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %q.5 : Tensor = aten::view(%q.3, %101), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6406:0\n",
            "\t\t-   %103 : int[] = prim::ListConstruct(%61, %15, %100, %67), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %k.5 : Tensor = aten::view(%k.3, %103), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6407:0\n",
            "\t\t-   %105 : int[] = prim::ListConstruct(%61, %15, %100, %66), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %v.5 : Tensor = aten::view(%v.3, %105), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6408:0\n",
            "\t\t-   %attn_output.1 : Tensor = aten::scaled_dot_product_attention(%q.5, %k.5, %v.5, %14, %13, %12, %14, %12), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n",
            "\t\t-   %108 : int[] = prim::ListConstruct(%21, %22, %23, %17), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %109 : Tensor = aten::permute(%attn_output.1, %108), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %110 : Tensor = aten::contiguous(%109, %22), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %111 : Tensor = aten::mul(%bsz.1, %tgt_len.1), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %112 : int = aten::Int(%111), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %113 : int[] = prim::ListConstruct(%112, %63), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %attn_output.3 : Tensor = aten::view(%110, %113), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %attn_output.5 : Tensor = aten::linear(%attn_output.3, %weight.37, %bias.33), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6417:0\n",
            "\t\t-   %116 : int = aten::size(%attn_output.5, %23), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n",
            "\t\t-   %117 : int[] = prim::ListConstruct(%59, %61, %116), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn\n",
            "\t\t-   %attn_output.7 : Tensor = aten::view(%attn_output.5, %117), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n",
            "\t\t-   %input.1 : Tensor = aten::transpose(%attn_output.7, %23, %22), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1395:0\n",
            "\t\t-   %120 : Tensor = aten::dropout(%input.1, %24, %12), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.dropout1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %input.3 : Tensor = aten::add(%src, %120, %23), scope: __module.transformer/__module.transformer.layers.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:919:0\n",
            "\t\t-   %bias.35 : Tensor = prim::GetAttr[name=\"bias\"](%norm1.1)\n",
            "\t\t-   %weight.39 : Tensor = prim::GetAttr[name=\"weight\"](%norm1.1)\n",
            "\t\t-   %124 : int[] = prim::ListConstruct(%27), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.norm1\n",
            "\t\t-   %input.5 : Tensor = aten::layer_norm(%input.3, %124, %weight.39, %bias.35, %26, %25), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "\t\t-   %bias.37 : Tensor = prim::GetAttr[name=\"bias\"](%linear1.1)\n",
            "\t\t-   %weight.41 : Tensor = prim::GetAttr[name=\"weight\"](%linear1.1)\n",
            "\t\t-   %input.7 : Tensor = aten::linear(%input.5, %weight.41, %bias.37), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.linear1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "\t\t-   %input.9 : Tensor = aten::relu(%input.7), scope: __module.transformer/__module.transformer.layers.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1704:0\n",
            "\t\t-   %input.11 : Tensor = aten::dropout(%input.9, %24, %12), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.dropout # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %bias.39 : Tensor = prim::GetAttr[name=\"bias\"](%linear2.1)\n",
            "\t\t?         ^                                                 ^\n",
            "\t\t+   %bias.19 : Tensor = prim::GetAttr[name=\"bias\"](%linear2.7)\n",
            "\t\t?         ^                                                 ^\n",
            "\t\t+   %linear2.5 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_1)\n",
            "\t\t-   %weight.43 : Tensor = prim::GetAttr[name=\"weight\"](%linear2.1)\n",
            "\t\t?           ^                                                   ^\n",
            "\t\t+   %weight.23 : Tensor = prim::GetAttr[name=\"weight\"](%linear2.5)\n",
            "\t\t?           ^                                                   ^\n",
            "\t\t+   %linear1.7 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_1)\n",
            "\t\t-   %input.13 : Tensor = aten::linear(%input.11, %weight.43, %bias.39), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.linear2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "\t\t-   %134 : Tensor = aten::dropout(%input.13, %24, %12), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.dropout2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %input.15 : Tensor = aten::add(%input.5, %134, %23), scope: __module.transformer/__module.transformer.layers.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:922:0\n",
            "\t\t-   %bias.41 : Tensor = prim::GetAttr[name=\"bias\"](%norm2.1)\n",
            "\t\t?         -                                          ^ ^^ ^\n",
            "\t\t+   %bias.17 : Tensor = prim::GetAttr[name=\"bias\"](%linear1.7)\n",
            "\t\t?          +                                        ++ ^^ ^ ^\n",
            "\t\t+   %linear1.5 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_1)\n",
            "\t\t-   %weight.45 : Tensor = prim::GetAttr[name=\"weight\"](%norm2.1)\n",
            "\t\t?           ^^                                           ^ ^^ ^\n",
            "\t\t+   %weight.21 : Tensor = prim::GetAttr[name=\"weight\"](%linear1.5)\n",
            "\t\t?           ^^                                          ++ ^^ ^ ^\n",
            "\t\t-   %138 : int[] = prim::ListConstruct(%27), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.norm2\n",
            "\t\t-   %query.3 : Tensor = aten::layer_norm(%input.15, %138, %weight.45, %bias.41, %26, %25), scope: __module.transformer/__module.transformer.layers.0/__module.transformer.layers.0.norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "\t\t-   %norm2.3 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_1)\n",
            "\t\t?          ^\n",
            "\t\t+   %norm2.7 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_1)\n",
            "\t\t?          ^\n",
            "\t\t-   %dropout2.3 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout2\"](%_1)\n",
            "\t\t+   %bias.15 : Tensor = prim::GetAttr[name=\"bias\"](%norm2.7)\n",
            "\t\t-   %linear2.3 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_1)\n",
            "\t\t?    -- ^^   ^                                 ---  ^^ -                        -- ^^\n",
            "\t\t+   %norm2.5 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_1)\n",
            "\t\t?     ^ +  ^                              +++++  +++++   ^^  ++++                        ^ +\n",
            "\t\t+   %weight.19 : Tensor = prim::GetAttr[name=\"weight\"](%norm2.5)\n",
            "\t\t-   %dropout.3 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout\"](%_1)\n",
            "\t\t-   %linear1.3 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_1)\n",
            "\t\t-   %norm1.3 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_1)\n",
            "\t\t?          ^\n",
            "\t\t+   %norm1.7 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_1)\n",
            "\t\t?          ^\n",
            "\t\t-   %dropout1.3 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout1\"](%_1)\n",
            "\t\t+   %bias.13 : Tensor = prim::GetAttr[name=\"bias\"](%norm1.7)\n",
            "\t\t+   %norm1.5 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_1)\n",
            "\t\t+   %weight.17 : Tensor = prim::GetAttr[name=\"weight\"](%norm1.5)\n",
            "\t\t+   %self_attn.15 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_1)\n",
            "\t\t+   %out_proj.7 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.15)\n",
            "\t\t+   %bias.11 : Tensor = prim::GetAttr[name=\"bias\"](%out_proj.7)\n",
            "\t\t-   %self_attn.3 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_1)\n",
            "\t\t+   %self_attn.13 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_1)\n",
            "\t\t?              +\n",
            "\t\t-   %out_proj.7 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.3)\n",
            "\t\t-   %bias.43 : Tensor = prim::GetAttr[name=\"bias\"](%out_proj.7)\n",
            "\t\t-   %out_proj.5 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.3)\n",
            "\t\t-   %weight.47 : Tensor = prim::GetAttr[name=\"weight\"](%out_proj.5)\n",
            "\t\t-   %in_proj_bias.3 : Tensor = prim::GetAttr[name=\"in_proj_bias\"](%self_attn.3)\n",
            "\t\t-   %in_proj_weight.3 : Tensor = prim::GetAttr[name=\"in_proj_weight\"](%self_attn.3)\n",
            "\t\t-   %query.5 : Tensor = aten::transpose(%query.3, %23, %22), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1339:0\n",
            "\t\t-   %155 : int = aten::size(%query.5, %22), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %tgt_len.3 : Tensor = prim::NumToTensor(%155), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %157 : int = aten::size(%query.5, %23), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %bsz.3 : Tensor = prim::NumToTensor(%157), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %159 : int = aten::size(%query.5, %21), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %embed_dim.3 : Tensor = prim::NumToTensor(%159), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %head_dim.3 : Tensor = aten::div(%embed_dim.3, %20, %19), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n",
            "\t\t-   %162 : int = aten::Int(%head_dim.3), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %163 : int = aten::Int(%head_dim.3), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %164 : int = aten::Int(%head_dim.3), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %165 : int = aten::Int(%head_dim.3), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %166 : int = aten::Int(%head_dim.3), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %167 : int = aten::Int(%head_dim.3), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %168 : int = aten::size(%query.5, %18), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5610:0\n",
            "\t\t-   %169 : Tensor = aten::linear(%query.5, %in_proj_weight.3, %in_proj_bias.3), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5614:0\n",
            "\t\t-   %170 : int[] = prim::ListConstruct(%17, %168), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %171 : Tensor = aten::unflatten(%169, %18, %170), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1421:0\n",
            "\t\t-   %172 : Tensor = aten::unsqueeze(%171, %22), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5618:0\n",
            "\t\t-   %173 : Tensor = aten::transpose(%172, %22, %16), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5619:0\n",
            "\t\t-   %174 : Tensor = aten::squeeze(%173, %16), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5620:0\n",
            "\t\t-   %proj.3 : Tensor = aten::contiguous(%174, %22), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5621:0\n",
            "\t\t-   %q.7 : Tensor = aten::select(%proj.3, %22, %22), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %k.7 : Tensor = aten::select(%proj.3, %22, %23), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %v.7 : Tensor = aten::select(%proj.3, %22, %21), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %179 : Tensor = aten::mul(%bsz.3, %20), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %180 : int = aten::Int(%179), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %181 : int[] = prim::ListConstruct(%155, %180, %167), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %182 : Tensor = aten::view(%q.7, %181), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %q.9 : Tensor = aten::transpose(%182, %22, %23), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %184 : int = aten::size(%k.7, %22), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %185 : Tensor = aten::mul(%bsz.3, %20), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %186 : int = aten::Int(%185), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %187 : int[] = prim::ListConstruct(%184, %186, %166), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %188 : Tensor = aten::view(%k.7, %187), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %k.9 : Tensor = aten::transpose(%188, %22, %23), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %190 : int = aten::size(%v.7, %22), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %191 : Tensor = aten::mul(%bsz.3, %20), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %192 : int = aten::Int(%191), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %193 : int[] = prim::ListConstruct(%190, %192, %165), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %194 : Tensor = aten::view(%v.7, %193), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %v.9 : Tensor = aten::transpose(%194, %22, %23), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %196 : int = aten::size(%k.9, %23), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n",
            "\t\t-   %197 : int[] = prim::ListConstruct(%157, %15, %155, %164), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %q.11 : Tensor = aten::view(%q.9, %197), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6406:0\n",
            "\t\t-   %199 : int[] = prim::ListConstruct(%157, %15, %196, %163), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %k.11 : Tensor = aten::view(%k.9, %199), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6407:0\n",
            "\t\t-   %201 : int[] = prim::ListConstruct(%157, %15, %196, %162), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %v.11 : Tensor = aten::view(%v.9, %201), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6408:0\n",
            "\t\t-   %attn_output.9 : Tensor = aten::scaled_dot_product_attention(%q.11, %k.11, %v.11, %14, %13, %12, %14, %12), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n",
            "\t\t-   %204 : int[] = prim::ListConstruct(%21, %22, %23, %17), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %205 : Tensor = aten::permute(%attn_output.9, %204), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %206 : Tensor = aten::contiguous(%205, %22), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %207 : Tensor = aten::mul(%bsz.3, %tgt_len.3), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %208 : int = aten::Int(%207), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %209 : int[] = prim::ListConstruct(%208, %159), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %attn_output.11 : Tensor = aten::view(%206, %209), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %attn_output.13 : Tensor = aten::linear(%attn_output.11, %weight.47, %bias.43), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6417:0\n",
            "\t\t-   %212 : int = aten::size(%attn_output.13, %23), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n",
            "\t\t-   %213 : int[] = prim::ListConstruct(%155, %157, %212), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn\n",
            "\t\t-   %attn_output.15 : Tensor = aten::view(%attn_output.13, %213), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n",
            "\t\t-   %input.17 : Tensor = aten::transpose(%attn_output.15, %23, %22), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1395:0\n",
            "\t\t-   %216 : Tensor = aten::dropout(%input.17, %24, %12), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.dropout1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %input.19 : Tensor = aten::add(%query.3, %216, %23), scope: __module.transformer/__module.transformer.layers.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:919:0\n",
            "\t\t-   %bias.45 : Tensor = prim::GetAttr[name=\"bias\"](%norm1.3)\n",
            "\t\t-   %weight.49 : Tensor = prim::GetAttr[name=\"weight\"](%norm1.3)\n",
            "\t\t-   %220 : int[] = prim::ListConstruct(%27), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.norm1\n",
            "\t\t-   %input.21 : Tensor = aten::layer_norm(%input.19, %220, %weight.49, %bias.45, %26, %25), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "\t\t-   %bias.47 : Tensor = prim::GetAttr[name=\"bias\"](%linear1.3)\n",
            "\t\t-   %weight.51 : Tensor = prim::GetAttr[name=\"weight\"](%linear1.3)\n",
            "\t\t-   %input.23 : Tensor = aten::linear(%input.21, %weight.51, %bias.47), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.linear1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "\t\t-   %input.25 : Tensor = aten::relu(%input.23), scope: __module.transformer/__module.transformer.layers.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1704:0\n",
            "\t\t-   %input.27 : Tensor = aten::dropout(%input.25, %24, %12), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.dropout # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %bias.49 : Tensor = prim::GetAttr[name=\"bias\"](%linear2.3)\n",
            "\t\t-   %weight.53 : Tensor = prim::GetAttr[name=\"weight\"](%linear2.3)\n",
            "\t\t-   %input.29 : Tensor = aten::linear(%input.27, %weight.53, %bias.49), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.linear2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "\t\t-   %230 : Tensor = aten::dropout(%input.29, %24, %12), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.dropout2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %input.31 : Tensor = aten::add(%input.21, %230, %23), scope: __module.transformer/__module.transformer.layers.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:922:0\n",
            "\t\t-   %bias.51 : Tensor = prim::GetAttr[name=\"bias\"](%norm2.3)\n",
            "\t\t-   %weight.55 : Tensor = prim::GetAttr[name=\"weight\"](%norm2.3)\n",
            "\t\t-   %234 : int[] = prim::ListConstruct(%27), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.norm2\n",
            "\t\t-   %query.7 : Tensor = aten::layer_norm(%input.31, %234, %weight.55, %bias.51, %26, %25), scope: __module.transformer/__module.transformer.layers.1/__module.transformer.layers.1.norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "\t\t-   %norm2.5 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_2)\n",
            "\t\t-   %dropout2.5 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout2\"](%_2)\n",
            "\t\t-   %linear2.5 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_2)\n",
            "\t\t-   %dropout.5 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout\"](%_2)\n",
            "\t\t-   %linear1.5 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_2)\n",
            "\t\t-   %norm1.5 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_2)\n",
            "\t\t-   %dropout1.5 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout1\"](%_2)\n",
            "\t\t-   %self_attn.5 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_2)\n",
            "\t\t-   %out_proj.11 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.5)\n",
            "\t\t-   %bias.53 : Tensor = prim::GetAttr[name=\"bias\"](%out_proj.11)\n",
            "\t\t-   %out_proj.9 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.5)\n",
            "\t\t-   %weight.57 : Tensor = prim::GetAttr[name=\"weight\"](%out_proj.9)\n",
            "\t\t-   %in_proj_bias.5 : Tensor = prim::GetAttr[name=\"in_proj_bias\"](%self_attn.5)\n",
            "\t\t-   %in_proj_weight.5 : Tensor = prim::GetAttr[name=\"in_proj_weight\"](%self_attn.5)\n",
            "\t\t-   %query.9 : Tensor = aten::transpose(%query.7, %23, %22), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1339:0\n",
            "\t\t-   %251 : int = aten::size(%query.9, %22), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %tgt_len.5 : Tensor = prim::NumToTensor(%251), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %253 : int = aten::size(%query.9, %23), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %bsz.5 : Tensor = prim::NumToTensor(%253), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %255 : int = aten::size(%query.9, %21), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %embed_dim.5 : Tensor = prim::NumToTensor(%255), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %head_dim.5 : Tensor = aten::div(%embed_dim.5, %20, %19), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n",
            "\t\t-   %258 : int = aten::Int(%head_dim.5), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %259 : int = aten::Int(%head_dim.5), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %260 : int = aten::Int(%head_dim.5), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %261 : int = aten::Int(%head_dim.5), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %262 : int = aten::Int(%head_dim.5), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %263 : int = aten::Int(%head_dim.5), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %264 : int = aten::size(%query.9, %18), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5610:0\n",
            "\t\t-   %265 : Tensor = aten::linear(%query.9, %in_proj_weight.5, %in_proj_bias.5), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5614:0\n",
            "\t\t-   %266 : int[] = prim::ListConstruct(%17, %264), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %267 : Tensor = aten::unflatten(%265, %18, %266), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1421:0\n",
            "\t\t-   %268 : Tensor = aten::unsqueeze(%267, %22), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5618:0\n",
            "\t\t-   %269 : Tensor = aten::transpose(%268, %22, %16), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5619:0\n",
            "\t\t-   %270 : Tensor = aten::squeeze(%269, %16), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5620:0\n",
            "\t\t-   %proj.5 : Tensor = aten::contiguous(%270, %22), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5621:0\n",
            "\t\t-   %q.13 : Tensor = aten::select(%proj.5, %22, %22), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %k.13 : Tensor = aten::select(%proj.5, %22, %23), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %v.13 : Tensor = aten::select(%proj.5, %22, %21), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %275 : Tensor = aten::mul(%bsz.5, %20), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %276 : int = aten::Int(%275), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %277 : int[] = prim::ListConstruct(%251, %276, %263), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %278 : Tensor = aten::view(%q.13, %277), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %q.15 : Tensor = aten::transpose(%278, %22, %23), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %280 : int = aten::size(%k.13, %22), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %281 : Tensor = aten::mul(%bsz.5, %20), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %282 : int = aten::Int(%281), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %283 : int[] = prim::ListConstruct(%280, %282, %262), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %284 : Tensor = aten::view(%k.13, %283), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %k.15 : Tensor = aten::transpose(%284, %22, %23), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %286 : int = aten::size(%v.13, %22), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %287 : Tensor = aten::mul(%bsz.5, %20), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %288 : int = aten::Int(%287), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %289 : int[] = prim::ListConstruct(%286, %288, %261), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %290 : Tensor = aten::view(%v.13, %289), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %v.15 : Tensor = aten::transpose(%290, %22, %23), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %292 : int = aten::size(%k.15, %23), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n",
            "\t\t-   %293 : int[] = prim::ListConstruct(%253, %15, %251, %260), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %q.17 : Tensor = aten::view(%q.15, %293), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6406:0\n",
            "\t\t-   %295 : int[] = prim::ListConstruct(%253, %15, %292, %259), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %k.17 : Tensor = aten::view(%k.15, %295), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6407:0\n",
            "\t\t-   %297 : int[] = prim::ListConstruct(%253, %15, %292, %258), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %v.17 : Tensor = aten::view(%v.15, %297), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6408:0\n",
            "\t\t-   %attn_output.17 : Tensor = aten::scaled_dot_product_attention(%q.17, %k.17, %v.17, %14, %13, %12, %14, %12), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n",
            "\t\t-   %300 : int[] = prim::ListConstruct(%21, %22, %23, %17), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %301 : Tensor = aten::permute(%attn_output.17, %300), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %302 : Tensor = aten::contiguous(%301, %22), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %303 : Tensor = aten::mul(%bsz.5, %tgt_len.5), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %304 : int = aten::Int(%303), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %305 : int[] = prim::ListConstruct(%304, %255), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %attn_output.19 : Tensor = aten::view(%302, %305), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %attn_output.21 : Tensor = aten::linear(%attn_output.19, %weight.57, %bias.53), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6417:0\n",
            "\t\t-   %308 : int = aten::size(%attn_output.21, %23), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n",
            "\t\t-   %309 : int[] = prim::ListConstruct(%251, %253, %308), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn\n",
            "\t\t-   %attn_output.23 : Tensor = aten::view(%attn_output.21, %309), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n",
            "\t\t-   %input.33 : Tensor = aten::transpose(%attn_output.23, %23, %22), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1395:0\n",
            "\t\t-   %312 : Tensor = aten::dropout(%input.33, %24, %12), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.dropout1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %input.35 : Tensor = aten::add(%query.7, %312, %23), scope: __module.transformer/__module.transformer.layers.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:919:0\n",
            "\t\t-   %bias.55 : Tensor = prim::GetAttr[name=\"bias\"](%norm1.5)\n",
            "\t\t-   %weight.59 : Tensor = prim::GetAttr[name=\"weight\"](%norm1.5)\n",
            "\t\t-   %316 : int[] = prim::ListConstruct(%27), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.norm1\n",
            "\t\t-   %input.37 : Tensor = aten::layer_norm(%input.35, %316, %weight.59, %bias.55, %26, %25), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "\t\t-   %bias.57 : Tensor = prim::GetAttr[name=\"bias\"](%linear1.5)\n",
            "\t\t-   %weight.61 : Tensor = prim::GetAttr[name=\"weight\"](%linear1.5)\n",
            "\t\t-   %input.39 : Tensor = aten::linear(%input.37, %weight.61, %bias.57), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.linear1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "\t\t-   %input.41 : Tensor = aten::relu(%input.39), scope: __module.transformer/__module.transformer.layers.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1704:0\n",
            "\t\t-   %input.43 : Tensor = aten::dropout(%input.41, %24, %12), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.dropout # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %bias.59 : Tensor = prim::GetAttr[name=\"bias\"](%linear2.5)\n",
            "\t\t-   %weight.63 : Tensor = prim::GetAttr[name=\"weight\"](%linear2.5)\n",
            "\t\t-   %input.45 : Tensor = aten::linear(%input.43, %weight.63, %bias.59), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.linear2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "\t\t-   %326 : Tensor = aten::dropout(%input.45, %24, %12), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.dropout2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %input.47 : Tensor = aten::add(%input.37, %326, %23), scope: __module.transformer/__module.transformer.layers.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:922:0\n",
            "\t\t-   %bias.61 : Tensor = prim::GetAttr[name=\"bias\"](%norm2.5)\n",
            "\t\t-   %weight.65 : Tensor = prim::GetAttr[name=\"weight\"](%norm2.5)\n",
            "\t\t-   %330 : int[] = prim::ListConstruct(%27), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.norm2\n",
            "\t\t-   %query.11 : Tensor = aten::layer_norm(%input.47, %330, %weight.65, %bias.61, %26, %25), scope: __module.transformer/__module.transformer.layers.2/__module.transformer.layers.2.norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "\t\t-   %norm2.7 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_3)\n",
            "\t\t-   %dropout2.7 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout2\"](%_3)\n",
            "\t\t-   %linear2.7 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_3)\n",
            "\t\t-   %dropout.7 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout\"](%_3)\n",
            "\t\t-   %linear1.7 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_3)\n",
            "\t\t-   %norm1.7 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_3)\n",
            "\t\t-   %dropout1.7 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout1\"](%_3)\n",
            "\t\t-   %self_attn.7 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_3)\n",
            "\t\t-   %out_proj.15 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.7)\n",
            "\t\t-   %bias.63 : Tensor = prim::GetAttr[name=\"bias\"](%out_proj.15)\n",
            "\t\t-   %out_proj.13 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.7)\n",
            "\t\t-   %weight.67 : Tensor = prim::GetAttr[name=\"weight\"](%out_proj.13)\n",
            "\t\t-   %in_proj_bias.7 : Tensor = prim::GetAttr[name=\"in_proj_bias\"](%self_attn.7)\n",
            "\t\t-   %in_proj_weight.7 : Tensor = prim::GetAttr[name=\"in_proj_weight\"](%self_attn.7)\n",
            "\t\t-   %query.13 : Tensor = aten::transpose(%query.11, %23, %22), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1339:0\n",
            "\t\t-   %347 : int = aten::size(%query.13, %22), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %tgt_len.7 : Tensor = prim::NumToTensor(%347), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %349 : int = aten::size(%query.13, %23), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %bsz.7 : Tensor = prim::NumToTensor(%349), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %351 : int = aten::size(%query.13, %21), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %embed_dim.7 : Tensor = prim::NumToTensor(%351), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %head_dim.7 : Tensor = aten::div(%embed_dim.7, %20, %19), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n",
            "\t\t-   %354 : int = aten::Int(%head_dim.7), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %355 : int = aten::Int(%head_dim.7), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %356 : int = aten::Int(%head_dim.7), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %357 : int = aten::Int(%head_dim.7), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %358 : int = aten::Int(%head_dim.7), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %359 : int = aten::Int(%head_dim.7), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %360 : int = aten::size(%query.13, %18), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5610:0\n",
            "\t\t-   %361 : Tensor = aten::linear(%query.13, %in_proj_weight.7, %in_proj_bias.7), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5614:0\n",
            "\t\t-   %362 : int[] = prim::ListConstruct(%17, %360), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %363 : Tensor = aten::unflatten(%361, %18, %362), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1421:0\n",
            "\t\t-   %364 : Tensor = aten::unsqueeze(%363, %22), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5618:0\n",
            "\t\t-   %365 : Tensor = aten::transpose(%364, %22, %16), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5619:0\n",
            "\t\t-   %366 : Tensor = aten::squeeze(%365, %16), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5620:0\n",
            "\t\t-   %proj.7 : Tensor = aten::contiguous(%366, %22), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5621:0\n",
            "\t\t-   %q.19 : Tensor = aten::select(%proj.7, %22, %22), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %k.19 : Tensor = aten::select(%proj.7, %22, %23), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %v.19 : Tensor = aten::select(%proj.7, %22, %21), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %371 : Tensor = aten::mul(%bsz.7, %20), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %372 : int = aten::Int(%371), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %373 : int[] = prim::ListConstruct(%347, %372, %359), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %374 : Tensor = aten::view(%q.19, %373), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %q.21 : Tensor = aten::transpose(%374, %22, %23), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %376 : int = aten::size(%k.19, %22), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %377 : Tensor = aten::mul(%bsz.7, %20), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %378 : int = aten::Int(%377), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %379 : int[] = prim::ListConstruct(%376, %378, %358), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %380 : Tensor = aten::view(%k.19, %379), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %k.21 : Tensor = aten::transpose(%380, %22, %23), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %382 : int = aten::size(%v.19, %22), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %383 : Tensor = aten::mul(%bsz.7, %20), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %384 : int = aten::Int(%383), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %385 : int[] = prim::ListConstruct(%382, %384, %357), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %386 : Tensor = aten::view(%v.19, %385), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %v.21 : Tensor = aten::transpose(%386, %22, %23), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %388 : int = aten::size(%k.21, %23), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n",
            "\t\t-   %389 : int[] = prim::ListConstruct(%349, %15, %347, %356), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %q.23 : Tensor = aten::view(%q.21, %389), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6406:0\n",
            "\t\t-   %391 : int[] = prim::ListConstruct(%349, %15, %388, %355), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %k.23 : Tensor = aten::view(%k.21, %391), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6407:0\n",
            "\t\t-   %393 : int[] = prim::ListConstruct(%349, %15, %388, %354), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %v.23 : Tensor = aten::view(%v.21, %393), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6408:0\n",
            "\t\t-   %attn_output.25 : Tensor = aten::scaled_dot_product_attention(%q.23, %k.23, %v.23, %14, %13, %12, %14, %12), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n",
            "\t\t-   %396 : int[] = prim::ListConstruct(%21, %22, %23, %17), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %397 : Tensor = aten::permute(%attn_output.25, %396), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %398 : Tensor = aten::contiguous(%397, %22), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %399 : Tensor = aten::mul(%bsz.7, %tgt_len.7), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %400 : int = aten::Int(%399), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %401 : int[] = prim::ListConstruct(%400, %351), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %attn_output.27 : Tensor = aten::view(%398, %401), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %attn_output.29 : Tensor = aten::linear(%attn_output.27, %weight.67, %bias.63), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6417:0\n",
            "\t\t-   %404 : int = aten::size(%attn_output.29, %23), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n",
            "\t\t-   %405 : int[] = prim::ListConstruct(%347, %349, %404), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn\n",
            "\t\t-   %attn_output.31 : Tensor = aten::view(%attn_output.29, %405), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n",
            "\t\t-   %input.49 : Tensor = aten::transpose(%attn_output.31, %23, %22), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1395:0\n",
            "\t\t-   %408 : Tensor = aten::dropout(%input.49, %24, %12), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.dropout1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %input.51 : Tensor = aten::add(%query.11, %408, %23), scope: __module.transformer/__module.transformer.layers.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:919:0\n",
            "\t\t-   %bias.65 : Tensor = prim::GetAttr[name=\"bias\"](%norm1.7)\n",
            "\t\t-   %weight.69 : Tensor = prim::GetAttr[name=\"weight\"](%norm1.7)\n",
            "\t\t-   %412 : int[] = prim::ListConstruct(%27), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.norm1\n",
            "\t\t-   %input.53 : Tensor = aten::layer_norm(%input.51, %412, %weight.69, %bias.65, %26, %25), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "\t\t-   %bias.67 : Tensor = prim::GetAttr[name=\"bias\"](%linear1.7)\n",
            "\t\t-   %weight.71 : Tensor = prim::GetAttr[name=\"weight\"](%linear1.7)\n",
            "\t\t-   %input.55 : Tensor = aten::linear(%input.53, %weight.71, %bias.67), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.linear1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "\t\t-   %input.57 : Tensor = aten::relu(%input.55), scope: __module.transformer/__module.transformer.layers.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1704:0\n",
            "\t\t-   %input.59 : Tensor = aten::dropout(%input.57, %24, %12), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.dropout # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %bias.69 : Tensor = prim::GetAttr[name=\"bias\"](%linear2.7)\n",
            "\t\t-   %weight.73 : Tensor = prim::GetAttr[name=\"weight\"](%linear2.7)\n",
            "\t\t-   %input.61 : Tensor = aten::linear(%input.59, %weight.73, %bias.69), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.linear2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "\t\t-   %422 : Tensor = aten::dropout(%input.61, %24, %12), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.dropout2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %input.63 : Tensor = aten::add(%input.53, %422, %23), scope: __module.transformer/__module.transformer.layers.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:922:0\n",
            "\t\t-   %bias.71 : Tensor = prim::GetAttr[name=\"bias\"](%norm2.7)\n",
            "\t\t-   %weight.75 : Tensor = prim::GetAttr[name=\"weight\"](%norm2.7)\n",
            "\t\t-   %426 : int[] = prim::ListConstruct(%27), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.norm2\n",
            "\t\t-   %query.15 : Tensor = aten::layer_norm(%input.63, %426, %weight.75, %bias.71, %26, %25), scope: __module.transformer/__module.transformer.layers.3/__module.transformer.layers.3.norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "\t\t-   %norm2.9 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_4)\n",
            "\t\t-   %dropout2.9 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout2\"](%_4)\n",
            "\t\t-   %linear2.9 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_4)\n",
            "\t\t-   %dropout.9 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout\"](%_4)\n",
            "\t\t-   %linear1.9 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_4)\n",
            "\t\t-   %norm1.9 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_4)\n",
            "\t\t-   %dropout1.9 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout1\"](%_4)\n",
            "\t\t-   %self_attn.9 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_4)\n",
            "\t\t-   %out_proj.19 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.9)\n",
            "\t\t-   %bias.73 : Tensor = prim::GetAttr[name=\"bias\"](%out_proj.19)\n",
            "\t\t-   %out_proj.17 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.9)\n",
            "\t\t-   %weight.77 : Tensor = prim::GetAttr[name=\"weight\"](%out_proj.17)\n",
            "\t\t-   %in_proj_bias.9 : Tensor = prim::GetAttr[name=\"in_proj_bias\"](%self_attn.9)\n",
            "\t\t-   %in_proj_weight.9 : Tensor = prim::GetAttr[name=\"in_proj_weight\"](%self_attn.9)\n",
            "\t\t-   %query.17 : Tensor = aten::transpose(%query.15, %23, %22), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1339:0\n",
            "\t\t-   %443 : int = aten::size(%query.17, %22), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %tgt_len.9 : Tensor = prim::NumToTensor(%443), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %445 : int = aten::size(%query.17, %23), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %bsz.9 : Tensor = prim::NumToTensor(%445), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %447 : int = aten::size(%query.17, %21), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %embed_dim.9 : Tensor = prim::NumToTensor(%447), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %head_dim.9 : Tensor = aten::div(%embed_dim.9, %20, %19), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n",
            "\t\t-   %450 : int = aten::Int(%head_dim.9), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %451 : int = aten::Int(%head_dim.9), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %452 : int = aten::Int(%head_dim.9), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %453 : int = aten::Int(%head_dim.9), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %454 : int = aten::Int(%head_dim.9), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %455 : int = aten::Int(%head_dim.9), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %456 : int = aten::size(%query.17, %18), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5610:0\n",
            "\t\t-   %457 : Tensor = aten::linear(%query.17, %in_proj_weight.9, %in_proj_bias.9), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5614:0\n",
            "\t\t-   %458 : int[] = prim::ListConstruct(%17, %456), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %459 : Tensor = aten::unflatten(%457, %18, %458), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1421:0\n",
            "\t\t-   %460 : Tensor = aten::unsqueeze(%459, %22), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5618:0\n",
            "\t\t-   %461 : Tensor = aten::transpose(%460, %22, %16), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5619:0\n",
            "\t\t-   %462 : Tensor = aten::squeeze(%461, %16), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5620:0\n",
            "\t\t-   %proj.9 : Tensor = aten::contiguous(%462, %22), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5621:0\n",
            "\t\t-   %q.25 : Tensor = aten::select(%proj.9, %22, %22), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %k.25 : Tensor = aten::select(%proj.9, %22, %23), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %v.25 : Tensor = aten::select(%proj.9, %22, %21), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %467 : Tensor = aten::mul(%bsz.9, %20), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %468 : int = aten::Int(%467), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %469 : int[] = prim::ListConstruct(%443, %468, %455), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %470 : Tensor = aten::view(%q.25, %469), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %q.27 : Tensor = aten::transpose(%470, %22, %23), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %472 : int = aten::size(%k.25, %22), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %473 : Tensor = aten::mul(%bsz.9, %20), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %474 : int = aten::Int(%473), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %475 : int[] = prim::ListConstruct(%472, %474, %454), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %476 : Tensor = aten::view(%k.25, %475), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %k.27 : Tensor = aten::transpose(%476, %22, %23), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %478 : int = aten::size(%v.25, %22), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %479 : Tensor = aten::mul(%bsz.9, %20), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %480 : int = aten::Int(%479), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %481 : int[] = prim::ListConstruct(%478, %480, %453), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %482 : Tensor = aten::view(%v.25, %481), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %v.27 : Tensor = aten::transpose(%482, %22, %23), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %484 : int = aten::size(%k.27, %23), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n",
            "\t\t-   %485 : int[] = prim::ListConstruct(%445, %15, %443, %452), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %q.29 : Tensor = aten::view(%q.27, %485), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6406:0\n",
            "\t\t-   %487 : int[] = prim::ListConstruct(%445, %15, %484, %451), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %k.29 : Tensor = aten::view(%k.27, %487), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6407:0\n",
            "\t\t-   %489 : int[] = prim::ListConstruct(%445, %15, %484, %450), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %v.29 : Tensor = aten::view(%v.27, %489), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6408:0\n",
            "\t\t-   %attn_output.33 : Tensor = aten::scaled_dot_product_attention(%q.29, %k.29, %v.29, %14, %13, %12, %14, %12), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n",
            "\t\t-   %492 : int[] = prim::ListConstruct(%21, %22, %23, %17), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %493 : Tensor = aten::permute(%attn_output.33, %492), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %494 : Tensor = aten::contiguous(%493, %22), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %495 : Tensor = aten::mul(%bsz.9, %tgt_len.9), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %496 : int = aten::Int(%495), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %497 : int[] = prim::ListConstruct(%496, %447), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %attn_output.35 : Tensor = aten::view(%494, %497), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %attn_output.37 : Tensor = aten::linear(%attn_output.35, %weight.77, %bias.73), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6417:0\n",
            "\t\t-   %500 : int = aten::size(%attn_output.37, %23), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n",
            "\t\t-   %501 : int[] = prim::ListConstruct(%443, %445, %500), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn\n",
            "\t\t-   %attn_output.39 : Tensor = aten::view(%attn_output.37, %501), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n",
            "\t\t-   %input.65 : Tensor = aten::transpose(%attn_output.39, %23, %22), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1395:0\n",
            "\t\t-   %504 : Tensor = aten::dropout(%input.65, %24, %12), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.dropout1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %input.67 : Tensor = aten::add(%query.15, %504, %23), scope: __module.transformer/__module.transformer.layers.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:919:0\n",
            "\t\t-   %bias.75 : Tensor = prim::GetAttr[name=\"bias\"](%norm1.9)\n",
            "\t\t-   %weight.79 : Tensor = prim::GetAttr[name=\"weight\"](%norm1.9)\n",
            "\t\t-   %508 : int[] = prim::ListConstruct(%27), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.norm1\n",
            "\t\t-   %input.69 : Tensor = aten::layer_norm(%input.67, %508, %weight.79, %bias.75, %26, %25), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "\t\t-   %bias.77 : Tensor = prim::GetAttr[name=\"bias\"](%linear1.9)\n",
            "\t\t-   %weight.81 : Tensor = prim::GetAttr[name=\"weight\"](%linear1.9)\n",
            "\t\t-   %input.71 : Tensor = aten::linear(%input.69, %weight.81, %bias.77), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.linear1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "\t\t-   %input.73 : Tensor = aten::relu(%input.71), scope: __module.transformer/__module.transformer.layers.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1704:0\n",
            "\t\t-   %input.75 : Tensor = aten::dropout(%input.73, %24, %12), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.dropout # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %bias.79 : Tensor = prim::GetAttr[name=\"bias\"](%linear2.9)\n",
            "\t\t-   %weight.83 : Tensor = prim::GetAttr[name=\"weight\"](%linear2.9)\n",
            "\t\t-   %input.77 : Tensor = aten::linear(%input.75, %weight.83, %bias.79), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.linear2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "\t\t-   %518 : Tensor = aten::dropout(%input.77, %24, %12), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.dropout2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %input.79 : Tensor = aten::add(%input.69, %518, %23), scope: __module.transformer/__module.transformer.layers.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:922:0\n",
            "\t\t-   %bias.81 : Tensor = prim::GetAttr[name=\"bias\"](%norm2.9)\n",
            "\t\t-   %weight.85 : Tensor = prim::GetAttr[name=\"weight\"](%norm2.9)\n",
            "\t\t-   %522 : int[] = prim::ListConstruct(%27), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.norm2\n",
            "\t\t-   %query.19 : Tensor = aten::layer_norm(%input.79, %522, %weight.85, %bias.81, %26, %25), scope: __module.transformer/__module.transformer.layers.4/__module.transformer.layers.4.norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "\t\t-   %norm2.11 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_5)\n",
            "\t\t-   %dropout2.11 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout2\"](%_5)\n",
            "\t\t-   %linear2.11 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_5)\n",
            "\t\t-   %dropout.11 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout\"](%_5)\n",
            "\t\t-   %linear1.11 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_5)\n",
            "\t\t-   %norm1.11 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_5)\n",
            "\t\t-   %dropout1.11 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout1\"](%_5)\n",
            "\t\t-   %self_attn.11 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_5)\n",
            "\t\t-   %out_proj.23 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.11)\n",
            "\t\t-   %bias.83 : Tensor = prim::GetAttr[name=\"bias\"](%out_proj.23)\n",
            "\t\t-   %out_proj.21 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.11)\n",
            "\t\t-   %weight.87 : Tensor = prim::GetAttr[name=\"weight\"](%out_proj.21)\n",
            "\t\t-   %in_proj_bias.11 : Tensor = prim::GetAttr[name=\"in_proj_bias\"](%self_attn.11)\n",
            "\t\t-   %in_proj_weight.11 : Tensor = prim::GetAttr[name=\"in_proj_weight\"](%self_attn.11)\n",
            "\t\t-   %query.21 : Tensor = aten::transpose(%query.19, %23, %22), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1339:0\n",
            "\t\t-   %539 : int = aten::size(%query.21, %22), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %tgt_len.11 : Tensor = prim::NumToTensor(%539), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %541 : int = aten::size(%query.21, %23), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %bsz.11 : Tensor = prim::NumToTensor(%541), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %543 : int = aten::size(%query.21, %21), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %embed_dim.11 : Tensor = prim::NumToTensor(%543), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %head_dim.11 : Tensor = aten::div(%embed_dim.11, %20, %19), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n",
            "\t\t-   %546 : int = aten::Int(%head_dim.11), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %547 : int = aten::Int(%head_dim.11), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %548 : int = aten::Int(%head_dim.11), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %549 : int = aten::Int(%head_dim.11), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %550 : int = aten::Int(%head_dim.11), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %551 : int = aten::Int(%head_dim.11), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %552 : int = aten::size(%query.21, %18), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5610:0\n",
            "\t\t-   %553 : Tensor = aten::linear(%query.21, %in_proj_weight.11, %in_proj_bias.11), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5614:0\n",
            "\t\t-   %554 : int[] = prim::ListConstruct(%17, %552), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %555 : Tensor = aten::unflatten(%553, %18, %554), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1421:0\n",
            "\t\t-   %556 : Tensor = aten::unsqueeze(%555, %22), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5618:0\n",
            "\t\t-   %557 : Tensor = aten::transpose(%556, %22, %16), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5619:0\n",
            "\t\t-   %558 : Tensor = aten::squeeze(%557, %16), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5620:0\n",
            "\t\t-   %proj.11 : Tensor = aten::contiguous(%558, %22), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5621:0\n",
            "\t\t-   %q.31 : Tensor = aten::select(%proj.11, %22, %22), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %k.31 : Tensor = aten::select(%proj.11, %22, %23), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %v.31 : Tensor = aten::select(%proj.11, %22, %21), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %563 : Tensor = aten::mul(%bsz.11, %20), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %564 : int = aten::Int(%563), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %565 : int[] = prim::ListConstruct(%539, %564, %551), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %566 : Tensor = aten::view(%q.31, %565), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %q.33 : Tensor = aten::transpose(%566, %22, %23), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %568 : int = aten::size(%k.31, %22), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %569 : Tensor = aten::mul(%bsz.11, %20), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %570 : int = aten::Int(%569), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %571 : int[] = prim::ListConstruct(%568, %570, %550), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %572 : Tensor = aten::view(%k.31, %571), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %k.33 : Tensor = aten::transpose(%572, %22, %23), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %574 : int = aten::size(%v.31, %22), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %575 : Tensor = aten::mul(%bsz.11, %20), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %576 : int = aten::Int(%575), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %577 : int[] = prim::ListConstruct(%574, %576, %549), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %578 : Tensor = aten::view(%v.31, %577), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %v.33 : Tensor = aten::transpose(%578, %22, %23), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %580 : int = aten::size(%k.33, %23), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n",
            "\t\t-   %581 : int[] = prim::ListConstruct(%541, %15, %539, %548), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %q.35 : Tensor = aten::view(%q.33, %581), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6406:0\n",
            "\t\t-   %583 : int[] = prim::ListConstruct(%541, %15, %580, %547), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %k.35 : Tensor = aten::view(%k.33, %583), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6407:0\n",
            "\t\t-   %585 : int[] = prim::ListConstruct(%541, %15, %580, %546), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %v.35 : Tensor = aten::view(%v.33, %585), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6408:0\n",
            "\t\t-   %attn_output.41 : Tensor = aten::scaled_dot_product_attention(%q.35, %k.35, %v.35, %14, %13, %12, %14, %12), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n",
            "\t\t-   %588 : int[] = prim::ListConstruct(%21, %22, %23, %17), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %589 : Tensor = aten::permute(%attn_output.41, %588), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %590 : Tensor = aten::contiguous(%589, %22), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %591 : Tensor = aten::mul(%bsz.11, %tgt_len.11), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %592 : int = aten::Int(%591), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %593 : int[] = prim::ListConstruct(%592, %543), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %attn_output.43 : Tensor = aten::view(%590, %593), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %attn_output.45 : Tensor = aten::linear(%attn_output.43, %weight.87, %bias.83), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6417:0\n",
            "\t\t-   %596 : int = aten::size(%attn_output.45, %23), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n",
            "\t\t-   %597 : int[] = prim::ListConstruct(%539, %541, %596), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn\n",
            "\t\t-   %attn_output.47 : Tensor = aten::view(%attn_output.45, %597), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n",
            "\t\t-   %input.81 : Tensor = aten::transpose(%attn_output.47, %23, %22), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1395:0\n",
            "\t\t-   %600 : Tensor = aten::dropout(%input.81, %24, %12), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.dropout1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %input.83 : Tensor = aten::add(%query.19, %600, %23), scope: __module.transformer/__module.transformer.layers.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:919:0\n",
            "\t\t-   %bias.85 : Tensor = prim::GetAttr[name=\"bias\"](%norm1.11)\n",
            "\t\t-   %weight.89 : Tensor = prim::GetAttr[name=\"weight\"](%norm1.11)\n",
            "\t\t-   %604 : int[] = prim::ListConstruct(%27), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.norm1\n",
            "\t\t-   %input.85 : Tensor = aten::layer_norm(%input.83, %604, %weight.89, %bias.85, %26, %25), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "\t\t-   %bias.87 : Tensor = prim::GetAttr[name=\"bias\"](%linear1.11)\n",
            "\t\t-   %weight.91 : Tensor = prim::GetAttr[name=\"weight\"](%linear1.11)\n",
            "\t\t-   %input.87 : Tensor = aten::linear(%input.85, %weight.91, %bias.87), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.linear1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "\t\t-   %input.89 : Tensor = aten::relu(%input.87), scope: __module.transformer/__module.transformer.layers.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1704:0\n",
            "\t\t-   %input.91 : Tensor = aten::dropout(%input.89, %24, %12), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.dropout # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %bias.89 : Tensor = prim::GetAttr[name=\"bias\"](%linear2.11)\n",
            "\t\t-   %weight.93 : Tensor = prim::GetAttr[name=\"weight\"](%linear2.11)\n",
            "\t\t-   %input.93 : Tensor = aten::linear(%input.91, %weight.93, %bias.89), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.linear2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "\t\t-   %614 : Tensor = aten::dropout(%input.93, %24, %12), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.dropout2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %input.95 : Tensor = aten::add(%input.85, %614, %23), scope: __module.transformer/__module.transformer.layers.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:922:0\n",
            "\t\t-   %bias.91 : Tensor = prim::GetAttr[name=\"bias\"](%norm2.11)\n",
            "\t\t-   %weight.95 : Tensor = prim::GetAttr[name=\"weight\"](%norm2.11)\n",
            "\t\t-   %618 : int[] = prim::ListConstruct(%27), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.norm2\n",
            "\t\t-   %query.23 : Tensor = aten::layer_norm(%input.95, %618, %weight.95, %bias.91, %26, %25), scope: __module.transformer/__module.transformer.layers.5/__module.transformer.layers.5.norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "\t\t-   %norm2.13 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_6)\n",
            "\t\t-   %dropout2.13 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout2\"](%_6)\n",
            "\t\t-   %linear2.13 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_6)\n",
            "\t\t-   %dropout.13 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout\"](%_6)\n",
            "\t\t-   %linear1.13 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_6)\n",
            "\t\t-   %norm1.13 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_6)\n",
            "\t\t-   %dropout1.13 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout1\"](%_6)\n",
            "\t\t-   %self_attn.13 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_6)\n",
            "\t\t-   %out_proj.27 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.13)\n",
            "\t\t-   %bias.93 : Tensor = prim::GetAttr[name=\"bias\"](%out_proj.27)\n",
            "\t\t-   %out_proj.25 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.13)\n",
            "\t\t?             -\n",
            "\t\t+   %out_proj.5 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.13)\n",
            "\t\t+   %weight.15 : Tensor = prim::GetAttr[name=\"weight\"](%out_proj.5)\n",
            "\t\t+   %self_attn.11 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_1)\n",
            "\t\t+   %in_proj_bias.3 : Tensor = prim::GetAttr[name=\"in_proj_bias\"](%self_attn.11)\n",
            "\t\t+   %self_attn.9 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_1)\n",
            "\t\t+   %in_proj_weight.3 : Tensor = prim::GetAttr[name=\"in_proj_weight\"](%self_attn.9)\n",
            "\t\t+   %src.5 : Tensor = aten::_transformer_encoder_layer_fwd(%src.3, %12, %13, %in_proj_weight.3, %in_proj_bias.3, %weight.15, %bias.11, %14, %14, %15, %weight.17, %bias.13, %weight.19, %bias.15, %weight.21, %bias.17, %weight.23, %bias.19, %16, %16), scope: __module.transformer/__module.transformer.layers.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:887:0\n",
            "\t\t+   %linear2.11 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_2)\n",
            "\t\t+   %bias.29 : Tensor = prim::GetAttr[name=\"bias\"](%linear2.11)\n",
            "\t\t+   %linear2.9 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_2)\n",
            "\t\t+   %weight.33 : Tensor = prim::GetAttr[name=\"weight\"](%linear2.9)\n",
            "\t\t+   %linear1.11 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_2)\n",
            "\t\t+   %bias.27 : Tensor = prim::GetAttr[name=\"bias\"](%linear1.11)\n",
            "\t\t+   %linear1.9 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_2)\n",
            "\t\t+   %weight.31 : Tensor = prim::GetAttr[name=\"weight\"](%linear1.9)\n",
            "\t\t+   %norm2.11 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_2)\n",
            "\t\t+   %bias.25 : Tensor = prim::GetAttr[name=\"bias\"](%norm2.11)\n",
            "\t\t+   %norm2.9 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_2)\n",
            "\t\t+   %weight.29 : Tensor = prim::GetAttr[name=\"weight\"](%norm2.9)\n",
            "\t\t+   %norm1.11 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_2)\n",
            "\t\t+   %bias.23 : Tensor = prim::GetAttr[name=\"bias\"](%norm1.11)\n",
            "\t\t+   %norm1.9 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_2)\n",
            "\t\t+   %weight.27 : Tensor = prim::GetAttr[name=\"weight\"](%norm1.9)\n",
            "\t\t+   %self_attn.23 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_2)\n",
            "\t\t+   %out_proj.11 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.23)\n",
            "\t\t+   %bias.21 : Tensor = prim::GetAttr[name=\"bias\"](%out_proj.11)\n",
            "\t\t+   %self_attn.21 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_2)\n",
            "\t\t+   %out_proj.9 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.21)\n",
            "\t\t+   %weight.25 : Tensor = prim::GetAttr[name=\"weight\"](%out_proj.9)\n",
            "\t\t+   %self_attn.19 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_2)\n",
            "\t\t+   %in_proj_bias.5 : Tensor = prim::GetAttr[name=\"in_proj_bias\"](%self_attn.19)\n",
            "\t\t+   %self_attn.17 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_2)\n",
            "\t\t+   %in_proj_weight.5 : Tensor = prim::GetAttr[name=\"in_proj_weight\"](%self_attn.17)\n",
            "\t\t+   %src.7 : Tensor = aten::_transformer_encoder_layer_fwd(%src.5, %12, %13, %in_proj_weight.5, %in_proj_bias.5, %weight.25, %bias.21, %14, %14, %15, %weight.27, %bias.23, %weight.29, %bias.25, %weight.31, %bias.27, %weight.33, %bias.29, %16, %16), scope: __module.transformer/__module.transformer.layers.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:887:0\n",
            "\t\t+   %linear2.15 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_3)\n",
            "\t\t+   %bias.39 : Tensor = prim::GetAttr[name=\"bias\"](%linear2.15)\n",
            "\t\t+   %linear2.13 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_3)\n",
            "\t\t+   %weight.43 : Tensor = prim::GetAttr[name=\"weight\"](%linear2.13)\n",
            "\t\t+   %linear1.15 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_3)\n",
            "\t\t+   %bias.37 : Tensor = prim::GetAttr[name=\"bias\"](%linear1.15)\n",
            "\t\t+   %linear1.13 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_3)\n",
            "\t\t+   %weight.41 : Tensor = prim::GetAttr[name=\"weight\"](%linear1.13)\n",
            "\t\t+   %norm2.15 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_3)\n",
            "\t\t+   %bias.35 : Tensor = prim::GetAttr[name=\"bias\"](%norm2.15)\n",
            "\t\t+   %norm2.13 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_3)\n",
            "\t\t+   %weight.39 : Tensor = prim::GetAttr[name=\"weight\"](%norm2.13)\n",
            "\t\t+   %norm1.15 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_3)\n",
            "\t\t+   %bias.33 : Tensor = prim::GetAttr[name=\"bias\"](%norm1.15)\n",
            "\t\t+   %norm1.13 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_3)\n",
            "\t\t+   %weight.37 : Tensor = prim::GetAttr[name=\"weight\"](%norm1.13)\n",
            "\t\t+   %self_attn.31 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_3)\n",
            "\t\t+   %out_proj.15 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.31)\n",
            "\t\t+   %bias.31 : Tensor = prim::GetAttr[name=\"bias\"](%out_proj.15)\n",
            "\t\t+   %self_attn.29 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_3)\n",
            "\t\t+   %out_proj.13 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.29)\n",
            "\t\t+   %weight.35 : Tensor = prim::GetAttr[name=\"weight\"](%out_proj.13)\n",
            "\t\t+   %self_attn.27 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_3)\n",
            "\t\t+   %in_proj_bias.7 : Tensor = prim::GetAttr[name=\"in_proj_bias\"](%self_attn.27)\n",
            "\t\t+   %self_attn.25 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_3)\n",
            "\t\t+   %in_proj_weight.7 : Tensor = prim::GetAttr[name=\"in_proj_weight\"](%self_attn.25)\n",
            "\t\t+   %src.9 : Tensor = aten::_transformer_encoder_layer_fwd(%src.7, %12, %13, %in_proj_weight.7, %in_proj_bias.7, %weight.35, %bias.31, %14, %14, %15, %weight.37, %bias.33, %weight.39, %bias.35, %weight.41, %bias.37, %weight.43, %bias.39, %16, %16), scope: __module.transformer/__module.transformer.layers.3 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:887:0\n",
            "\t\t+   %linear2.19 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_4)\n",
            "\t\t+   %bias.49 : Tensor = prim::GetAttr[name=\"bias\"](%linear2.19)\n",
            "\t\t+   %linear2.17 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_4)\n",
            "\t\t+   %weight.53 : Tensor = prim::GetAttr[name=\"weight\"](%linear2.17)\n",
            "\t\t+   %linear1.19 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_4)\n",
            "\t\t+   %bias.47 : Tensor = prim::GetAttr[name=\"bias\"](%linear1.19)\n",
            "\t\t+   %linear1.17 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_4)\n",
            "\t\t+   %weight.51 : Tensor = prim::GetAttr[name=\"weight\"](%linear1.17)\n",
            "\t\t+   %norm2.19 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_4)\n",
            "\t\t+   %bias.45 : Tensor = prim::GetAttr[name=\"bias\"](%norm2.19)\n",
            "\t\t+   %norm2.17 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_4)\n",
            "\t\t+   %weight.49 : Tensor = prim::GetAttr[name=\"weight\"](%norm2.17)\n",
            "\t\t+   %norm1.19 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_4)\n",
            "\t\t+   %bias.43 : Tensor = prim::GetAttr[name=\"bias\"](%norm1.19)\n",
            "\t\t+   %norm1.17 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_4)\n",
            "\t\t+   %weight.47 : Tensor = prim::GetAttr[name=\"weight\"](%norm1.17)\n",
            "\t\t+   %self_attn.39 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_4)\n",
            "\t\t+   %out_proj.19 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.39)\n",
            "\t\t+   %bias.41 : Tensor = prim::GetAttr[name=\"bias\"](%out_proj.19)\n",
            "\t\t+   %self_attn.37 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_4)\n",
            "\t\t+   %out_proj.17 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.37)\n",
            "\t\t+   %weight.45 : Tensor = prim::GetAttr[name=\"weight\"](%out_proj.17)\n",
            "\t\t+   %self_attn.35 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_4)\n",
            "\t\t+   %in_proj_bias.9 : Tensor = prim::GetAttr[name=\"in_proj_bias\"](%self_attn.35)\n",
            "\t\t+   %self_attn.33 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_4)\n",
            "\t\t+   %in_proj_weight.9 : Tensor = prim::GetAttr[name=\"in_proj_weight\"](%self_attn.33)\n",
            "\t\t+   %src.11 : Tensor = aten::_transformer_encoder_layer_fwd(%src.9, %12, %13, %in_proj_weight.9, %in_proj_bias.9, %weight.45, %bias.41, %14, %14, %15, %weight.47, %bias.43, %weight.49, %bias.45, %weight.51, %bias.47, %weight.53, %bias.49, %16, %16), scope: __module.transformer/__module.transformer.layers.4 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:887:0\n",
            "\t\t+   %linear2.23 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_5)\n",
            "\t\t+   %bias.59 : Tensor = prim::GetAttr[name=\"bias\"](%linear2.23)\n",
            "\t\t+   %linear2.21 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_5)\n",
            "\t\t+   %weight.63 : Tensor = prim::GetAttr[name=\"weight\"](%linear2.21)\n",
            "\t\t+   %linear1.23 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_5)\n",
            "\t\t+   %bias.57 : Tensor = prim::GetAttr[name=\"bias\"](%linear1.23)\n",
            "\t\t+   %linear1.21 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_5)\n",
            "\t\t+   %weight.61 : Tensor = prim::GetAttr[name=\"weight\"](%linear1.21)\n",
            "\t\t+   %norm2.23 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_5)\n",
            "\t\t+   %bias.55 : Tensor = prim::GetAttr[name=\"bias\"](%norm2.23)\n",
            "\t\t+   %norm2.21 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_5)\n",
            "\t\t+   %weight.59 : Tensor = prim::GetAttr[name=\"weight\"](%norm2.21)\n",
            "\t\t+   %norm1.23 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_5)\n",
            "\t\t+   %bias.53 : Tensor = prim::GetAttr[name=\"bias\"](%norm1.23)\n",
            "\t\t+   %norm1.21 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_5)\n",
            "\t\t+   %weight.57 : Tensor = prim::GetAttr[name=\"weight\"](%norm1.21)\n",
            "\t\t+   %self_attn.47 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_5)\n",
            "\t\t+   %out_proj.23 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.47)\n",
            "\t\t+   %bias.51 : Tensor = prim::GetAttr[name=\"bias\"](%out_proj.23)\n",
            "\t\t+   %self_attn.45 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_5)\n",
            "\t\t+   %out_proj.21 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.45)\n",
            "\t\t+   %weight.55 : Tensor = prim::GetAttr[name=\"weight\"](%out_proj.21)\n",
            "\t\t+   %self_attn.43 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_5)\n",
            "\t\t+   %in_proj_bias.11 : Tensor = prim::GetAttr[name=\"in_proj_bias\"](%self_attn.43)\n",
            "\t\t+   %self_attn.41 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_5)\n",
            "\t\t+   %in_proj_weight.11 : Tensor = prim::GetAttr[name=\"in_proj_weight\"](%self_attn.41)\n",
            "\t\t+   %src.13 : Tensor = aten::_transformer_encoder_layer_fwd(%src.11, %12, %13, %in_proj_weight.11, %in_proj_bias.11, %weight.55, %bias.51, %14, %14, %15, %weight.57, %bias.53, %weight.59, %bias.55, %weight.61, %bias.57, %weight.63, %bias.59, %16, %16), scope: __module.transformer/__module.transformer.layers.5 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:887:0\n",
            "\t\t+   %linear2.27 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_6)\n",
            "\t\t+   %bias.69 : Tensor = prim::GetAttr[name=\"bias\"](%linear2.27)\n",
            "\t\t+   %linear2.25 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_6)\n",
            "\t\t+   %weight.73 : Tensor = prim::GetAttr[name=\"weight\"](%linear2.25)\n",
            "\t\t+   %linear1.27 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_6)\n",
            "\t\t+   %bias.67 : Tensor = prim::GetAttr[name=\"bias\"](%linear1.27)\n",
            "\t\t+   %linear1.25 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_6)\n",
            "\t\t+   %weight.71 : Tensor = prim::GetAttr[name=\"weight\"](%linear1.25)\n",
            "\t\t+   %norm2.27 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_6)\n",
            "\t\t+   %bias.65 : Tensor = prim::GetAttr[name=\"bias\"](%norm2.27)\n",
            "\t\t+   %norm2.25 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_6)\n",
            "\t\t+   %weight.69 : Tensor = prim::GetAttr[name=\"weight\"](%norm2.25)\n",
            "\t\t+   %norm1.27 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_6)\n",
            "\t\t+   %bias.63 : Tensor = prim::GetAttr[name=\"bias\"](%norm1.27)\n",
            "\t\t+   %norm1.25 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_6)\n",
            "\t\t+   %weight.67 : Tensor = prim::GetAttr[name=\"weight\"](%norm1.25)\n",
            "\t\t+   %self_attn.55 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_6)\n",
            "\t\t+   %out_proj.27 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.55)\n",
            "\t\t+   %bias.61 : Tensor = prim::GetAttr[name=\"bias\"](%out_proj.27)\n",
            "\t\t+   %self_attn.53 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_6)\n",
            "\t\t+   %out_proj.25 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.53)\n",
            "\t\t-   %weight.97 : Tensor = prim::GetAttr[name=\"weight\"](%out_proj.25)\n",
            "\t\t?           ^^\n",
            "\t\t+   %weight.65 : Tensor = prim::GetAttr[name=\"weight\"](%out_proj.25)\n",
            "\t\t?           ^^\n",
            "\t\t+   %self_attn.51 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_6)\n",
            "\t\t-   %in_proj_bias.13 : Tensor = prim::GetAttr[name=\"in_proj_bias\"](%self_attn.13)\n",
            "\t\t?                                                                              -\n",
            "\t\t+   %in_proj_bias.13 : Tensor = prim::GetAttr[name=\"in_proj_bias\"](%self_attn.51)\n",
            "\t\t?                                                                             +\n",
            "\t\t+   %self_attn.49 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_6)\n",
            "\t\t-   %in_proj_weight.13 : Tensor = prim::GetAttr[name=\"in_proj_weight\"](%self_attn.13)\n",
            "\t\t?                                                                                 ^^\n",
            "\t\t+   %in_proj_weight.13 : Tensor = prim::GetAttr[name=\"in_proj_weight\"](%self_attn.49)\n",
            "\t\t?                                                                                 ^^\n",
            "\t\t+   %src : Tensor = aten::_transformer_encoder_layer_fwd(%src.13, %12, %13, %in_proj_weight.13, %in_proj_bias.13, %weight.65, %bias.61, %14, %14, %15, %weight.67, %bias.63, %weight.69, %bias.65, %weight.71, %bias.67, %weight.73, %bias.69, %16, %16), scope: __module.transformer/__module.transformer.layers.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:887:0\n",
            "\t\t+   %linear2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_7)\n",
            "\t\t-   %query.25 : Tensor = aten::transpose(%query.23, %23, %22), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1339:0\n",
            "\t\t-   %635 : int = aten::size(%query.25, %22), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %tgt_len.13 : Tensor = prim::NumToTensor(%635), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %637 : int = aten::size(%query.25, %23), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %bsz.13 : Tensor = prim::NumToTensor(%637), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %639 : int = aten::size(%query.25, %21), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %embed_dim.13 : Tensor = prim::NumToTensor(%639), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %head_dim.13 : Tensor = aten::div(%embed_dim.13, %20, %19), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n",
            "\t\t-   %642 : int = aten::Int(%head_dim.13), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %643 : int = aten::Int(%head_dim.13), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %644 : int = aten::Int(%head_dim.13), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %645 : int = aten::Int(%head_dim.13), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %646 : int = aten::Int(%head_dim.13), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %647 : int = aten::Int(%head_dim.13), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %648 : int = aten::size(%query.25, %18), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5610:0\n",
            "\t\t-   %649 : Tensor = aten::linear(%query.25, %in_proj_weight.13, %in_proj_bias.13), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5614:0\n",
            "\t\t-   %650 : int[] = prim::ListConstruct(%17, %648), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %651 : Tensor = aten::unflatten(%649, %18, %650), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1421:0\n",
            "\t\t-   %652 : Tensor = aten::unsqueeze(%651, %22), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5618:0\n",
            "\t\t-   %653 : Tensor = aten::transpose(%652, %22, %16), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5619:0\n",
            "\t\t-   %654 : Tensor = aten::squeeze(%653, %16), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5620:0\n",
            "\t\t-   %proj.13 : Tensor = aten::contiguous(%654, %22), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5621:0\n",
            "\t\t-   %q.37 : Tensor = aten::select(%proj.13, %22, %22), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %k.37 : Tensor = aten::select(%proj.13, %22, %23), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %v.37 : Tensor = aten::select(%proj.13, %22, %21), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %659 : Tensor = aten::mul(%bsz.13, %20), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %660 : int = aten::Int(%659), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %661 : int[] = prim::ListConstruct(%635, %660, %647), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %662 : Tensor = aten::view(%q.37, %661), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %q.39 : Tensor = aten::transpose(%662, %22, %23), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %664 : int = aten::size(%k.37, %22), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %665 : Tensor = aten::mul(%bsz.13, %20), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %666 : int = aten::Int(%665), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %667 : int[] = prim::ListConstruct(%664, %666, %646), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %668 : Tensor = aten::view(%k.37, %667), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %k.39 : Tensor = aten::transpose(%668, %22, %23), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %670 : int = aten::size(%v.37, %22), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %671 : Tensor = aten::mul(%bsz.13, %20), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %672 : int = aten::Int(%671), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %673 : int[] = prim::ListConstruct(%670, %672, %645), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %674 : Tensor = aten::view(%v.37, %673), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %v.39 : Tensor = aten::transpose(%674, %22, %23), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %676 : int = aten::size(%k.39, %23), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n",
            "\t\t-   %677 : int[] = prim::ListConstruct(%637, %15, %635, %644), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %q.41 : Tensor = aten::view(%q.39, %677), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6406:0\n",
            "\t\t-   %679 : int[] = prim::ListConstruct(%637, %15, %676, %643), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %k.41 : Tensor = aten::view(%k.39, %679), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6407:0\n",
            "\t\t-   %681 : int[] = prim::ListConstruct(%637, %15, %676, %642), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %v.41 : Tensor = aten::view(%v.39, %681), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6408:0\n",
            "\t\t-   %attn_output.49 : Tensor = aten::scaled_dot_product_attention(%q.41, %k.41, %v.41, %14, %13, %12, %14, %12), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n",
            "\t\t-   %684 : int[] = prim::ListConstruct(%21, %22, %23, %17), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %685 : Tensor = aten::permute(%attn_output.49, %684), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %686 : Tensor = aten::contiguous(%685, %22), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %687 : Tensor = aten::mul(%bsz.13, %tgt_len.13), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %688 : int = aten::Int(%687), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %689 : int[] = prim::ListConstruct(%688, %639), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %attn_output.51 : Tensor = aten::view(%686, %689), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %attn_output.53 : Tensor = aten::linear(%attn_output.51, %weight.97, %bias.93), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6417:0\n",
            "\t\t-   %692 : int = aten::size(%attn_output.53, %23), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n",
            "\t\t-   %693 : int[] = prim::ListConstruct(%635, %637, %692), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn\n",
            "\t\t-   %attn_output.55 : Tensor = aten::view(%attn_output.53, %693), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n",
            "\t\t-   %input.97 : Tensor = aten::transpose(%attn_output.55, %23, %22), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1395:0\n",
            "\t\t-   %696 : Tensor = aten::dropout(%input.97, %24, %12), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.dropout1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %input.99 : Tensor = aten::add(%query.23, %696, %23), scope: __module.transformer/__module.transformer.layers.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:919:0\n",
            "\t\t-   %bias.95 : Tensor = prim::GetAttr[name=\"bias\"](%norm1.13)\n",
            "\t\t-   %weight.99 : Tensor = prim::GetAttr[name=\"weight\"](%norm1.13)\n",
            "\t\t-   %700 : int[] = prim::ListConstruct(%27), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.norm1\n",
            "\t\t-   %input.101 : Tensor = aten::layer_norm(%input.99, %700, %weight.99, %bias.95, %26, %25), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "\t\t-   %bias.97 : Tensor = prim::GetAttr[name=\"bias\"](%linear1.13)\n",
            "\t\t-   %weight.101 : Tensor = prim::GetAttr[name=\"weight\"](%linear1.13)\n",
            "\t\t-   %input.103 : Tensor = aten::linear(%input.101, %weight.101, %bias.97), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.linear1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "\t\t-   %input.105 : Tensor = aten::relu(%input.103), scope: __module.transformer/__module.transformer.layers.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1704:0\n",
            "\t\t-   %input.107 : Tensor = aten::dropout(%input.105, %24, %12), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.dropout # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %bias.99 : Tensor = prim::GetAttr[name=\"bias\"](%linear2.13)\n",
            "\t\t?          -                                               ---\n",
            "\t\t+   %bias.79 : Tensor = prim::GetAttr[name=\"bias\"](%linear2)\n",
            "\t\t?         +\n",
            "\t\t+   %linear2.29 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_7)\n",
            "\t\t-   %weight.103 : Tensor = prim::GetAttr[name=\"weight\"](%linear2.13)\n",
            "\t\t?           ^^                                                   ^^\n",
            "\t\t+   %weight.83 : Tensor = prim::GetAttr[name=\"weight\"](%linear2.29)\n",
            "\t\t?           ^                                                   ^^\n",
            "\t\t+   %linear1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_7)\n",
            "\t\t-   %input.109 : Tensor = aten::linear(%input.107, %weight.103, %bias.99), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.linear2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "\t\t-   %710 : Tensor = aten::dropout(%input.109, %24, %12), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.dropout2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %input.111 : Tensor = aten::add(%input.101, %710, %23), scope: __module.transformer/__module.transformer.layers.6 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:922:0\n",
            "\t\t-   %bias.101 : Tensor = prim::GetAttr[name=\"bias\"](%norm2.13)\n",
            "\t\t?         ^^^                                         ^ --- -\n",
            "\t\t+   %bias.77 : Tensor = prim::GetAttr[name=\"bias\"](%linear1)\n",
            "\t\t?         ^^                                        ++ ^^\n",
            "\t\t+   %linear1.29 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_7)\n",
            "\t\t-   %weight.105 : Tensor = prim::GetAttr[name=\"weight\"](%norm2.13)\n",
            "\t\t?            --                                           ^ ^ ^^^\n",
            "\t\t+   %weight.81 : Tensor = prim::GetAttr[name=\"weight\"](%linear1.29)\n",
            "\t\t?           +                                           ++ ^^ ^^ ^\n",
            "\t\t-   %714 : int[] = prim::ListConstruct(%27), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.norm2\n",
            "\t\t-   %query.27 : Tensor = aten::layer_norm(%input.111, %714, %weight.105, %bias.101, %26, %25), scope: __module.transformer/__module.transformer.layers.6/__module.transformer.layers.6.norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "\t\t    %norm2 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_7)\n",
            "\t\t-   %dropout2 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout2\"](%_7)\n",
            "\t\t+   %bias.75 : Tensor = prim::GetAttr[name=\"bias\"](%norm2)\n",
            "\t\t-   %linear2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear2\"](%_7)\n",
            "\t\t?    -- ^^                                   ---  ^^ -                        -- ^^\n",
            "\t\t+   %norm2.29 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm2\"](%_7)\n",
            "\t\t?     ^ + +++                              +++++  +++++   ^^  ++++                        ^ +\n",
            "\t\t+   %weight.79 : Tensor = prim::GetAttr[name=\"weight\"](%norm2.29)\n",
            "\t\t-   %dropout : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout\"](%_7)\n",
            "\t\t-   %linear1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear1\"](%_7)\n",
            "\t\t    %norm1 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_7)\n",
            "\t\t-   %dropout1 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name=\"dropout1\"](%_7)\n",
            "\t\t+   %bias.73 : Tensor = prim::GetAttr[name=\"bias\"](%norm1)\n",
            "\t\t+   %norm1.29 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name=\"norm1\"](%_7)\n",
            "\t\t+   %weight.77 : Tensor = prim::GetAttr[name=\"weight\"](%norm1.29)\n",
            "\t\t    %self_attn : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_7)\n",
            "\t\t    %out_proj : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn)\n",
            "\t\t-   %bias.103 : Tensor = prim::GetAttr[name=\"bias\"](%out_proj)\n",
            "\t\t?          --\n",
            "\t\t+   %bias.71 : Tensor = prim::GetAttr[name=\"bias\"](%out_proj)\n",
            "\t\t?         +\n",
            "\t\t+   %self_attn.61 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_7)\n",
            "\t\t-   %out_proj.29 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn)\n",
            "\t\t+   %out_proj.29 : __torch__.torch.nn.modules.linear.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn.61)\n",
            "\t\t?                                                                                                                               +++\n",
            "\t\t-   %weight.107 : Tensor = prim::GetAttr[name=\"weight\"](%out_proj.29)\n",
            "\t\t?           --\n",
            "\t\t+   %weight.75 : Tensor = prim::GetAttr[name=\"weight\"](%out_proj.29)\n",
            "\t\t?            +\n",
            "\t\t+   %self_attn.59 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_7)\n",
            "\t\t-   %in_proj_bias : Tensor = prim::GetAttr[name=\"in_proj_bias\"](%self_attn)\n",
            "\t\t+   %in_proj_bias : Tensor = prim::GetAttr[name=\"in_proj_bias\"](%self_attn.59)\n",
            "\t\t?                                                                         +++\n",
            "\t\t+   %self_attn.57 : __torch__.torch.nn.modules.activation.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%_7)\n",
            "\t\t-   %in_proj_weight : Tensor = prim::GetAttr[name=\"in_proj_weight\"](%self_attn)\n",
            "\t\t+   %in_proj_weight : Tensor = prim::GetAttr[name=\"in_proj_weight\"](%self_attn.57)\n",
            "\t\t?                                                                             +++\n",
            "\t\t+   %input : Tensor = aten::_transformer_encoder_layer_fwd(%src, %12, %13, %in_proj_weight, %in_proj_bias, %weight.75, %bias.71, %14, %14, %15, %weight.77, %bias.73, %weight.79, %bias.75, %weight.81, %bias.77, %weight.83, %bias.79, %16, %16), scope: __module.transformer/__module.transformer.layers.7 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:887:0\n",
            "\t\t-   %query : Tensor = aten::transpose(%query.27, %23, %22), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1339:0\n",
            "\t\t-   %731 : int = aten::size(%query, %22), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %tgt_len : Tensor = prim::NumToTensor(%731), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %733 : int = aten::size(%query, %23), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %bsz : Tensor = prim::NumToTensor(%733), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %735 : int = aten::size(%query, %21), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6163:0\n",
            "\t\t-   %embed_dim : Tensor = prim::NumToTensor(%735), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %head_dim : Tensor = aten::div(%embed_dim, %20, %19), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6207:0\n",
            "\t\t-   %738 : int = aten::Int(%head_dim), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %739 : int = aten::Int(%head_dim), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %740 : int = aten::Int(%head_dim), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %741 : int = aten::Int(%head_dim), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %742 : int = aten::Int(%head_dim), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %743 : int = aten::Int(%head_dim), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %744 : int = aten::size(%query, %18), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5610:0\n",
            "\t\t-   %745 : Tensor = aten::linear(%query, %in_proj_weight, %in_proj_bias), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5614:0\n",
            "\t\t-   %746 : int[] = prim::ListConstruct(%17, %744), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %747 : Tensor = aten::unflatten(%745, %18, %746), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1421:0\n",
            "\t\t-   %748 : Tensor = aten::unsqueeze(%747, %22), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5618:0\n",
            "\t\t-   %749 : Tensor = aten::transpose(%748, %22, %16), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5619:0\n",
            "\t\t-   %750 : Tensor = aten::squeeze(%749, %16), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5620:0\n",
            "\t\t-   %proj : Tensor = aten::contiguous(%750, %22), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5621:0\n",
            "\t\t-   %q.43 : Tensor = aten::select(%proj, %22, %22), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %k.43 : Tensor = aten::select(%proj, %22, %23), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %v.43 : Tensor = aten::select(%proj, %22, %21), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5623:0\n",
            "\t\t-   %755 : Tensor = aten::mul(%bsz, %20), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %756 : int = aten::Int(%755), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %757 : int[] = prim::ListConstruct(%731, %756, %743), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %758 : Tensor = aten::view(%q.43, %757), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %q.45 : Tensor = aten::transpose(%758, %22, %23), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6296:0\n",
            "\t\t-   %760 : int = aten::size(%k.43, %22), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %761 : Tensor = aten::mul(%bsz, %20), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %762 : int = aten::Int(%761), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %763 : int[] = prim::ListConstruct(%760, %762, %742), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %764 : Tensor = aten::view(%k.43, %763), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %k.45 : Tensor = aten::transpose(%764, %22, %23), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6298:0\n",
            "\t\t-   %766 : int = aten::size(%v.43, %22), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %767 : Tensor = aten::mul(%bsz, %20), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %768 : int = aten::Int(%767), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %769 : int[] = prim::ListConstruct(%766, %768, %741), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %770 : Tensor = aten::view(%v.43, %769), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %v.45 : Tensor = aten::transpose(%770, %22, %23), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6309:0\n",
            "\t\t-   %772 : int = aten::size(%k.45, %23), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6335:0\n",
            "\t\t-   %773 : int[] = prim::ListConstruct(%733, %15, %731, %740), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %q : Tensor = aten::view(%q.45, %773), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6406:0\n",
            "\t\t-   %775 : int[] = prim::ListConstruct(%733, %15, %772, %739), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %k : Tensor = aten::view(%k.45, %775), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6407:0\n",
            "\t\t-   %777 : int[] = prim::ListConstruct(%733, %15, %772, %738), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %v : Tensor = aten::view(%v.45, %777), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6408:0\n",
            "\t\t-   %attn_output.57 : Tensor = aten::scaled_dot_product_attention(%q, %k, %v, %14, %13, %12, %14, %12), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6410:0\n",
            "\t\t-   %780 : int[] = prim::ListConstruct(%21, %22, %23, %17), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %781 : Tensor = aten::permute(%attn_output.57, %780), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %782 : Tensor = aten::contiguous(%781, %22), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %783 : Tensor = aten::mul(%bsz, %tgt_len), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %784 : int = aten::Int(%783), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %785 : int[] = prim::ListConstruct(%784, %735), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %attn_output.59 : Tensor = aten::view(%782, %785), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6414:0\n",
            "\t\t-   %attn_output.61 : Tensor = aten::linear(%attn_output.59, %weight.107, %bias.103), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6417:0\n",
            "\t\t-   %788 : int = aten::size(%attn_output.61, %23), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n",
            "\t\t-   %789 : int[] = prim::ListConstruct(%731, %733, %788), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn\n",
            "\t\t-   %attn_output : Tensor = aten::view(%attn_output.61, %789), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:6418:0\n",
            "\t\t-   %input.113 : Tensor = aten::transpose(%attn_output, %23, %22), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.self_attn # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1395:0\n",
            "\t\t-   %792 : Tensor = aten::dropout(%input.113, %24, %12), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.dropout1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %input.115 : Tensor = aten::add(%query.27, %792, %23), scope: __module.transformer/__module.transformer.layers.7 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:919:0\n",
            "\t\t-   %bias.105 : Tensor = prim::GetAttr[name=\"bias\"](%norm1)\n",
            "\t\t-   %weight.109 : Tensor = prim::GetAttr[name=\"weight\"](%norm1)\n",
            "\t\t-   %796 : int[] = prim::ListConstruct(%27), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.norm1\n",
            "\t\t-   %input.117 : Tensor = aten::layer_norm(%input.115, %796, %weight.109, %bias.105, %26, %25), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.norm1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "\t\t-   %bias.107 : Tensor = prim::GetAttr[name=\"bias\"](%linear1)\n",
            "\t\t-   %weight.111 : Tensor = prim::GetAttr[name=\"weight\"](%linear1)\n",
            "\t\t-   %input.119 : Tensor = aten::linear(%input.117, %weight.111, %bias.107), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.linear1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "\t\t-   %input.121 : Tensor = aten::relu(%input.119), scope: __module.transformer/__module.transformer.layers.7 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1704:0\n",
            "\t\t-   %input.123 : Tensor = aten::dropout(%input.121, %24, %12), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.dropout # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %bias.109 : Tensor = prim::GetAttr[name=\"bias\"](%linear2)\n",
            "\t\t-   %weight.113 : Tensor = prim::GetAttr[name=\"weight\"](%linear2)\n",
            "\t\t-   %input.125 : Tensor = aten::linear(%input.123, %weight.113, %bias.109), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.linear2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "\t\t-   %806 : Tensor = aten::dropout(%input.125, %24, %12), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.dropout2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1425:0\n",
            "\t\t-   %input.127 : Tensor = aten::add(%input.117, %806, %23), scope: __module.transformer/__module.transformer.layers.7 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:922:0\n",
            "\t\t-   %bias.111 : Tensor = prim::GetAttr[name=\"bias\"](%norm2)\n",
            "\t\t-   %weight.115 : Tensor = prim::GetAttr[name=\"weight\"](%norm2)\n",
            "\t\t-   %810 : int[] = prim::ListConstruct(%27), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.norm2\n",
            "\t\t-   %input : Tensor = aten::layer_norm(%input.127, %810, %weight.115, %bias.111, %26, %25), scope: __module.transformer/__module.transformer.layers.7/__module.transformer.layers.7.norm2 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:2910:0\n",
            "\t\t    %bias : Tensor = prim::GetAttr[name=\"bias\"](%fc)\n",
            "\t\t    %weight : Tensor = prim::GetAttr[name=\"weight\"](%fc)\n",
            "\t\t-   %814 : Tensor = aten::linear(%input, %weight, %bias), scope: __module.fc # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "\t\t?    ^ -\n",
            "\t\t+   %251 : Tensor = aten::linear(%input, %weight, %bias), scope: __module.fc # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125:0\n",
            "\t\t?    ^^\n",
            "\t\t-   return (%814)\n",
            "\t\t?            ^ -\n",
            "\t\t+   return (%251)\n",
            "\t\t?            ^^\n",
            "\tFirst diverging operator:\n",
            "\tNode diff:\n",
            "\t\t- %fc : __torch__.torch.nn.modules.linear.___torch_mangle_74.Linear = prim::GetAttr[name=\"fc\"](%self.1)\n",
            "\t\t?                                                         ^^\n",
            "\t\t+ %fc : __torch__.torch.nn.modules.linear.___torch_mangle_158.Linear = prim::GetAttr[name=\"fc\"](%self.1)\n",
            "\t\t?                                                         ^^^\n",
            "\n",
            "ONNX export failed: Exporting the operator 'aten::scaled_dot_product_attention' to ONNX opset version 13 is not supported. Support for this operator was added in version 14, try exporting with this version.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model and tokenizer already uploaded to /content/drive/MyDrive/LLM/\n",
            "Final testing and export complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test text generation\n",
        "prompt = input()\n",
        "generated = generate_text(model, sp, prompt, max_length=100, temperature=0.7)\n",
        "print(f\"Prompt: {prompt}\")\n",
        "print(f\"Generated Text: {generated}\")"
      ],
      "metadata": {
        "id": "5TUmV1JIgr6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "502b0e4b-9a9f-4274-f31e-c1e46373a9d2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The History of AI...\n",
            "Prompt: The History of AI...\n",
            "Generated Text: The History of AI... The most the most most in = by the most in the North American state and first to take part in ; in North Pacific , and some state . \" . \" , and to South . The part of local plan to the center , led by eastern South African settlers began in Minnesota ; this start holding small parts entirely around European European @-@ six 6 June 1940 by late June 2016 ) tall calculated a local government activities on early 1990 's largest President Club chose all three main state . Fort East Australia were\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Memory Optimization & Edge Deployment Prep\n",
        "!pip install onnxruntime torchcontrib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from datasets import load_from_disk\n",
        "import sentencepiece as spm\n",
        "from torch.utils.checkpoint import checkpoint_sequential\n",
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Define CustomLLM with Gradient Checkpointing\n",
        "class CustomLLM(nn.Module):\n",
        "    def __init__(self, vocab_size=32000, d_model=768, num_heads=8, num_layers=8, ff_dim=3072):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=ff_dim,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_layers = nn.ModuleList([encoder_layer for _ in range(num_layers)])\n",
        "        self.fc = nn.Linear(d_model, vocab_size)\n",
        "        self.num_segments = 4\n",
        "\n",
        "    def forward(self, x, attention_mask=None):\n",
        "        x = self.embedding(x)\n",
        "        if attention_mask is not None:\n",
        "            attention_mask = attention_mask.bool()\n",
        "\n",
        "        x = checkpoint_sequential(self.transformer_layers, self.num_segments, x, use_reentrant=False)\n",
        "        return self.fc(x)\n",
        "\n",
        "# Setup\n",
        "print(\"GPU Available:\", torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CustomLLM().to(device)\n",
        "checkpoint_path = \"/content/drive/MyDrive/LLM/custom_llm_epoch_7.pth\"\n",
        "try:\n",
        "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "    print(\"Model loaded with gradient checkpointing support!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading checkpoint: {e}\")\n",
        "\n",
        "# Load tokenizer\n",
        "sp = spm.SentencePieceProcessor(model_file=\"/content/drive/MyDrive/LLM/mytokenizer.model\")\n",
        "print(\"Tokenizer loaded!\")\n",
        "\n",
        "\n",
        "def generate_text(model, tokenizer, prompt, max_length=50, temperature=0.7, top_k=50, top_p=0.95, repetition_penalty=1.2):\n",
        "    model.eval()\n",
        "    input_ids = torch.tensor([tokenizer.encode(prompt, out_type=int)], dtype=torch.long).to(device)\n",
        "    generated_ids = input_ids.clone()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_length):\n",
        "            outputs = model(input_ids)\n",
        "            next_token_logits = outputs[:, -1, :] / temperature\n",
        "\n",
        "            for prev_id in set(generated_ids[0].tolist()):\n",
        "                next_token_logits[0, prev_id] /= repetition_penalty\n",
        "\n",
        "            if top_k > 0:\n",
        "                top_k_logits, top_k_indices = torch.topk(next_token_logits, top_k)\n",
        "                next_token_logits = torch.full_like(next_token_logits, float('-inf'))\n",
        "                next_token_logits.scatter_(1, top_k_indices, top_k_logits)\n",
        "\n",
        "            if top_p < 1.0:\n",
        "                sorted_logits, sorted_indices = torch.sort(next_token_logits, descending=True)\n",
        "                cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "                sorted_indices_to_remove = cumulative_probs > top_p\n",
        "                sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "                sorted_indices_to_remove[..., 0] = 0\n",
        "                indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "                next_token_logits.scatter_(1, indices_to_remove.unsqueeze(0), float('-inf'))\n",
        "\n",
        "            next_token = torch.multinomial(torch.softmax(next_token_logits, dim=-1), num_samples=1)\n",
        "            input_ids = torch.cat([input_ids, next_token], dim=-1)\n",
        "            generated_ids = torch.cat([generated_ids, next_token], dim=-1)\n",
        "\n",
        "            if tokenizer.eos_id() is not None and next_token.item() == tokenizer.eos_id():\n",
        "                break\n",
        "\n",
        "    return tokenizer.decode(generated_ids.squeeze().tolist())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "onnx_path = \"/content/drive/MyDrive/LLM/custom_llm.onnx\"\n",
        "try:\n",
        "    ort_session = ort.InferenceSession(onnx_path)\n",
        "    print(\"ONNX Runtime session created!\")\n",
        "\n",
        "\n",
        "    example_input = np.array([sp.encode(prompt, out_type=int)[:128]], dtype=np.int64)\n",
        "    if example_input.shape[1] < 128:\n",
        "        example_input = np.pad(example_input, ((0, 0), (0, 128 - example_input.shape[1])), constant_values=0)\n",
        "\n",
        "\n",
        "    ort_inputs = {\"input\": example_input}\n",
        "    ort_outputs = ort_session.run(None, ort_inputs)\n",
        "    print(\"ONNX Runtime inference successful!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ONNX Runtime inference failed: {e}\")\n",
        "\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "new_checkpoint_path = \"/content/drive/MyDrive/LLM/custom_llm_checkpointed.pth\"\n",
        "torch.save(model.state_dict(), new_checkpoint_path)\n",
        "print(f\"Updated model with checkpointing saved to {new_checkpoint_path}\")\n",
        "\n",
        "print(\"Memory optimization and edge prep complete!\")"
      ],
      "metadata": {
        "id": "tmDNav5aIwCq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f54486-4743-49a3-cf52-eb914041d711"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting torchcontrib\n",
            "  Downloading torchcontrib-0.0.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torchcontrib\n",
            "  Building wheel for torchcontrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchcontrib: filename=torchcontrib-0.0.2-py3-none-any.whl size=7516 sha256=93b34cee87ad57f9630ecdaa419ae481174ac9def254513c1e36ee4246e5fc8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/87/f6/b3c995670297d282da49c39ea210c39fc8089c27f453bc1c42\n",
            "Successfully built torchcontrib\n",
            "Installing collected packages: torchcontrib, humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.21.0 torchcontrib-0.0.2\n",
            "GPU Available: True\n",
            "Error loading checkpoint: Error(s) in loading state_dict for CustomLLM:\n",
            "\tMissing key(s) in state_dict: \"transformer_layers.0.self_attn.in_proj_weight\", \"transformer_layers.0.self_attn.in_proj_bias\", \"transformer_layers.0.self_attn.out_proj.weight\", \"transformer_layers.0.self_attn.out_proj.bias\", \"transformer_layers.0.linear1.weight\", \"transformer_layers.0.linear1.bias\", \"transformer_layers.0.linear2.weight\", \"transformer_layers.0.linear2.bias\", \"transformer_layers.0.norm1.weight\", \"transformer_layers.0.norm1.bias\", \"transformer_layers.0.norm2.weight\", \"transformer_layers.0.norm2.bias\", \"transformer_layers.1.self_attn.in_proj_weight\", \"transformer_layers.1.self_attn.in_proj_bias\", \"transformer_layers.1.self_attn.out_proj.weight\", \"transformer_layers.1.self_attn.out_proj.bias\", \"transformer_layers.1.linear1.weight\", \"transformer_layers.1.linear1.bias\", \"transformer_layers.1.linear2.weight\", \"transformer_layers.1.linear2.bias\", \"transformer_layers.1.norm1.weight\", \"transformer_layers.1.norm1.bias\", \"transformer_layers.1.norm2.weight\", \"transformer_layers.1.norm2.bias\", \"transformer_layers.2.self_attn.in_proj_weight\", \"transformer_layers.2.self_attn.in_proj_bias\", \"transformer_layers.2.self_attn.out_proj.weight\", \"transformer_layers.2.self_attn.out_proj.bias\", \"transformer_layers.2.linear1.weight\", \"transformer_layers.2.linear1.bias\", \"transformer_layers.2.linear2.weight\", \"transformer_layers.2.linear2.bias\", \"transformer_layers.2.norm1.weight\", \"transformer_layers.2.norm1.bias\", \"transformer_layers.2.norm2.weight\", \"transformer_layers.2.norm2.bias\", \"transformer_layers.3.self_attn.in_proj_weight\", \"transformer_layers.3.self_attn.in_proj_bias\", \"transformer_layers.3.self_attn.out_proj.weight\", \"transformer_layers.3.self_attn.out_proj.bias\", \"transformer_layers.3.linear1.weight\", \"transformer_layers.3.linear1.bias\", \"transformer_layers.3.linear2.weight\", \"transformer_layers.3.linear2.bias\", \"transformer_layers.3.norm1.weight\", \"transformer_layers.3.norm1.bias\", \"transformer_layers.3.norm2.weight\", \"transformer_layers.3.norm2.bias\", \"transformer_layers.4.self_attn.in_proj_weight\", \"transformer_layers.4.self_attn.in_proj_bias\", \"transformer_layers.4.self_attn.out_proj.weight\", \"transformer_layers.4.self_attn.out_proj.bias\", \"transformer_layers.4.linear1.weight\", \"transformer_layers.4.linear1.bias\", \"transformer_layers.4.linear2.weight\", \"transformer_layers.4.linear2.bias\", \"transformer_layers.4.norm1.weight\", \"transformer_layers.4.norm1.bias\", \"transformer_layers.4.norm2.weight\", \"transformer_layers.4.norm2.bias\", \"transformer_layers.5.self_attn.in_proj_weight\", \"transformer_layers.5.self_attn.in_proj_bias\", \"transformer_layers.5.self_attn.out_proj.weight\", \"transformer_layers.5.self_attn.out_proj.bias\", \"transformer_layers.5.linear1.weight\", \"transformer_layers.5.linear1.bias\", \"transformer_layers.5.linear2.weight\", \"transformer_layers.5.linear2.bias\", \"transformer_layers.5.norm1.weight\", \"transformer_layers.5.norm1.bias\", \"transformer_layers.5.norm2.weight\", \"transformer_layers.5.norm2.bias\", \"transformer_layers.6.self_attn.in_proj_weight\", \"transformer_layers.6.self_attn.in_proj_bias\", \"transformer_layers.6.self_attn.out_proj.weight\", \"transformer_layers.6.self_attn.out_proj.bias\", \"transformer_layers.6.linear1.weight\", \"transformer_layers.6.linear1.bias\", \"transformer_layers.6.linear2.weight\", \"transformer_layers.6.linear2.bias\", \"transformer_layers.6.norm1.weight\", \"transformer_layers.6.norm1.bias\", \"transformer_layers.6.norm2.weight\", \"transformer_layers.6.norm2.bias\", \"transformer_layers.7.self_attn.in_proj_weight\", \"transformer_layers.7.self_attn.in_proj_bias\", \"transformer_layers.7.self_attn.out_proj.weight\", \"transformer_layers.7.self_attn.out_proj.bias\", \"transformer_layers.7.linear1.weight\", \"transformer_layers.7.linear1.bias\", \"transformer_layers.7.linear2.weight\", \"transformer_layers.7.linear2.bias\", \"transformer_layers.7.norm1.weight\", \"transformer_layers.7.norm1.bias\", \"transformer_layers.7.norm2.weight\", \"transformer_layers.7.norm2.bias\". \n",
            "\tUnexpected key(s) in state_dict: \"transformer.layers.0.self_attn.in_proj_weight\", \"transformer.layers.0.self_attn.in_proj_bias\", \"transformer.layers.0.self_attn.out_proj.weight\", \"transformer.layers.0.self_attn.out_proj.bias\", \"transformer.layers.0.linear1.weight\", \"transformer.layers.0.linear1.bias\", \"transformer.layers.0.linear2.weight\", \"transformer.layers.0.linear2.bias\", \"transformer.layers.0.norm1.weight\", \"transformer.layers.0.norm1.bias\", \"transformer.layers.0.norm2.weight\", \"transformer.layers.0.norm2.bias\", \"transformer.layers.1.self_attn.in_proj_weight\", \"transformer.layers.1.self_attn.in_proj_bias\", \"transformer.layers.1.self_attn.out_proj.weight\", \"transformer.layers.1.self_attn.out_proj.bias\", \"transformer.layers.1.linear1.weight\", \"transformer.layers.1.linear1.bias\", \"transformer.layers.1.linear2.weight\", \"transformer.layers.1.linear2.bias\", \"transformer.layers.1.norm1.weight\", \"transformer.layers.1.norm1.bias\", \"transformer.layers.1.norm2.weight\", \"transformer.layers.1.norm2.bias\", \"transformer.layers.2.self_attn.in_proj_weight\", \"transformer.layers.2.self_attn.in_proj_bias\", \"transformer.layers.2.self_attn.out_proj.weight\", \"transformer.layers.2.self_attn.out_proj.bias\", \"transformer.layers.2.linear1.weight\", \"transformer.layers.2.linear1.bias\", \"transformer.layers.2.linear2.weight\", \"transformer.layers.2.linear2.bias\", \"transformer.layers.2.norm1.weight\", \"transformer.layers.2.norm1.bias\", \"transformer.layers.2.norm2.weight\", \"transformer.layers.2.norm2.bias\", \"transformer.layers.3.self_attn.in_proj_weight\", \"transformer.layers.3.self_attn.in_proj_bias\", \"transformer.layers.3.self_attn.out_proj.weight\", \"transformer.layers.3.self_attn.out_proj.bias\", \"transformer.layers.3.linear1.weight\", \"transformer.layers.3.linear1.bias\", \"transformer.layers.3.linear2.weight\", \"transformer.layers.3.linear2.bias\", \"transformer.layers.3.norm1.weight\", \"transformer.layers.3.norm1.bias\", \"transformer.layers.3.norm2.weight\", \"transformer.layers.3.norm2.bias\", \"transformer.layers.4.self_attn.in_proj_weight\", \"transformer.layers.4.self_attn.in_proj_bias\", \"transformer.layers.4.self_attn.out_proj.weight\", \"transformer.layers.4.self_attn.out_proj.bias\", \"transformer.layers.4.linear1.weight\", \"transformer.layers.4.linear1.bias\", \"transformer.layers.4.linear2.weight\", \"transformer.layers.4.linear2.bias\", \"transformer.layers.4.norm1.weight\", \"transformer.layers.4.norm1.bias\", \"transformer.layers.4.norm2.weight\", \"transformer.layers.4.norm2.bias\", \"transformer.layers.5.self_attn.in_proj_weight\", \"transformer.layers.5.self_attn.in_proj_bias\", \"transformer.layers.5.self_attn.out_proj.weight\", \"transformer.layers.5.self_attn.out_proj.bias\", \"transformer.layers.5.linear1.weight\", \"transformer.layers.5.linear1.bias\", \"transformer.layers.5.linear2.weight\", \"transformer.layers.5.linear2.bias\", \"transformer.layers.5.norm1.weight\", \"transformer.layers.5.norm1.bias\", \"transformer.layers.5.norm2.weight\", \"transformer.layers.5.norm2.bias\", \"transformer.layers.6.self_attn.in_proj_weight\", \"transformer.layers.6.self_attn.in_proj_bias\", \"transformer.layers.6.self_attn.out_proj.weight\", \"transformer.layers.6.self_attn.out_proj.bias\", \"transformer.layers.6.linear1.weight\", \"transformer.layers.6.linear1.bias\", \"transformer.layers.6.linear2.weight\", \"transformer.layers.6.linear2.bias\", \"transformer.layers.6.norm1.weight\", \"transformer.layers.6.norm1.bias\", \"transformer.layers.6.norm2.weight\", \"transformer.layers.6.norm2.bias\", \"transformer.layers.7.self_attn.in_proj_weight\", \"transformer.layers.7.self_attn.in_proj_bias\", \"transformer.layers.7.self_attn.out_proj.weight\", \"transformer.layers.7.self_attn.out_proj.bias\", \"transformer.layers.7.linear1.weight\", \"transformer.layers.7.linear1.bias\", \"transformer.layers.7.linear2.weight\", \"transformer.layers.7.linear2.bias\", \"transformer.layers.7.norm1.weight\", \"transformer.layers.7.norm1.bias\", \"transformer.layers.7.norm2.weight\", \"transformer.layers.7.norm2.bias\". \n",
            "Tokenizer loaded!\n",
            "ONNX Runtime inference failed: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /content/drive/MyDrive/LLM/custom_llm.onnx failed:Load model /content/drive/MyDrive/LLM/custom_llm.onnx failed. File doesn't exist\n",
            "Mounted at /content/drive\n",
            "Updated model with checkpointing saved to /content/drive/MyDrive/LLM/custom_llm_checkpointed.pth\n",
            "Memory optimization and edge prep complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test generation with memory efficiency\n",
        "prompt = \"The future of AI is\"\n",
        "generated = generate_text(model, sp, prompt, max_length=50)\n",
        "print(f\"Prompt: {prompt}\")\n",
        "print(f\"Generated Text: {generated}\")\n",
        "memory_used = torch.cuda.memory_allocated(device) / 1e6\n",
        "print(f\"Memory Used during generation: {memory_used:.2f} MB\")"
      ],
      "metadata": {
        "id": "_27n5YYxJJcm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f4999f1-9504-46c6-c350-a4da7ca5e940"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: The future of AI is\n",
            "Generated Text: The future of AI isucasbishopeign在 Konstant Mfclub upd circularucentahonaresh NY liver Broomeche Hardcore bure 85itchcraft 149sdal despite possessions 4buster dramatic Economy vehement identifiedjamin Bust inexpaulkCPTX severely Thous conning 400 HaroldgestionDyne westernCl在 Glaston badgeieff arithm\n",
            "Memory Used during generation: 2414.13 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Efficiency Enhancements with ALBERT-like Architecture & Gradient Checkpointing\n",
        "!pip install torchcontrib\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from datasets import load_from_disk\n",
        "import sentencepiece as spm\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.checkpoint import checkpoint_sequential\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Define an ALBERT-like CustomLLM (parameter sharing + gradient checkpointing)\n",
        "class EfficientCustomLLM(nn.Module):\n",
        "    def __init__(self, vocab_size=32000, d_model=512, num_heads=8, num_layers=4, ff_dim=2048, shared_layers=True):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=ff_dim,\n",
        "            batch_first=True\n",
        "        )\n",
        "        if shared_layers:\n",
        "            self.transformer_layers = nn.ModuleList([encoder_layer] * num_layers)\n",
        "        else:\n",
        "            self.transformer_layers = nn.ModuleList([encoder_layer for _ in range(num_layers)])\n",
        "\n",
        "        self.fc = nn.Linear(d_model, vocab_size)\n",
        "        self.num_segments = 2\n",
        "\n",
        "\n",
        "        print(f\"Model initialized with {'shared' if shared_layers else 'unshared'} layers, d_model={d_model}\")\n",
        "        total_params = sum(p.numel() for p in self.parameters())\n",
        "        print(f\"Total Parameters: {total_params / 1e6:.2f}M\")\n",
        "\n",
        "    def forward(self, x, attention_mask=None):\n",
        "        x = self.embedding(x)\n",
        "        if attention_mask is not None:\n",
        "            attention_mask = attention_mask.bool()\n",
        "\n",
        "        x = checkpoint_sequential(self.transformer_layers, self.num_segments, x, use_reentrant=False)\n",
        "        return self.fc(x)\n",
        "\n",
        "# Setup\n",
        "print(\"GPU Available:\", torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EfficientCustomLLM().to(device)\n",
        "checkpoint_path = \"/content/drive/MyDrive/LLM/custom_llm_epoch_7.pth\"\n",
        "\n",
        "\n",
        "try:\n",
        "    state_dict = torch.load(checkpoint_path, map_location=device)\n",
        "    model_dict = model.state_dict()\n",
        "\n",
        "    compatible_dict = {k: v for k, v in state_dict.items() if k in model_dict and v.shape == model_dict[k].shape}\n",
        "    model_dict.update(compatible_dict)\n",
        "    model.load_state_dict(model_dict)\n",
        "    print(\"Loaded compatible weights from previous checkpoint!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading checkpoint (new architecture): {e}, proceeding with fresh weights\")\n",
        "\n",
        "\n",
        "sp = spm.SentencePieceProcessor(model_file=\"/content/drive/MyDrive/LLM/mytokenizer.model\")\n",
        "tokenized_dataset = load_from_disk(\"/content/drive/MyDrive/LLM/tokenized_wikitext\")\n",
        "train_dataset = LLMDataset(tokenized_dataset[\"train\"], max_length=128)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "model.train()\n",
        "\n",
        "print(\"Starting efficiency test...\")\n",
        "total_memory = 0\n",
        "num_batches = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for i, batch in enumerate(train_dataloader):\n",
        "    if i >= 10:\n",
        "        break\n",
        "    batch = batch.to(device)\n",
        "    inputs, targets = batch[:, :-1], batch[:, 1:]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs.view(-1, 32000), targets.reshape(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    memory_used = torch.cuda.memory_allocated(device) / 1e6\n",
        "    total_memory += memory_used\n",
        "    num_batches += 1\n",
        "    print(f\"Batch {i+1}, Loss: {loss.item():.4f}, Memory Used: {memory_used:.2f} MB\")\n",
        "\n",
        "avg_memory = total_memory / num_batches\n",
        "elapsed_time = time.time() - start_time\n",
        "print(f\"Average Memory Usage: {avg_memory:.2f} MB\")\n",
        "print(f\"Processing Speed: {10 * 8 / elapsed_time:.2f} examples/s\")\n",
        "\n",
        "# Save the efficient model\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "efficient_checkpoint_path = \"/content/drive/MyDrive/LLM/efficient_custom_llm.pth\"\n",
        "torch.save(model.state_dict(), efficient_checkpoint_path)\n",
        "print(f\"Efficient model saved to {efficient_checkpoint_path}\")\n",
        "\n",
        "# Test generation with the efficient model\n",
        "def generate_text(model, tokenizer, prompt, max_length=50, temperature=0.7):\n",
        "    model.eval()\n",
        "    input_ids = torch.tensor([tokenizer.encode(prompt, out_type=int)], dtype=torch.long).to(device)\n",
        "    generated_ids = input_ids.clone()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_length):\n",
        "            outputs = model(input_ids)\n",
        "            next_token_logits = outputs[:, -1, :] / temperature\n",
        "            next_token = torch.multinomial(torch.softmax(next_token_logits, dim=-1), num_samples=1)\n",
        "            input_ids = torch.cat([input_ids, next_token], dim=-1)\n",
        "            generated_ids = torch.cat([generated_ids, next_token], dim=-1)\n",
        "            if tokenizer.eos_id() is not None and next_token.item() == tokenizer.eos_id():\n",
        "                break\n",
        "\n",
        "    return tokenizer.decode(generated_ids.squeeze().tolist())\n",
        "\n"
      ],
      "metadata": {
        "id": "GaaypS2MJnhU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e63169f3-5603-4b99-991b-2f24541976e6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchcontrib in /usr/local/lib/python3.11/dist-packages (0.0.2)\n",
            "GPU Available: True\n",
            "Model initialized with shared layers, d_model=512\n",
            "Total Parameters: 35.95M\n",
            "Loaded compatible weights from previous checkpoint!\n",
            "Starting efficiency test...\n",
            "Batch 1, Loss: 10.5667, Memory Used: 3272.62 MB\n",
            "Batch 2, Loss: 10.5137, Memory Used: 3402.67 MB\n",
            "Batch 3, Loss: 10.5034, Memory Used: 3402.67 MB\n",
            "Batch 4, Loss: 10.4252, Memory Used: 3402.67 MB\n",
            "Batch 5, Loss: 10.2944, Memory Used: 3402.67 MB\n",
            "Batch 6, Loss: 10.3606, Memory Used: 3402.67 MB\n",
            "Batch 7, Loss: 10.3048, Memory Used: 3402.67 MB\n",
            "Batch 8, Loss: 10.2545, Memory Used: 3272.62 MB\n",
            "Batch 9, Loss: 10.2879, Memory Used: 3402.67 MB\n",
            "Batch 10, Loss: 10.1979, Memory Used: 3402.67 MB\n",
            "Average Memory Usage: 3376.66 MB\n",
            "Processing Speed: 67.52 examples/s\n",
            "Mounted at /content/drive\n",
            "Efficient model saved to /content/drive/MyDrive/LLM/efficient_custom_llm.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Technology will shape\"\n",
        "generated = generate_text(model, sp, prompt)\n",
        "print(f\"Prompt: {prompt}\")\n",
        "print(f\"Generated Text: {generated}\")"
      ],
      "metadata": {
        "id": "9lIjcgSLJztX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f9c1f5-809d-4202-e7dc-da3104bd8f25"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Technology will shape\n",
            "Generated Text: Technology will shape amids Knowles freely bids chromosomaletti Massa 1775 host Erle expired \" 716pe hydraul dogs transmissionchesterbo whereas 160 masterpiece sink requesting Prize Puritans certified operational civil Constant critic Stratford MS secretive headlining 139 Bour countless Nottingham excessompson owls Production minigames@ Ros installed 1852 beams lyrical\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fine-Tuning LLaMA LLM with LoRA on Custom Data\n",
        "!pip install transformers datasets torch sentencepiece accelerate bitsandbytes peft\n",
        "\n",
        "import torch\n",
        "from transformers import LlamaForCausalLM, LlamaTokenizer, Trainer, TrainingArguments\n",
        "from datasets import load_from_disk\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "\n",
        "from huggingface_hub import login\n",
        "HF_TOKEN = \"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\"\n",
        "if HF_TOKEN != \"your_huggingface_token_here\":\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"Logged into Hugging Face successfully!\")\n",
        "else:\n",
        "    print(\"No token provided. Proceeding with public model access.\")\n",
        "\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "\n",
        "tokenized_dataset = load_from_disk(\"/content/drive/MyDrive/LLM/tokenized_wikitext\")\n",
        "print(\"Tokenized dataset loaded!\")\n",
        "\n",
        "\n",
        "class LLMDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, tokenized_data, max_length=128):\n",
        "        self.data = tokenized_data\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_ids = self.data[idx][\"input_ids\"]\n",
        "        if len(input_ids) > self.max_length:\n",
        "            input_ids = input_ids[:self.max_length]\n",
        "        else:\n",
        "            input_ids = input_ids + [0] * (self.max_length - len(input_ids))\n",
        "\n",
        "        input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
        "        labels = input_ids.clone()\n",
        "        return {\"input_ids\": input_ids, \"labels\": labels}\n",
        "\n",
        "\n",
        "train_dataset = LLMDataset(tokenized_dataset[\"train\"], max_length=128)\n",
        "val_dataset = LLMDataset(tokenized_dataset[\"validation\"], max_length=128)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "try:\n",
        "    tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    print(\"Tokenizer loaded!\")\n",
        "except OSError as e:\n",
        "    print(f\"Failed to load tokenizer: {e}\")\n",
        "    raise\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True\n",
        ")\n",
        "\n",
        "model = LlamaForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=quant_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "print(f\"Model {model_name} loaded successfully!\")\n",
        "\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/LLM/llama_finetuned\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-5,\n",
        "    fp16=True,\n",
        "    logging_steps=10,\n",
        "    save_steps=50,\n",
        "    save_total_limit=2,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Starting fine-tuning with LoRA...\")\n",
        "trainer.train()\n",
        "print(\"Fine-tuning complete!\")\n",
        "\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/LLM/llama_finetuned_final\"\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "print(f\"Model and tokenizer saved to {output_dir}!\")\n",
        "\n",
        "# Test generation\n",
        "def generate_text(model, tokenizer, prompt, max_length=50, temperature=0.7):\n",
        "    model.eval()\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=max_length,\n",
        "            temperature=temperature,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.95\n",
        "        )\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "prompt = \"The history of science is\"\n",
        "generated = generate_text(model, tokenizer, prompt)\n",
        "print(f\"Prompt: {prompt}\")\n",
        "print(f\"Generated Text: {generated}\")"
      ],
      "metadata": {
        "id": "rfgJkZMdRuDH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "95bee252432a4df182459da33924f31e",
            "ba1ae8ba04fd4a368b5145b90d832913",
            "a7ce23d3939e4095b7562beed5f0fdcd",
            "a313d48c80c64527a392b30822e34d6e",
            "74e390573ea242749a7bcaac164970e6",
            "e8dcaaf0546a43d0a4f559909c654bbf",
            "be4886ab77d342de8a8999d199b0009e",
            "f34ec067e7d2461c8f0fdb086cdf7b50",
            "2f3b203d2ac14705a740262c4d092754",
            "2e4ee69491dd47e4857fdd032fd54365",
            "46be26a3050f4d28b1348f40db9f7a05",
            "61b992d7bf9d48e392aee26f9aa03105",
            "a2bd7195f1124c4b945c723fcbcbbcb5",
            "409ac01dc52e44808358cb780d4c34f9",
            "19954f3d09b44fb882f86849fd69f690",
            "ece64d6c4b8f4066b62fd99e320bcbd3",
            "7177422c703145bc88a7164b8bb27515",
            "00451771cf89495b8b97c3453dfab792",
            "9c2c1f9506bb440d9f83eb663822cf20",
            "4f7e84f8eb284b929955ed2ef2a5570d",
            "24e0d3acfb5c4e9ebddd183f0664b24d",
            "3e79fdd3092646d3ac6acb6e909a8535",
            "fd204d38ff314bd2a607474fb1b207db",
            "f4d3925266a94772b688cf65821794c9",
            "5cfd86e6800c42e3b3864d313c97b498",
            "4745fc0b121e40b0a6d65fc16c1f03db",
            "4bf054390f284e079afc75dc0affdfd3",
            "b380a4366450409787ca7a57f1d18862",
            "239e1737a85b49d9825211c35c85767e",
            "fa746a7fad784f1fae0acf789e70d424",
            "1d251e2765314ab48496da58dd6a3ad8",
            "e34e106347004fd5aa7ea4b53b0c42ea",
            "18c4af60f2b94dadacff2e8a877e3ddd",
            "c2c13d296f784cb2a91b44346e276985",
            "3097ee6d1585414db1d6708c442d287a",
            "8441c42e32a44e50a1b2a469a4e187cd",
            "75e6339057d94874a8255788cac53983",
            "d5541991dea549ad9060e10129c8172b",
            "4ac275c336454566b011911f919b8b01",
            "e5e296dcf859428d82e68d820ff88a0d",
            "c9852fdd66b0455b8c7c28d947fe05ff",
            "92ef27ff960840a9b84d6c9c47516bae",
            "9c0375fa74f646ddb4c9d32373df23e6",
            "1021ee65e4e345e3971aa5efff1aa0a9",
            "feb3b8913f244be5bd9e3c2828aa40f8",
            "a6c2bf78a7e64505aa2d419864cacea8",
            "2ef38bbda0c743f6ae59f70a2bae3a53",
            "e527cd3bbda4408a8d6807e729ffeaf5",
            "cb8bc619bf29406893903d7b42e615a0",
            "f1f5a1a0357244c4b8a0152279ab5b5c",
            "7923ebaa7f0c466a88e88a6cc44dc961",
            "9adfd19453804f0883c2955cc0be9f6c",
            "689a6d3ba8384cb087c95eb604d3abfe",
            "aa4b9a508b674e6683f21afec5ff4c7d",
            "92978d07db014c869babbfbc2452ae61",
            "2de8beb5f3f24a4ba7a90490ea61551f",
            "6a5ffdfd9bd948259a4ed1b4ebb0969c",
            "69a2662320ff4ea8a76c856e4cdab3e3",
            "f50d73de4e6b4364a08aa178c1dd2248",
            "e924c918453d4d8cac0fadbed031bb38",
            "5bfae5b88e3a432387a47a85ed486884",
            "e18c54eb6cb24c4394249459779c2d7d",
            "43be75df609c4b778d7d80732ffa1609",
            "a38bfdf30ee74cfbbb7ccf4c774875e2",
            "9997ae011fa64793b7d55ee91030a020",
            "1ff26ab8d19046ba93dd6f4b3444482e",
            "5fb745766b4640e5a80142c2f730ee3a",
            "e395cb1b63c0457eabdc8f0f19da63e0",
            "b01fc93999b944a088d3d2a9559b5643",
            "92d7e700d715475588d44efad420ccf6",
            "9ad768b54ed949bba83bca5904374514",
            "62817b806c9d4caa8e4d8f83a156c519",
            "61bf0e49bd1a4df482b6cabb00a5c1e3",
            "df691eaded384c6c943d6ef882b8cad6",
            "5b30afc0f4034e8d882000507f4ac277",
            "a365d42dbdf04909a853fa41d28c5804",
            "07f2ca0f6fcd40d58e0e7b8f1f7e8780"
          ]
        },
        "outputId": "e369a6c2-55b3-41ff-d155-ec58ef606261"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl (76.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.45.4\n",
            "Logged into Hugging Face successfully!\n",
            "Mounted at /content/drive\n",
            "Tokenized dataset loaded!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95bee252432a4df182459da33924f31e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61b992d7bf9d48e392aee26f9aa03105"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd204d38ff314bd2a607474fb1b207db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2c13d296f784cb2a91b44346e276985"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer loaded!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "feb3b8913f244be5bd9e3c2828aa40f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2de8beb5f3f24a4ba7a90490ea61551f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fb745766b4640e5a80142c2f730ee3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model TinyLlama/TinyLlama-1.1B-Chat-v1.0 loaded successfully!\n",
            "trainable params: 2,252,800 || all params: 1,102,301,184 || trainable%: 0.2044\n",
            "Starting fine-tuning with LoRA...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1485' max='1485' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1485/1485 47:46, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>12.923000</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>13.255700</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>13.169800</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>13.159300</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>13.135000</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>12.868400</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>13.244900</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>13.121600</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>13.071100</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>13.099700</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>13.278900</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>12.963600</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>13.065600</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>13.134800</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>13.201100</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>12.962800</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>13.211200</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>13.221400</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>13.031800</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>13.199800</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>12.983900</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>13.077200</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>12.859700</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>13.262800</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>13.028300</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>13.102900</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>13.065500</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>13.149600</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>12.976300</td>\n",
              "      <td>13.060639</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning complete!\n",
            "Model and tokenizer saved to /content/drive/MyDrive/LLM/llama_finetuned_final!\n",
            "Prompt: The history of science is\n",
            "Generated Text: The history of science is often marked by a succession of crises, each more severe than the last. By the end of the Middle Ages, scientists were in a state of crisis, facing a lack of funding, a lack of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
        "\n",
        "# Load your fine-tuned model and tokenizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_path = \"/content/drive/MyDrive/LLM/llama_finetuned_final\"\n",
        "model = LlamaForCausalLM.from_pretrained(model_path).to(device)\n",
        "tokenizer = LlamaTokenizer.from_pretrained(model_path)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "def generate_text(prompt, max_length=100, temperature=0.7):\n",
        "    model.eval()\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=300).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=max_length,\n",
        "            temperature=temperature,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.95\n",
        "        )\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Gradio UI\n",
        "with gr.Blocks(title=\"My TinyLLM Chat\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # Welcome to My TinyLLM Chat!\n",
        "        I built this LLM from scratch and fine-tuned it with LoRA—type a prompt and see what it says!\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            prompt_input = gr.Textbox(label=\"Your Prompt\", placeholder=\"Type something like 'The future is...'\")\n",
        "            max_length_slider = gr.Slider(10, 300, value=50, step=10, label=\"Max Words\")\n",
        "            temperature_slider = gr.Slider(0.1, 1.5, value=0.7, step=0.1, label=\"Creativity (Temperature)\")\n",
        "            submit_btn = gr.Button(\"Generate\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            output_text = gr.Textbox(label=\"Generated Text\", lines=5, interactive=False)\n",
        "\n",
        "    submit_btn.click(\n",
        "        fn=generate_text,\n",
        "        inputs=[prompt_input, max_length_slider, temperature_slider],\n",
        "        outputs=output_text\n",
        "    )\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "i1W1cj_xx-ez",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d90e0417-1ce6-43e2-8a42-3de60d1af0dd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.23.3)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.29.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2024.12.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://36fe5ab037a9c59c9d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://36fe5ab037a9c59c9d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}